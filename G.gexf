<?xml version='1.0' encoding='utf-8'?>
<gexf xmlns="http://www.gexf.net/1.2draft" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.gexf.net/1.2draft http://www.gexf.net/1.2draft/gexf.xsd" version="1.2">
  <meta lastmodifieddate="2022-05-06">
    <creator>NetworkX 2.6.3</creator>
  </meta>
  <graph defaultedgetype="undirected" mode="static" name="">
    <nodes>
      <node id="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " label="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " />
      <node id="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " label="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " />
      <node id="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " label="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " />
      <node id="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " label="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " />
      <node id="(och and ney, 2004; koehnetal.,2003;marcuandwong,2002))charac" label="(och and ney, 2004; koehnetal.,2003;marcuandwong,2002))charac" />
      <node id="the basic model uses the following features, analogous to pharaoh’s default feature set: • p(γ " label="the basic model uses the following features, analogous to pharaoh’s default feature set: • p(γ " />
      <node id="in (koehn et al, 2003), various aspects of phrase-based systems are compared." label="in (koehn et al, 2003), various aspects of phrase-based systems are compared." />
      <node id="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " label="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " />
      <node id="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " label="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " />
      <node id="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " label="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " />
      <node id="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " label="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " />
      <node id="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " label="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " />
      <node id="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " label="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " />
      <node id="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " label="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " />
      <node id="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " label="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " />
      <node id="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " label="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " />
      <node id="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " label="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " />
      <node id="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " label="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " />
      <node id="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " label="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " />
      <node id="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " label="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " />
      <node id="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." label="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." />
      <node id="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " label="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " />
      <node id="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " label="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " />
      <node id="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " label="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " />
      <node id="the translation model used in (koehn et al, 2003) is the product of translation probability a34a35a4 a29 a0 a33 a6 a29 a2 a33 a8 and distortion probability a36a37a4a39a38 a33a41a40a43a42a44a33a46a45 a32 a8 , a3a5a4a35a29 a0 a30 a32 a6 a29 a2 a30 a32 a8 a10 a30 a47 a33a49a48 a32 a34a35a4 a29 a0a22a33 a6 a29 a2 a33a50a8 a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 (1) where a38 a33 denotes the start position of the source phrase translated into the a54 -th target phrase, and a42 a33a53a45 a32 denotes the end position of the source phrase translated into the a4a53a54 a40a56a55 a8 -th target phrase. " label="the translation model used in (koehn et al, 2003) is the product of translation probability a34a35a4 a29 a0 a33 a6 a29 a2 a33 a8 and distortion probability a36a37a4a39a38 a33a41a40a43a42a44a33a46a45 a32 a8 , a3a5a4a35a29 a0 a30 a32 a6 a29 a2 a30 a32 a8 a10 a30 a47 a33a49a48 a32 a34a35a4 a29 a0a22a33 a6 a29 a2 a33a50a8 a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 (1) where a38 a33 denotes the start position of the source phrase translated into the a54 -th target phrase, and a42 a33a53a45 a32 denotes the end position of the source phrase translated into the a4a53a54 a40a56a55 a8 -th target phrase. " />
      <node id="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " label="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " />
      <node id="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " label="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " />
      <node id="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " label="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " />
      <node id="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " label="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " />
      <node id="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " label="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " />
      <node id="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " label="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " />
      <node id="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " label="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " />
      <node id="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " label="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " />
      <node id="we also compared our model with pharaoh (koehn et al, 2003). " label="we also compared our model with pharaoh (koehn et al, 2003). " />
      <node id="the phrase-based model of koehn et al (2003) is an instance of this framework. " label="the phrase-based model of koehn et al (2003) is an instance of this framework. " />
      <node id="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " label="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " />
      <node id="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " label="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " />
      <node id="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " label="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " />
      <node id="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " label="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " />
      <node id="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " label="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " />
      <node id="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " label="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " />
      <node id="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " label="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " />
      <node id="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " label="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " />
      <node id="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " label="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " />
      <node id="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " label="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " />
      <node id="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " label="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " />
      <node id="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " label="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " />
      <node id="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " label="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " />
      <node id="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " label="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " />
      <node id="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " label="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " />
      <node id="we use the model of koehn et al (2003) as a baseline for our experiments. " label="we use the model of koehn et al (2003) as a baseline for our experiments. " />
      <node id="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " label="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " />
      <node id="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " label="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " />
      <node id="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " label="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " />
      <node id="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " label="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " />
      <node id="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " label="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " />
      <node id="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " label="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " />
      <node id="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." label="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." />
      <node id="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " label="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " />
      <node id="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " label="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " />
      <node id="we therefore adopted a modified weighting scheme following(koehnetal., 2003), whichincorporates null alignments. " label="we therefore adopted a modified weighting scheme following(koehnetal., 2003), whichincorporates null alignments. " />
      <node id="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " label="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " />
      <node id="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " label="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " />
      <node id="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " label="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " />
      <node id="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " label="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " />
      <node id="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " label="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " />
      <node id="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " label="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " />
      <node id="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " label="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " />
      <node id="our baseline is the phrase-based mt system of (koehn et al, 2003). " label="our baseline is the phrase-based mt system of (koehn et al, 2003). " />
      <node id="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " label="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " />
      <node id="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " label="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " />
      <node id="for further information on these parameter settings, confer (koehn et al, 2003). " label="for further information on these parameter settings, confer (koehn et al, 2003). " />
      <node id="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " label="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " />
      <node id="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " label="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " />
      <node id="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " label="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " />
      <node id="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " label="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " />
      <node id="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " label="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " />
      <node id="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " label="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " />
      <node id="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " label="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " />
      <node id="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " label="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " />
      <node id="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " label="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " />
      <node id="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " label="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " />
      <node id="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " label="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " />
      <node id="see (och and ney, 2000), (yamada and knight, 2001), (koehn and knight, 2002), (koehn et al, 2003), (schafer and yarowsky, 2003) and (gildea, 2003). " label="see (och and ney, 2000), (yamada and knight, 2001), (koehn and knight, 2002), (koehn et al, 2003), (schafer and yarowsky, 2003) and (gildea, 2003). " />
      <node id="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " label="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " />
      <node id="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " label="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " />
      <node id="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " label="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " />
      <node id="on smaller data sets (koehn et al, 2003) the joint model shows performance comparable to the standard model, however the joint model does not reach the level of performance of the stan156 en-es es-en joint 3-gram, dl4 20.51 26.64 5-gram, dl6 26.34 27.17 + lex. " label="on smaller data sets (koehn et al, 2003) the joint model shows performance comparable to the standard model, however the joint model does not reach the level of performance of the stan156 en-es es-en joint 3-gram, dl4 20.51 26.64 5-gram, dl6 26.34 27.17 + lex. " />
      <node id="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " label="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " />
      <node id="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " label="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " />
      <node id="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " label="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " />
      <node id="we use the following features for our rules: • sourceand target-conditioned neg-log lexical weights as described in (koehn et al, 2003b) • neg-log relative frequencies: left-handside-conditioned, target-phrase-conditioned, source-phrase-conditioned • counters: n.o. " label="we use the following features for our rules: • sourceand target-conditioned neg-log lexical weights as described in (koehn et al, 2003b) • neg-log relative frequencies: left-handside-conditioned, target-phrase-conditioned, source-phrase-conditioned • counters: n.o. " />
      <node id="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " label="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " />
      <node id="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " label="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " />
      <node id="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " label="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " />
      <node id="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " label="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " />
      <node id="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " label="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " />
      <node id="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " label="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " />
      <node id="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " label="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " />
      <node id="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " label="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " />
      <node id="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " label="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " />
      <node id="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " label="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " />
      <node id="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " label="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " />
      <node id="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " label="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " />
      <node id="791 and score the alignment template model phrases (koehn et al, 2003). " label="791 and score the alignment template model phrases (koehn et al, 2003). " />
      <node id="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " label="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " />
      <node id="traditionally, maximum-likelihood estimation from relative frequencies is used to obtain conditional probabilities (koehn et al, 2003), eg, p(˜s" label="traditionally, maximum-likelihood estimation from relative frequencies is used to obtain conditional probabilities (koehn et al, 2003), eg, p(˜s" />
      <node id="to derive the joint counts c(˜s,˜t) from which p(˜s" label="to derive the joint counts c(˜s,˜t) from which p(˜s" />
      <node id="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " label="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " />
      <node id="koehn et al (2003) compare a number of different approaches to phrase-based statistical machine 255 length num uniq (mil) average # translations avg trans length 1 .88 " label="koehn et al (2003) compare a number of different approaches to phrase-based statistical machine 255 length num uniq (mil) average # translations avg trans length 1 .88 " />
      <node id="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " label="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " />
      <node id="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " label="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " />
      <node id="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " label="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " />
      <node id="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " label="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " />
      <node id="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " label="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " />
      <node id="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " label="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " />
      <node id="for acquiring a pbm, we followed the approach described by koehn et al (2003). " label="for acquiring a pbm, we followed the approach described by koehn et al (2003). " />
      <node id="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " label="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " />
      <node id="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " label="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " />
      <node id="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " label="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " />
      <node id="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " label="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " />
      <node id="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " label="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " />
      <node id="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " label="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " />
      <node id="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " label="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " />
      <node id="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " label="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " />
      <node id="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " label="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " />
      <node id="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " label="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " />
      <node id="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " label="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " />
      <node id="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " label="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " />
      <node id="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " label="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " />
      <node id="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " label="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " />
      <node id="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " label="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " />
      <node id="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " label="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " />
      <node id="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " label="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " />
      <node id="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " label="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " />
      <node id="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " label="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " />
      <node id=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " label=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " />
      <node id="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " label="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " />
      <node id="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " label="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " />
      <node id="for details, please refer to koehn et al (2003). " label="for details, please refer to koehn et al (2003). " />
      <node id="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " label="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " />
      <node id="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " label="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " />
      <node id="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " label="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " />
      <node id="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " label="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " />
      <node id="details of this model are described by koehn et al (2003). " label="details of this model are described by koehn et al (2003). " />
      <node id="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " label="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " />
      <node id="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " label="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " />
      <node id="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " label="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " />
      <node id="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " label="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " />
      <node id="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " label="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " />
      <node id="for our experiments we used the following features, analogous to pharaoh's default feature set: • p(γ " label="for our experiments we used the following features, analogous to pharaoh's default feature set: • p(γ " />
      <node id="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " label="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " />
      <node id="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " label="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " />
      <node id="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " label="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " />
      <node id="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " label="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " />
      <node id="when we run a phrase-based system, pharaoh (koehn et al, 2003; koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations: (4) [aozhou] [shi] [yu] [bei han] [you] [bangjiao]1 [de shaoshu guojia zhiyi] [australia] [is] [dipl. " label="when we run a phrase-based system, pharaoh (koehn et al, 2003; koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations: (4) [aozhou] [shi] [yu] [bei han] [you] [bangjiao]1 [de shaoshu guojia zhiyi] [australia] [is] [dipl. " />
      <node id="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " label="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " />
      <node id="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " label="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " />
      <node id="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " label="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " />
      <node id="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" label="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" />
      <node id="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " label="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " />
      <node id="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " label="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " />
      <node id="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " label="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " />
      <node id="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " label="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " />
      <node id="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." label="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." />
      <node id="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " label="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " />
      <node id="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " label="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " />
      <node id="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " label="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " />
      <node id="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " label="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " />
      <node id="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " label="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " />
      <node id="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " label="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " />
      <node id="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " label="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " />
    </nodes>
    <edges>
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " id="0" weight="88.63158744315842" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " id="1" weight="82.73435785433125" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " id="2" weight="86.6452799253306" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " id="3" weight="88.97888086577166" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " id="4" weight="84.19124396767998" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="5" weight="86.27501449527726" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="6" weight="82.22211745376218" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="7" weight="82.95618228848247" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " id="8" weight="80.90108802625173" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="9" weight="84.62857139055716" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="10" weight="84.33684595341715" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="11" weight="83.34129862260346" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="12" weight="85.35748139352519" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="13" weight="84.9722989081699" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="14" weight="84.35095889653579" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="15" weight="83.61856831626275" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="16" weight="81.95668324217664" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="17" weight="83.26022881776791" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="18" weight="85.76976957799431" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="19" weight="81.9630952603911" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="20" weight="81.57072244797014" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="21" weight="80.72643527275298" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="22" weight="81.23554163175248" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="23" weight="87.38671607674672" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="24" weight="80.94974237467427" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="25" weight="85.36817341536249" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="26" weight="85.19927692673201" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="27" weight="82.66478475099652" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="28" weight="86.23638812359285" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="29" weight="82.00778585500225" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="30" weight="88.02999992563738" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="31" weight="80.65785673725834" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="32" weight="82.12758092573749" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="33" weight="82.78973625420916" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="34" weight="83.25579539694428" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="35" weight="83.37522316427597" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="36" weight="83.0548726241371" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="37" weight="80.91597783561045" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="38" weight="84.78048413030908" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="39" weight="85.54305013549133" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="40" weight="83.52865753881808" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="41" weight="88.88722613691611" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="42" weight="85.17540387788472" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="43" weight="83.2111155733698" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="44" weight="81.50400644328958" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="45" weight="81.23266650961429" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="46" weight="83.66693063378405" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="47" weight="83.7337954580552" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="48" weight="80.3466671662795" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="49" weight="82.77623119906248" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="50" weight="80.63503238826637" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="51" weight="83.99221619918835" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="52" weight="81.58903718330737" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="53" weight="82.41141004391584" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="54" weight="88.49242609918664" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="55" weight="80.28649823067431" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="56" weight="83.53086871243688" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="57" weight="87.68146922980935" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="58" weight="87.89207932576899" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="59" weight="89.23397906134414" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="60" weight="83.60233461681676" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="61" weight="81.043789946104" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="62" weight="82.84926033597763" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="63" weight="87.23156309883726" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="64" weight="81.25579363450753" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="65" weight="82.81217638402121" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="66" weight="88.64472764976466" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="67" weight="80.09452880635936" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="68" weight="82.05361283773304" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="69" weight="83.71276024533493" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="70" weight="84.58890698795179" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="71" weight="86.66445076918106" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="72" weight="82.24451589731758" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="73" weight="83.17177012051718" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="74" weight="82.80896038202947" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="75" weight="87.07417071275061" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="76" weight="82.16923803375576" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="77" weight="83.1604670717905" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="78" weight="82.92152306528679" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="79" weight="84.99737961195561" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="80" weight="81.46866110205401" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="81" weight="85.37779363575126" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="82" weight="80.00167222031858" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="83" weight="85.48511402425396" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="84" weight="82.91436871963644" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="85" weight="82.39459151589297" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="86" weight="83.65809623132759" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="87" weight="87.29537586770071" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="88" weight="86.01425192005698" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="89" weight="83.69859498032078" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="90" weight="81.93003738906353" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="91" weight="89.87224093394425" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="92" weight="85.3508134507616" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="93" weight="83.6617762846002" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="94" weight="86.2398184709148" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="95" weight="85.87597710489749" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="96" weight="84.1850397531963" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="97" weight="80.32650392040746" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="98" weight="82.9923093156452" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="99" weight="85.26072639238052" />
      <edge source="a common approach to phrase-based translation is to extract an inventory of phrase pairs (ppi) from bitext (koehn et al, 2003), for example, in the phraseextract algorithm (och, 2002), a word alignment ˆam1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : ˆam1 : ˆaj ∈ [i1,i2] iff j ∈ [j1,j2] . " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="100" weight="81.24766973612769" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " id="101" weight="82.89030123132204" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " id="102" weight="82.08096447337634" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " id="103" weight="87.59622431374619" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " id="104" weight="83.5233718629055" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="105" weight="84.52000494957723" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="106" weight="81.92412142727663" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="107" weight="81.4597312335694" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="108" weight="84.99576544366154" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="109" weight="85.28522276311423" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="110" weight="83.37129181047978" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="111" weight="81.63792608730671" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="112" weight="85.69484802544574" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="113" weight="82.26008434708976" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="114" weight="80.08158487218839" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="115" weight="85.26606761458675" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="116" weight="83.51278258052852" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="117" weight="83.33910789254048" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="118" weight="87.6595924621944" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="119" weight="81.00581106489653" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="120" weight="85.55500189143204" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="121" weight="81.38844030989816" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="122" weight="83.33015009130085" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="123" weight="84.14838305026085" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="124" weight="80.10158669584824" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="125" weight="80.26217509182135" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="126" weight="81.06503199800055" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="127" weight="81.04314437685713" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="128" weight="86.29046266592843" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="129" weight="84.66272241099198" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="130" weight="83.13873213987245" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="131" weight="82.46035960293074" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="132" weight="87.33423199036987" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="133" weight="81.40486401694571" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="134" weight="81.77871122281375" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="135" weight="84.2748940541987" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="136" weight="82.5654144275474" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="137" weight="83.65498666646754" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " id="138" weight="86.16989694350762" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="139" weight="83.34466411162495" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="140" weight="84.96069117013691" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="141" weight="85.4626837777823" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="142" weight="87.7237861002256" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="143" weight="84.6749062090175" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="144" weight="84.01092953071674" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="145" weight="82.41277360763755" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="146" weight="80.56734402487756" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="147" weight="84.4473264387056" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="148" weight="86.67636499462523" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="149" weight="81.03073831747041" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="150" weight="85.08085687520904" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="151" weight="83.86884391218716" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="152" weight="81.98262796344974" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="153" weight="84.38259761958622" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="154" weight="85.82554762797608" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="155" weight="86.0446765233389" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="156" weight="83.93041941939268" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="157" weight="80.77994185324226" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="158" weight="82.91923197628408" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="159" weight="80.88622045199743" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="160" weight="85.7651843524583" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="161" weight="80.6402207590553" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="162" weight="85.51898427206908" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="163" weight="83.43551915652263" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="164" weight="80.98831620401363" />
      <edge source="we generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (koehn et al, 2003) (both directions) and phrase penalty (constant value). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="165" weight="80.06178621328435" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " id="166" weight="83.16052297728918" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in (koehn et al, 2003), various aspects of phrase-based systems are compared." id="167" weight="80.20839800166671" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " id="168" weight="82.27152692546899" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " id="169" weight="82.17212876404601" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="170" weight="87.45536298650798" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="171" weight="85.61428102957758" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="172" weight="81.50646177498804" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="173" weight="83.64786733277757" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="174" weight="84.95712477023164" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="175" weight="84.99361368459901" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="176" weight="84.58447076315052" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="177" weight="82.31176197404724" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="178" weight="85.23846322563836" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="179" weight="80.90518507037746" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="180" weight="81.87740872749303" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="181" weight="80.96303340794955" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="182" weight="84.61608788353148" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="183" weight="84.10696038044117" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="184" weight="82.82466202910061" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " id="185" weight="83.65248910461396" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="186" weight="81.93637536542431" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="187" weight="86.59875029996122" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="188" weight="84.5104115532199" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="189" weight="86.50705295248106" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="190" weight="83.44193842180437" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="191" weight="82.78847338540263" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="192" weight="82.58617911853028" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="193" weight="86.74653291811943" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="194" weight="80.17385802959029" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="195" weight="85.48124049794082" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="196" weight="83.82081712482434" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="197" weight="80.91396148403417" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="198" weight="85.92946543707538" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="199" weight="84.16919275257855" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="200" weight="86.0154799738794" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="201" weight="82.53594917503597" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="202" weight="88.54731644206286" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="203" weight="85.46410836534793" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="204" weight="81.32056315487743" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="205" weight="89.15793239298264" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="206" weight="80.29385523836943" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="207" weight="82.76954195927671" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="208" weight="82.01957791258887" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="209" weight="86.72112373448569" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="210" weight="82.71086705099917" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="211" weight="80.68644256071076" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="212" weight="80.70954916313282" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="213" weight="80.47067531998809" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="214" weight="85.46477326048002" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="215" weight="84.58512745612082" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="216" weight="85.12675962336446" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="217" weight="85.15840449718728" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="218" weight="80.91081601990571" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="219" weight="80.39613370480667" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="220" weight="84.53920389155869" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="221" weight="83.28428360256885" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="222" weight="82.95176837402079" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="223" weight="81.30293822015464" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="224" weight="87.37850067939456" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="225" weight="82.10930275868111" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="226" weight="82.29666536400603" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="227" weight="84.85451892470081" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="228" weight="83.26822880037454" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="229" weight="85.09453007432325" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="230" weight="85.88835229746834" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="231" weight="87.24631986371494" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="232" weight="81.87371933970564" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="233" weight="84.60846530768316" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="234" weight="86.6095592690792" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="235" weight="83.08372367623052" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="236" weight="82.32307664974321" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="237" weight="82.83998352769915" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="238" weight="82.83219633080925" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="239" weight="82.43987422063512" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="240" weight="81.06485479610211" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="241" weight="80.09749616574268" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="242" weight="80.06043446544255" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="243" weight="85.02815340111987" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="244" weight="82.04864608356426" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="245" weight="83.64622564084118" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="246" weight="84.6782945385467" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="247" weight="81.3691039239041" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="248" weight="83.77872281699273" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="249" weight="80.47883383626106" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="250" weight="85.2432507254531" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="251" weight="83.71252563561025" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="252" weight="84.98391326134953" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="details of this model are described by koehn et al (2003). " id="253" weight="80.56768705007653" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="254" weight="85.32080619918472" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="255" weight="83.25571825516033" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="256" weight="88.04879543850186" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="257" weight="83.68108892623248" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="258" weight="82.83633124432671" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="259" weight="88.53212055998083" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="260" weight="80.96621508243508" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="261" weight="81.99823551635228" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="262" weight="83.82838641757576" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="263" weight="80.67768367397738" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="264" weight="85.12320869454086" />
      <edge source="the lexical-weighting features are estimated using a method similar to that of koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="265" weight="83.07548128221698" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " id="266" weight="87.81545361390141" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " id="267" weight="87.30299239544314" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="268" weight="92.02125600906321" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="269" weight="80.2036195023334" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="270" weight="85.41967073787431" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " id="271" weight="83.459797845715" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="272" weight="83.38800147379803" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="273" weight="87.70082165674427" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="274" weight="86.74301592131097" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="275" weight="83.00867747187321" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="276" weight="87.43243714235898" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="277" weight="88.40155439052747" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="278" weight="80.15583722793357" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="279" weight="89.24141070478586" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="280" weight="90.1119129321542" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="281" weight="81.56816053872085" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="282" weight="85.99048869049959" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " id="283" weight="86.23599958893386" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="284" weight="85.40360608830726" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="285" weight="81.17026264148801" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="286" weight="83.83106076041274" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="287" weight="81.71964338364666" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="288" weight="80.94360022837883" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="289" weight="81.58277219564832" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="290" weight="85.77819702321388" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="291" weight="82.79001041436173" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="292" weight="91.01622928852811" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="293" weight="80.59299272869902" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="294" weight="85.94702776753635" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="295" weight="84.19173252142905" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="296" weight="84.76051893206107" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="297" weight="82.70841715491892" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="298" weight="80.40530965584902" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="299" weight="89.53232101147948" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="300" weight="88.42540176146821" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="301" weight="80.48064399382717" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="302" weight="81.2454746135157" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="303" weight="90.20430081962118" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="304" weight="83.6392605178548" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="305" weight="84.6701698752843" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="306" weight="82.99541537425279" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="307" weight="88.05181180990749" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="308" weight="88.12147239337658" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="309" weight="92.43971872005092" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="310" weight="88.26807650789617" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="311" weight="82.28332597208079" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="312" weight="88.20959040852563" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="313" weight="85.08651684136058" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="314" weight="81.55368268842112" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="315" weight="88.26856711951298" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="316" weight="83.02086045776281" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="317" weight="85.2099800520939" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="318" weight="81.95803512716431" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="319" weight="81.2647170766307" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="320" weight="86.42818070161434" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="321" weight="83.01295562455955" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="322" weight="88.79594392876801" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="323" weight="91.18181457459586" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="324" weight="90.92829423614303" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="325" weight="86.8259044425133" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="326" weight="86.1031421941495" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="327" weight="85.72091736708967" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="328" weight="83.4582518426499" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="329" weight="86.9888449877779" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="330" weight="84.62644452914444" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="331" weight="87.62529954266442" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="332" weight="86.55246374776846" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="333" weight="80.12318743573668" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="334" weight="88.81774139079018" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="335" weight="83.91455312499633" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="336" weight="80.7347948406565" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="337" weight="82.86478540842057" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="338" weight="88.654555022881" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="339" weight="91.08828820271712" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="340" weight="88.93836415247067" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="341" weight="83.21027416494245" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="342" weight="86.89912191614397" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="343" weight="81.59598546444231" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="344" weight="83.162849958759" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="345" weight="82.83442330351025" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="346" weight="80.4361592734577" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="347" weight="85.1867803421814" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="348" weight="85.99398460552796" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="349" weight="82.4270631334138" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="350" weight="91.15777258653834" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="351" weight="87.89896506524855" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="352" weight="85.77070790518239" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="353" weight="83.46275674906647" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="354" weight="86.24306217327306" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="355" weight="84.62998086504658" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="356" weight="87.68932752645784" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="357" weight="83.30084596891058" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="358" weight="83.33289141872882" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="359" weight="85.72328572311152" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="360" weight="82.2526505167702" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="361" weight="81.92630585670896" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="362" weight="92.2537785477773" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="363" weight="84.89873910068934" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="364" weight="81.47368673437654" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="365" weight="85.2331838287266" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="366" weight="83.55107477794093" />
      <edge source="training begins with phrase pairs, obtained as by och, koehn, and others: giza++ (och and ney, 2000) is used to obtain one-to-many word alignments in both directions, which are combined into a single set of refined alignments using the final-and� method of koehn et al (2003); then those pairs of substrings that are exclusively aligned to each other are extracted as phrase pairs. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="367" weight="83.61975313428583" />
      <edge source="the basic model uses the following features, analogous to pharaoh’s default feature set: • p(γ " target="for our experiments we used the following features, analogous to pharaoh's default feature set: • p(γ " id="368" weight="92.21620076005198" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " id="369" weight="84.18892295230229" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " id="370" weight="84.46133327318222" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="371" weight="81.42220991269772" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="372" weight="82.54425966137677" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="373" weight="80.37919346190097" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="374" weight="87.87402455398068" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="375" weight="90.74133432120615" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="376" weight="80.85825223053465" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="we also compared our model with pharaoh (koehn et al, 2003). " id="377" weight="80.69158617489383" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="378" weight="81.12244501753105" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="379" weight="85.22583723670452" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="380" weight="81.35724083109285" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="381" weight="87.41344511119354" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="382" weight="87.82000478660457" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="383" weight="85.47400265392436" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="384" weight="84.5740265585636" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="385" weight="82.08176309770963" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="386" weight="90.07346888522876" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="387" weight="89.77784082773937" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="388" weight="81.61209135657785" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="389" weight="85.45007568516773" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="390" weight="81.85244464206977" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="391" weight="83.98315717137407" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="392" weight="80.3348700250665" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="393" weight="83.87683852878997" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="394" weight="86.17040816593915" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="395" weight="86.20394198985785" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="396" weight="88.18581054228385" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="397" weight="87.12848955770298" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="398" weight="87.33085461538835" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="399" weight="85.05512017033261" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="for further information on these parameter settings, confer (koehn et al, 2003). " id="400" weight="80.59531079742355" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="401" weight="86.55887471567654" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="402" weight="82.98854197774487" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="403" weight="85.19937921332503" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="404" weight="80.692728044872" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="405" weight="83.70723891606681" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="406" weight="81.05866561309223" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="407" weight="89.92168226629983" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="408" weight="85.99674219988864" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="409" weight="80.68770255641735" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="410" weight="84.62380450284068" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="411" weight="85.06017900734646" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="412" weight="80.49151805066894" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="413" weight="81.40068207177198" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="414" weight="82.22781596472666" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="415" weight="85.13988936412093" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="416" weight="88.12272629451418" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="417" weight="80.94774764713941" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="418" weight="85.85491050022836" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="419" weight="84.00143080907779" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="420" weight="80.68096473775033" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="421" weight="80.23528209955748" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="422" weight="82.55279711762107" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="details of this model are described by koehn et al (2003). " id="423" weight="81.1976956154925" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="424" weight="84.59951739282397" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="425" weight="81.27699665965591" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="426" weight="80.82816875014338" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="427" weight="85.50852020858744" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="428" weight="84.73393864611718" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="429" weight="84.82357802819442" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="430" weight="81.73656756449125" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="431" weight="85.74925260049974" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="432" weight="86.03594553552159" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="433" weight="81.22436094685546" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="434" weight="83.68011622071971" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="435" weight="85.44294153133656" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="436" weight="88.03825126560119" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="437" weight="85.1018371965572" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="438" weight="82.36232824768821" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="439" weight="86.03142640071253" />
      <edge source="in (koehn et al, 2003), various aspects of phrase-based systems are compared." target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="440" weight="80.34274068892185" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " id="441" weight="82.91005281841448" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="442" weight="84.61715956744658" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="443" weight="83.52975707722914" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="444" weight="85.8412816740008" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " id="445" weight="82.02365443768815" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="446" weight="87.14591377434272" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="447" weight="84.35250069589257" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="448" weight="80.16499102183458" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="449" weight="81.07330699186382" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="450" weight="83.71054825673376" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="451" weight="83.33127651978786" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="452" weight="82.92043515774697" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="453" weight="88.8407428951282" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="454" weight="82.09411156307023" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="455" weight="85.91947879094842" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="456" weight="80.9672879343887" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="457" weight="81.52475552336911" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="458" weight="82.76515341788419" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="459" weight="80.50479375675945" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="460" weight="81.85297686121129" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="461" weight="84.93389838610166" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="462" weight="87.53686587029601" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="463" weight="85.05431060361843" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="464" weight="88.73300038769368" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="465" weight="85.69163797361577" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="466" weight="89.16662754075062" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="467" weight="80.10834146113224" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="468" weight="87.5762784109026" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="469" weight="85.50822529430448" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="470" weight="87.01922221868968" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="471" weight="81.45771951609892" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="472" weight="81.705763619414" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="473" weight="80.13401565722664" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="474" weight="82.9472606751005" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="475" weight="81.10238743474325" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="476" weight="81.21074143400449" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="477" weight="83.83948770901341" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="478" weight="84.52432390925043" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="479" weight="82.2501978271838" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="480" weight="87.22589820169344" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="481" weight="83.19895355061647" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="482" weight="87.40985863000019" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="483" weight="80.92558686459724" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="484" weight="88.53943144623426" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="485" weight="84.69046273368235" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="486" weight="87.87895876651595" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="487" weight="82.32162664353385" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="488" weight="82.96559410748915" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="489" weight="86.42367792701945" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="490" weight="84.50082729007666" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="491" weight="81.1658757677602" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="492" weight="86.35054906927505" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="493" weight="87.56019850902872" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="494" weight="83.57751192845531" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="495" weight="88.59034648909483" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="496" weight="83.08962140119192" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " id="497" weight="81.84977344866233" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="498" weight="83.59838604716458" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="499" weight="89.89599999351192" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="500" weight="82.2408325944054" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="501" weight="86.69940050396904" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="502" weight="85.76267494691724" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="503" weight="84.2753416988233" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="504" weight="85.7865866399241" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="505" weight="80.52537516918912" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="506" weight="82.45987130248074" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="507" weight="88.29869045507846" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="508" weight="81.82442365186581" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="509" weight="84.22505436821164" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="510" weight="91.45585287592219" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="511" weight="80.54571463453608" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="512" weight="83.96611507408957" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="513" weight="85.05812900097425" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="514" weight="82.55747724609293" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="515" weight="83.99345577103551" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="516" weight="89.85442053679411" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="517" weight="82.18939487064647" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="518" weight="84.83126070467779" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="519" weight="88.52333391937756" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="520" weight="82.36534582038469" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="521" weight="82.6652944480958" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="522" weight="87.90159474260565" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="523" weight="80.5962892056018" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="524" weight="86.37501027076368" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="525" weight="87.5885942499313" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="526" weight="81.8265809102366" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="527" weight="83.99166210503672" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="528" weight="88.74347312756757" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="529" weight="84.19102268042533" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="530" weight="85.27786016888696" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="531" weight="83.4174874991233" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="532" weight="81.56427324585378" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="533" weight="88.4527876841283" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="534" weight="82.9413269225168" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="535" weight="80.610805885897" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="536" weight="87.60207901328336" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="537" weight="86.22513022194333" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="538" weight="80.51980681170777" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="539" weight="93.3366771223133" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="540" weight="82.47715517660082" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="541" weight="86.80336141076901" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="542" weight="90.53946666702453" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="543" weight="89.78728079520862" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="544" weight="85.99230195169815" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="545" weight="81.36511642087301" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="546" weight="82.40025924992302" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="547" weight="83.78463924743392" />
      <edge source="although the best performing systems are “phrasebased” (see, for instance, och and ney (2004) or koehn et al (2003)), possible phrase translations must first be extracted from word-aligned bilingual text segments. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="548" weight="83.24701366713192" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " id="549" weight="82.43360765805485" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="550" weight="84.38460182724177" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="551" weight="85.71814865976629" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " id="552" weight="84.79277742228426" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="553" weight="88.60314889855141" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="554" weight="80.95837394689222" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="555" weight="92.96372128354837" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="556" weight="84.74060818253446" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="557" weight="92.82249738267872" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="558" weight="90.80986765229713" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="559" weight="82.77568101832856" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="560" weight="87.57702994756997" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="561" weight="82.58263534658536" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="562" weight="81.57139521973897" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="563" weight="83.3585330323908" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="564" weight="82.64126563738456" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="565" weight="81.54960212348435" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="566" weight="83.98665155259715" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="567" weight="89.9933763596244" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="568" weight="85.01248252195872" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="569" weight="83.67120629571833" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="570" weight="82.50155703355307" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="571" weight="84.47539501845178" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="572" weight="86.09728224646041" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="573" weight="84.33192137719084" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="574" weight="80.13332208451955" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="575" weight="82.7577005069799" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="576" weight="83.7110810148275" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="577" weight="82.00649126553144" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="578" weight="81.208988047408" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="579" weight="86.42149058240629" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="580" weight="88.41274287345638" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="581" weight="91.26837413744266" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="582" weight="88.58449449304766" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="583" weight="82.03864851884977" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="584" weight="80.49230979230444" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="585" weight="88.39907049853998" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="586" weight="88.38198949705193" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="587" weight="80.24776627389225" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="588" weight="84.30579851958531" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="589" weight="83.92267481922187" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="590" weight="81.39755776819536" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="591" weight="85.16457112246398" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="592" weight="88.2200129528714" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="593" weight="87.18091849387845" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="594" weight="86.05677165023174" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="595" weight="86.3408409731565" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="596" weight="83.09468162066894" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="597" weight="83.98632705573796" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="598" weight="88.10276027048619" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="599" weight="80.24084541390899" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="600" weight="81.21203343599572" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="601" weight="86.23691238488259" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="602" weight="81.61423456423509" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="603" weight="82.12042821738315" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="604" weight="83.00580174766799" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="605" weight="82.28457345774464" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="606" weight="85.41248839362352" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="607" weight="80.88962684655552" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="608" weight="88.43486983829334" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="609" weight="85.2867882611659" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="610" weight="86.88281966715125" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="611" weight="82.95278208777357" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="612" weight="85.13158702170547" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="613" weight="84.92830328231018" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="614" weight="83.4559979042466" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="615" weight="83.81765254459863" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="616" weight="85.53653272450366" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="617" weight="80.24135267451717" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="618" weight="87.51133757160633" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="619" weight="84.34475924631593" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="620" weight="80.23502241013185" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="621" weight="81.45083324759021" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="622" weight="82.20148960407359" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="623" weight="82.59048404530812" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="624" weight="81.79685128621583" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="625" weight="80.1940740745583" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="626" weight="83.18598410109735" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="627" weight="82.87682350365262" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="628" weight="81.60250190511684" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="629" weight="81.7957794473335" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="630" weight="81.2483625254806" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="631" weight="83.73763250146138" />
      <edge source="the phrase-based decoder extracts phrases from the word alignments produced by giza++, and computes translation probabilities based on the frequency of one phrase being aligned with another (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="632" weight="82.67881948324967" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " id="633" weight="86.94556885985665" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="634" weight="80.78036674494686" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="635" weight="84.7751611144607" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="636" weight="83.67460117468464" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="637" weight="80.86180415712735" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="638" weight="81.25738905002329" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="639" weight="80.60017158414982" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="640" weight="84.67090974489567" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="641" weight="81.48385475706132" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="642" weight="83.9361404911846" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="643" weight="80.04583650646487" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="644" weight="81.67685300009052" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="645" weight="80.36069201842244" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="646" weight="80.88853846727805" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="647" weight="83.0192968673293" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="648" weight="81.50890101023664" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="649" weight="82.20549636434906" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="650" weight="80.34033274277657" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="651" weight="80.73071834186916" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="652" weight="80.22117576986936" />
      <edge source="the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (koehn et al, 2003), details are given in section 3.4. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="653" weight="80.01827761147864" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " id="654" weight="81.75378606218896" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="655" weight="83.36824387154765" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="656" weight="87.84958473047932" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="657" weight="82.09416868998831" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="658" weight="87.40469479959312" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="659" weight="81.93855069700258" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="we also compared our model with pharaoh (koehn et al, 2003). " id="660" weight="85.69201280338254" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="661" weight="84.02600429140404" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="662" weight="80.39569122457691" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="663" weight="80.28242858272037" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="664" weight="84.09818247703417" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="665" weight="85.89831036757106" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="666" weight="83.4194789401273" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="667" weight="85.38199684555683" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="668" weight="90.56828089319136" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="669" weight="83.42022978766761" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="670" weight="81.00531791516492" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="671" weight="80.43404169793224" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="672" weight="81.07115744386093" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="673" weight="91.51699501712787" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="674" weight="93.6052059728644" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="675" weight="91.88067633124999" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="676" weight="84.970786242059" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="677" weight="84.64900734003933" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="678" weight="88.58651570814202" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="679" weight="80.45085266998959" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="680" weight="92.45432889977788" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="681" weight="90.51420989454584" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="682" weight="88.61830691257447" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="683" weight="86.76816621690887" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="684" weight="89.87290654524914" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="685" weight="80.46565451412636" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="686" weight="84.61886111181462" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="687" weight="86.54078809634302" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="791 and score the alignment template model phrases (koehn et al, 2003). " id="688" weight="81.67342368597919" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="689" weight="81.93568911359033" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="690" weight="85.52819480789391" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="691" weight="84.46925302007173" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="692" weight="87.79392490200382" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="693" weight="89.9139035097408" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="for details, please refer to koehn et al (2003). " id="694" weight="80.82809739971101" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="695" weight="80.29748856377601" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="details of this model are described by koehn et al (2003). " id="696" weight="85.53901610263206" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="697" weight="88.88119564997345" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="698" weight="83.52592084971289" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="699" weight="84.99845173332557" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="700" weight="85.04082819448271" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="701" weight="87.59639631605076" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="702" weight="86.4828573583329" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="703" weight="86.00220094552098" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="704" weight="86.2402661372919" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="705" weight="88.33826895290923" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="706" weight="86.96951894405822" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="707" weight="80.97982832245125" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="708" weight="85.94864983396006" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="709" weight="81.29197977632565" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="710" weight="88.1953381859613" />
      <edge source="this section describes a phrase-based model for smt similar to the models presented in (koehn et al, 2003; och et al, 1999; tillmann and xia, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="711" weight="82.92304474985023" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " id="712" weight="83.71738163696638" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="713" weight="85.23940874883245" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="714" weight="86.28247179891308" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="715" weight="84.85047180949077" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="716" weight="83.69263641031878" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="717" weight="84.41390881745218" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="718" weight="84.83350329453559" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="719" weight="83.06708781270842" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="720" weight="84.95445457458032" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="721" weight="83.70723645348863" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="722" weight="84.08231372683099" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="723" weight="83.42728191051381" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="724" weight="88.61563333173434" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="725" weight="85.0082117977299" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="726" weight="84.17518826556245" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " id="727" weight="86.70423562492395" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="728" weight="87.46882813630543" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="729" weight="82.0808252790663" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="730" weight="82.7310902272399" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="731" weight="86.55335094686494" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="732" weight="84.7828734181935" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="733" weight="80.77017075762775" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="734" weight="83.1149031259784" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="735" weight="84.21410732309538" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="736" weight="86.42301099464366" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="737" weight="87.98625034479916" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="738" weight="82.87428997866047" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="739" weight="83.56384471806746" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="740" weight="86.90168479280189" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="741" weight="80.97965878506493" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="742" weight="82.453475405709" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="743" weight="85.48902724014597" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="744" weight="84.72553870067611" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="745" weight="87.03637639210726" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="746" weight="83.34270114746636" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="747" weight="91.22993671586708" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="748" weight="83.50648677378909" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="749" weight="80.57705593485811" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="750" weight="80.60428222015533" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="751" weight="84.0743831482038" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="752" weight="80.35120894659468" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="753" weight="81.1797363385378" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="754" weight="84.46641161701685" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="755" weight="86.58733797631379" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="756" weight="81.21751772254437" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="757" weight="86.02033962831403" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="758" weight="82.79402201699457" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="759" weight="80.13314649188257" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="760" weight="86.62996359352495" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="761" weight="85.99755866515038" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="762" weight="81.8656955761857" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="763" weight="89.24885078948483" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="764" weight="87.52110329110063" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="765" weight="82.77220178659388" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="766" weight="82.68731897444968" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="767" weight="86.73154015487101" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="768" weight="81.78822004381445" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="769" weight="85.84245288182805" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="770" weight="85.39828860298447" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="771" weight="85.90255411601144" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="772" weight="84.9919595725043" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="773" weight="81.12911504417882" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="774" weight="82.68503283042298" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="775" weight="83.84538910790337" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="776" weight="87.75367021628368" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="777" weight="83.21315328931868" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="778" weight="82.15092833373905" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="779" weight="87.40174502059776" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="780" weight="88.96705833072262" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="781" weight="90.57172590344105" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="782" weight="89.32207459408997" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="783" weight="80.43747969543126" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="784" weight="81.56715348224908" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="785" weight="86.36383441424051" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="786" weight="83.80818752629924" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="787" weight="85.03180609117966" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="788" weight="83.89261160803592" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="789" weight="85.53304870095452" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="790" weight="81.32790502644933" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="791" weight="82.8572997462637" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="792" weight="81.4673834421917" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="793" weight="89.82421060775539" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="794" weight="81.46066260286207" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="795" weight="83.41867523109379" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="796" weight="84.33920623616189" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="797" weight="83.19711730771866" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="798" weight="86.89739276134925" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="799" weight="89.7019945587912" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="800" weight="84.82696901301668" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="801" weight="84.14322677429085" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="802" weight="82.88456029997306" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="803" weight="83.76454599651973" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="804" weight="83.86084343361804" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="805" weight="80.11006839732498" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="806" weight="80.64268616909816" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="807" weight="81.45716917813964" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="808" weight="83.6354152347567" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="809" weight="87.04471344145286" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="810" weight="89.98338825175469" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="811" weight="85.78084477840196" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="812" weight="81.47114351073239" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="813" weight="81.66455656977674" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="814" weight="87.64698545590007" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="815" weight="82.51504640223193" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="816" weight="81.00777444855729" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="817" weight="88.99171992543693" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="818" weight="84.95100981109522" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="819" weight="80.30135758787131" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="820" weight="87.20055456761804" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="821" weight="90.78157959195423" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="822" weight="83.04385281271063" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="823" weight="89.11682052690986" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="824" weight="86.43230496968388" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="825" weight="87.15486141055501" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="826" weight="80.24872802056733" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="827" weight="80.19614287781462" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="828" weight="85.82533780907158" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="829" weight="86.70226616970645" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="830" weight="82.05381763114781" />
      <edge source="two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (koehn et al, 2003; tillmann and xia, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="831" weight="80.63002635011894" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="832" weight="86.63032260716778" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="833" weight="83.98865958440072" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="834" weight="83.3797841703172" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="835" weight="84.31518511540328" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="836" weight="80.0070191070199" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="837" weight="80.05266244858224" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="838" weight="80.69877882066336" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="839" weight="82.32399677016897" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="840" weight="81.04656125574414" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="841" weight="83.20686768486578" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="842" weight="80.21965301740872" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="843" weight="80.99357245391063" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="844" weight="82.67053764488533" />
      <edge source="by introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e∗ = argmaxe pr(e " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="845" weight="82.21805254944896" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " id="846" weight="80.29283488973059" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " id="847" weight="82.91460810275572" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="848" weight="87.73602450945135" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="849" weight="83.75318176180303" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="850" weight="80.5339544619373" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="851" weight="86.31726984548396" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="852" weight="83.4795067013752" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="853" weight="87.21098558453444" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="854" weight="85.55573237654856" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="855" weight="85.07707944386067" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="856" weight="83.91928427727176" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="857" weight="80.33257823026132" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="858" weight="83.33754135767452" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="859" weight="87.20786777818523" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="860" weight="84.9361892650439" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="861" weight="84.11501127615438" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="862" weight="88.31296415924311" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="863" weight="87.1726372425108" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="864" weight="84.72729943781884" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="865" weight="82.33963059077121" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="866" weight="88.45048243383111" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="867" weight="85.04862408659419" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="868" weight="87.2364884999286" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="869" weight="83.3446233775933" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="870" weight="86.09107425518965" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="871" weight="81.912194791173" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="872" weight="90.51322465947436" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="873" weight="85.86416810531736" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="874" weight="87.34915739651011" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="875" weight="83.60630339286863" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="876" weight="83.89659640999984" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="877" weight="86.92065609088408" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="878" weight="88.16165121896063" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="879" weight="85.5917237422162" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="880" weight="87.72160132867705" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="881" weight="89.851680930396" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="882" weight="81.52682877482866" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="883" weight="84.92924810630926" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="884" weight="82.98512634622126" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="885" weight="80.32719469847076" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="886" weight="82.05267207730185" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="887" weight="83.74690018761459" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="888" weight="89.89432428475064" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="889" weight="85.5249042385068" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="890" weight="85.821930002913" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="891" weight="82.16917859352588" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="892" weight="89.07120083466653" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="893" weight="83.42372562253504" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="894" weight="87.08258588055212" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="895" weight="88.23474698898816" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="896" weight="80.76265249986146" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="897" weight="82.60865158412034" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="898" weight="83.76452664299904" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="899" weight="91.5513088545059" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="900" weight="84.5052282964693" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="901" weight="84.73949578190849" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="902" weight="82.86199403777621" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="903" weight="81.80355506412185" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="904" weight="83.08828121503582" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="905" weight="85.05754642272336" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="906" weight="88.16733382722732" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="907" weight="87.07596822551294" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="908" weight="85.09296222613511" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="909" weight="88.16879623170053" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="910" weight="85.4734454433873" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="911" weight="87.20332964140462" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="912" weight="82.50543385140922" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="913" weight="84.31061143601436" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="914" weight="86.2423503888075" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="915" weight="85.88705254301627" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="916" weight="83.79828822762153" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="917" weight="81.75089785720961" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="918" weight="80.32776760041469" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="919" weight="84.81734588103424" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="920" weight="84.33463554956084" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="921" weight="83.60679665334538" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="922" weight="83.70031507818338" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="923" weight="85.33697063877241" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="924" weight="82.39766851613786" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="925" weight="84.72718673359083" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="926" weight="85.90196953145156" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="927" weight="83.49363220174001" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="928" weight="88.07674273194233" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="929" weight="88.47267905323703" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="930" weight="85.9515583063245" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="931" weight="85.08144395861387" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="932" weight="83.46792423621767" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="933" weight="80.12724847748464" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="934" weight="82.32213756221923" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="935" weight="85.83274784459405" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="936" weight="88.17799730447595" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="937" weight="80.82259178158692" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="938" weight="85.54427643456128" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="939" weight="82.71846783383079" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="940" weight="82.27909429586686" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="941" weight="86.74813371312507" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="942" weight="85.56105363795112" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="943" weight="84.10439016278468" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="944" weight="82.31492154228086" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="945" weight="88.07603556825303" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="946" weight="86.88421220106908" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="947" weight="82.55682217532028" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="948" weight="86.64028795781576" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="949" weight="82.7403970387405" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="950" weight="87.85503975830247" />
      <edge source="our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="951" weight="90.51056443161998" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " id="952" weight="90.07464641004603" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="953" weight="83.00960693503453" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="954" weight="82.98163396878631" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="955" weight="81.99161109580291" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="956" weight="83.1059250602053" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="957" weight="83.61248649422923" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="958" weight="80.50294155801177" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="959" weight="84.31446002772141" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="960" weight="81.05112559378394" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="961" weight="82.96742517178647" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="962" weight="82.58460366993083" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we also compared our model with pharaoh (koehn et al, 2003). " id="963" weight="81.00611521474575" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="964" weight="80.0170996970101" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="965" weight="83.32108590359262" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="966" weight="85.1372971464905" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="967" weight="80.80169503245465" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="968" weight="81.82326595636754" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="969" weight="87.29834004839468" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="970" weight="82.08181948995777" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="971" weight="86.42605889174871" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="972" weight="82.06598969925281" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="973" weight="80.56223752000126" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="974" weight="82.48305717186473" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="975" weight="83.934004510737" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="976" weight="82.61442826998473" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="977" weight="86.64328044815439" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="978" weight="81.61610650898396" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="979" weight="81.56784172203551" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="980" weight="82.6959500016188" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="981" weight="84.8927695024668" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="982" weight="83.52698991189274" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="983" weight="84.0919524928166" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="984" weight="84.70150642125634" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="985" weight="82.465289676803" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="986" weight="88.39263358740233" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="987" weight="82.33217074457959" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="988" weight="88.44535699055331" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="989" weight="82.47830927551954" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="990" weight="83.09444259600652" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="991" weight="85.79060718282554" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="992" weight="85.40540545509768" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="993" weight="85.1127493151093" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="994" weight="82.83593165948899" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="995" weight="87.76640442389349" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="996" weight="84.37462995896495" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="997" weight="81.37522527946157" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="998" weight="81.85659430349514" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="999" weight="82.93238299554773" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="1000" weight="86.98977985314144" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1001" weight="84.23426312517222" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1002" weight="88.77740650858085" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1003" weight="83.91889777636543" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1004" weight="86.6329131746425" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="1005" weight="82.63768932227886" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1006" weight="83.31473749838274" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1007" weight="84.79663623544404" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1008" weight="81.76781821342925" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1009" weight="85.18812809670524" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1010" weight="82.91626149350746" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1011" weight="86.54780761733282" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="1012" weight="80.17985550988485" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1013" weight="82.05982709134973" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1014" weight="89.83369707264244" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1015" weight="80.31732871415731" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="1016" weight="84.5158402862183" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1017" weight="83.47216976971785" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="1018" weight="87.34649884892818" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1019" weight="84.89188486639333" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1020" weight="86.82326593858937" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1021" weight="83.77281052868344" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1022" weight="83.15182431199" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="1023" weight="81.81079309413958" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1024" weight="84.02673276683923" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1025" weight="81.94686000883074" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1026" weight="83.50249503584355" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="1027" weight="82.80948040304628" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="1028" weight="85.18371547475219" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1029" weight="84.80553297078744" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="1030" weight="85.35681950891356" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="1031" weight="82.24966135528582" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="1032" weight="81.9715268176844" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1033" weight="88.9910702266525" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="1034" weight="85.02833063572572" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="1035" weight="83.56739486777577" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1036" weight="88.97579847841615" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="1037" weight="92.07233450318395" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1038" weight="80.38814014818803" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1039" weight="86.41918850589838" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1040" weight="84.22345434426927" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="1041" weight="87.55681854681758" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1042" weight="86.98449203776465" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1043" weight="90.0608282299344" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1044" weight="85.79642192259334" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1045" weight="82.57900923208675" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1046" weight="83.27898713916684" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="1047" weight="89.84465035197616" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1048" weight="82.35687579205478" />
      <edge source="one is distortion model (och and ney, 2004; koehn et al, 2003) which penalizes translations according to their jump distance instead of their content. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="1049" weight="81.41808674394125" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="1050" weight="81.17619414923338" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="1051" weight="85.67480521040711" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="1052" weight="88.51956683754976" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="1053" weight="84.72139663433641" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="1054" weight="90.28894689995914" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1055" weight="87.0096397666108" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1056" weight="81.82615132096247" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1057" weight="80.75516475889381" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1058" weight="82.70128205286966" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1059" weight="81.66951043255615" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1060" weight="85.26574636472013" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1061" weight="87.16570402226209" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1062" weight="82.86208636939558" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1063" weight="83.24663996387885" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1064" weight="84.53404675256533" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1065" weight="81.63159636521013" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="1066" weight="80.73804044757445" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1067" weight="86.04591737616474" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1068" weight="84.64231214872358" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1069" weight="82.01141797871863" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1070" weight="85.03682567087777" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1071" weight="80.1405906263212" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1072" weight="85.11084597993288" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1073" weight="84.54023710481412" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1074" weight="89.8817355045189" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1075" weight="84.9502033582007" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="1076" weight="81.74654975571312" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1077" weight="80.72341905947435" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1078" weight="85.50434970233387" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1079" weight="82.4663137762439" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1080" weight="81.93788228680341" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1081" weight="81.85600533122879" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1082" weight="82.90267309014152" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1083" weight="84.13171131463342" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1084" weight="85.20219530219622" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1085" weight="81.11695409058375" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1086" weight="86.71762926721607" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1087" weight="80.79801261125452" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1088" weight="87.40004592005062" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1089" weight="83.89887363646771" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1090" weight="84.14065831972901" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1091" weight="80.82812677812284" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1092" weight="85.6038273623317" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1093" weight="80.97127697871245" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1094" weight="82.52351759065948" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="1095" weight="90.02918788431214" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1096" weight="86.17523311993256" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="1097" weight="85.87363708087324" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1098" weight="81.50131112972423" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1099" weight="88.47163483272722" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1100" weight="81.13214878544571" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1101" weight="84.91248386916652" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1102" weight="81.73358650969188" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1103" weight="86.97067683385116" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1104" weight="80.82113125402468" />
      <edge source="statistical phrase-based translation (koehn et al, 2003): here “phrase-based” means “subsequence-based”, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1105" weight="82.29507554447089" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " id="1106" weight="83.68716231961304" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " id="1107" weight="81.24507098048774" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="1108" weight="81.14767429804624" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="1109" weight="88.72965705001437" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="1110" weight="80.23973927880641" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="1111" weight="86.04328351772051" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1112" weight="81.94367715800246" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1113" weight="84.97418464516022" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1114" weight="80.73465527189938" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " id="1115" weight="82.48428316570946" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1116" weight="83.83964247192881" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we also compared our model with pharaoh (koehn et al, 2003). " id="1117" weight="81.32122325962861" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="1118" weight="83.72890380565741" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1119" weight="80.2281888994566" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1120" weight="86.84159290073717" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="1121" weight="81.84084026125002" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="1122" weight="81.21956187671144" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1123" weight="90.73957305488187" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1124" weight="82.98358209719872" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1125" weight="86.93975990425866" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="1126" weight="83.62867071170561" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1127" weight="81.49790586314454" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="1128" weight="92.35626691731204" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="1129" weight="84.87453595561223" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1130" weight="91.39319367533008" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="1131" weight="86.67508409614955" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="1132" weight="88.84451762367935" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="1133" weight="88.85029557170382" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="1134" weight="84.58489831942163" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1135" weight="85.25493025381179" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1136" weight="88.21528110776768" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="1137" weight="83.47122062097951" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1138" weight="88.70614424989161" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1139" weight="85.35872881081576" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="1140" weight="80.43866627831835" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="1141" weight="82.07884244446144" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1142" weight="85.29314664457908" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="1143" weight="89.35127712992738" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="1144" weight="89.49983656188556" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="1145" weight="92.3335008997737" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1146" weight="82.61216715968631" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1147" weight="89.11807284896862" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="1148" weight="87.09514930385802" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1149" weight="91.78996147852227" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="1150" weight="80.7648641891895" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="1151" weight="82.43842777163594" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="1152" weight="87.89816711317833" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1153" weight="88.35409541478474" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1154" weight="80.66227197839436" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="1155" weight="85.5163076996153" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1156" weight="88.12877229512237" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1157" weight="85.7507208313128" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="1158" weight="85.47587271682748" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="1159" weight="80.4566343243873" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="1160" weight="82.64874900413801" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="1161" weight="81.72327243411127" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1162" weight="87.15217229809376" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1163" weight="91.10787981743202" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1164" weight="84.93036128609475" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="1165" weight="88.12109071456615" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="1166" weight="81.56739679197248" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1167" weight="84.78678738564783" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="1168" weight="85.51698190814984" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="1169" weight="94.46389671794482" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1170" weight="85.39820559708022" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1171" weight="91.02664541782781" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="1172" weight="84.96640281936179" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1173" weight="86.45223762490753" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1174" weight="89.15398449554746" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="1175" weight="85.09688880421209" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1176" weight="83.90544168691936" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1177" weight="87.37833799182013" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1178" weight="84.3458245396356" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1179" weight="83.82522703976554" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1180" weight="87.96401824867498" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1181" weight="86.5790209788267" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="1182" weight="83.03355825704621" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1183" weight="81.24191219252224" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1184" weight="93.35331909225285" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="1185" weight="83.85193969359351" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1186" weight="83.57675921528316" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="1187" weight="90.7501603575113" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1188" weight="85.75129108792132" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1189" weight="88.9326529214897" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1190" weight="85.22505309150449" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1191" weight="83.88625370668893" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="1192" weight="80.23282778309854" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1193" weight="85.64260109334916" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1194" weight="81.92603979983852" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="1195" weight="80.21180818374162" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="1196" weight="82.78946219150033" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1197" weight="80.29717034829109" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1198" weight="86.6736079563575" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="1199" weight="83.54942058170786" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="details of this model are described by koehn et al (2003). " id="1200" weight="81.49663438415683" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="1201" weight="90.943437599142" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1202" weight="87.6794462660546" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="1203" weight="86.57068552461541" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1204" weight="81.17821778926246" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="1205" weight="85.18858996774182" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1206" weight="90.77888716459658" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="1207" weight="86.46835565214215" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1208" weight="89.83528432431778" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="1209" weight="90.93220630610335" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1210" weight="89.46204020703163" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1211" weight="85.0935294294002" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="1212" weight="90.70589806954519" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1213" weight="87.9830798432125" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1214" weight="95.46550020906362" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1215" weight="89.52302380878538" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1216" weight="82.48517573459704" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1217" weight="88.62844175913212" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="1218" weight="94.37801884679698" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1219" weight="83.49038730061737" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="1220" weight="82.07252557104401" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="1221" weight="81.10515507954008" />
      <edge source="recent work in statistical machine translation (mt) has sought to overcome the limitations of phrase-based models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) by making use of syntactic information. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1222" weight="81.49644765749468" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="1223" weight="88.24000466354525" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="1224" weight="81.38687649075212" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="1225" weight="90.68675664129593" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="1226" weight="86.67920858238477" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="1227" weight="83.98699542399837" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1228" weight="85.72074651756105" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1229" weight="80.21133897222221" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1230" weight="84.26564541344177" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1231" weight="83.73684075559953" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1232" weight="82.40570745748927" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1233" weight="80.94040103150937" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1234" weight="84.87005059125994" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1235" weight="80.12690732907592" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1236" weight="81.86849809514283" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1237" weight="86.0458355900209" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="1238" weight="81.34455040481146" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="1239" weight="84.5336584605755" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1240" weight="87.33508924605434" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1241" weight="82.36899860024143" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1242" weight="82.80030885348111" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1243" weight="87.41023165977883" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1244" weight="84.3230914403422" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1245" weight="85.45150027187225" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1246" weight="82.1534268931976" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1247" weight="82.50362097204176" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="1248" weight="81.50133348675972" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1249" weight="85.63573920893757" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1250" weight="86.72385143387106" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1251" weight="92.06991788921535" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1252" weight="86.68310292043017" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1253" weight="89.6316522257864" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1254" weight="84.64273723862871" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1255" weight="80.74569865433277" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="1256" weight="84.42382085799484" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1257" weight="81.7522390407123" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="1258" weight="85.99022451259526" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="1259" weight="81.87664616898861" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1260" weight="83.93141858823287" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1261" weight="86.30985072274638" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="1262" weight="84.19334379441202" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1263" weight="87.9446922345424" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1264" weight="91.34759751543335" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1265" weight="87.90942312888497" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1266" weight="85.69002214526589" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1267" weight="83.1414816948218" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1268" weight="82.99183133712317" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1269" weight="83.5742314294742" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1270" weight="86.46287367099153" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1271" weight="83.10255473729133" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1272" weight="86.30565761637857" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1273" weight="83.24566929224898" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1274" weight="86.65884540341631" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1275" weight="81.88389673415533" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="1276" weight="80.04313892261345" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="1277" weight="81.78866755816858" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1278" weight="83.23564445869154" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="1279" weight="80.4913124841637" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1280" weight="88.92929448310814" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1281" weight="85.26637041521998" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1282" weight="82.31768267354072" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1283" weight="87.57226359488206" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1284" weight="86.20182623890744" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1285" weight="81.47745621523192" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="1286" weight="82.18676986312563" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1287" weight="80.71134867687144" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1288" weight="82.87206241331208" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1289" weight="88.37806212906307" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="1290" weight="82.46475400491522" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1291" weight="86.35956917137366" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1292" weight="84.88911496708376" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="1293" weight="81.35344660257272" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1294" weight="85.54091447434196" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="1295" weight="80.24192253165819" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1296" weight="82.08089244803239" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1297" weight="83.79358868180393" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="1298" weight="81.16257898770287" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1299" weight="84.25098159150681" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1300" weight="85.35257864830339" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1301" weight="83.52983691352374" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1302" weight="82.96189303357755" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1303" weight="80.722438842613" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="1304" weight="82.54813727080348" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1305" weight="82.5001164299844" />
      <edge source="word alignment and phrase extraction we used the giza++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source french file and the english reference file, and the refined word alignment strategy of (och and ney, 2003; koehn et al, 2003; tiedemann, 2004) to obtain improved word and phrase alignments. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1306" weight="85.39385480181724" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." id="1307" weight="84.01170374553448" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="1308" weight="81.33998152465955" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="1309" weight="80.89289203283086" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="1310" weight="82.40671128975687" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="1311" weight="86.1178638450539" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1312" weight="82.31105935174155" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1313" weight="84.14918576476487" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1314" weight="82.41082847867966" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="1315" weight="81.38674987121475" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1316" weight="81.39516468069152" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1317" weight="84.67330449263525" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1318" weight="85.32847533397263" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="1319" weight="80.5455753193904" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="1320" weight="80.73739025324416" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="1321" weight="83.53735195412501" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1322" weight="84.88357861256102" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1323" weight="86.56398603048304" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="1324" weight="82.56128577031272" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1325" weight="83.03042938810457" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1326" weight="85.42488087676207" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="1327" weight="80.00024118587544" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1328" weight="84.35815655092003" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1329" weight="82.59951321609837" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="1330" weight="82.51080060327263" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1331" weight="81.99194645375087" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1332" weight="82.73189154013956" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="1333" weight="85.58602232061652" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="1334" weight="80.98615383558369" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1335" weight="80.53951430891144" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1336" weight="82.03658746357027" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1337" weight="83.31444142733271" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1338" weight="85.17400276581132" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="1339" weight="82.31078745998923" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1340" weight="80.57596837391682" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1341" weight="80.21763093782799" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="1342" weight="80.92535670586567" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1343" weight="80.9709200965849" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1344" weight="82.4178376386048" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1345" weight="84.02850515496421" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1346" weight="87.04008130664873" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1347" weight="83.7005489941363" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1348" weight="80.62965201244248" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1349" weight="81.78155698168541" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="1350" weight="81.64596197284189" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1351" weight="84.60288916996703" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1352" weight="80.72224944078418" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="1353" weight="82.5873620686017" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1354" weight="83.55486357132233" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1355" weight="83.47659143339715" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1356" weight="82.08405780361277" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="1357" weight="82.72863331535393" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1358" weight="84.02455087375185" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1359" weight="81.07351216372243" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="1360" weight="82.61860017145636" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="1361" weight="80.57701273493065" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1362" weight="83.5986222013125" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="1363" weight="84.53492289444824" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1364" weight="81.58134971052569" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1365" weight="83.12278626829183" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1366" weight="82.44054320416707" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1367" weight="81.48594366362775" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="1368" weight="82.81739409332486" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1369" weight="86.09532872802686" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="1370" weight="84.43723364975399" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1371" weight="83.14690945530059" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1372" weight="87.58801307185928" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1373" weight="88.96915203742097" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1374" weight="83.61504424369737" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1375" weight="88.06306735022453" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1376" weight="81.08802055459188" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1377" weight="85.69847300551501" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="1378" weight="81.14948471480454" />
      <edge source="similarly, (koehn et al, 2003) propose a relative distortion model to be used with a phrase decoder. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1379" weight="82.45538355317036" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " id="1380" weight="83.99486632734701" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="1381" weight="95.57168557449853" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="1382" weight="91.03048622236633" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="1383" weight="87.51820956618907" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1384" weight="87.8632077583503" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1385" weight="84.34872619449591" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1386" weight="84.31532841830878" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1387" weight="85.11698845639441" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="1388" weight="81.49934457615603" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1389" weight="85.8998656577323" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1390" weight="83.66461007645225" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1391" weight="82.08184608852831" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1392" weight="82.08660872281921" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1393" weight="83.39832856552081" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1394" weight="88.94428517072485" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1395" weight="84.0422672963103" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1396" weight="84.96899398890659" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1397" weight="82.44717862517163" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1398" weight="88.11046304328487" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1399" weight="85.14520542560768" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="1400" weight="80.5426470619191" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="1401" weight="80.39250502815935" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="1402" weight="81.80421112395886" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1403" weight="82.17790674208305" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="1404" weight="80.71191032614327" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1405" weight="87.23120878843366" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1406" weight="84.22394534114963" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1407" weight="80.84116741731029" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="1408" weight="84.38648959270512" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1409" weight="85.81081691593977" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1410" weight="89.48336343566574" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1411" weight="90.88595877813228" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1412" weight="90.2350322762965" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1413" weight="89.05705681175166" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1414" weight="86.3497802948642" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="1415" weight="85.04320134784413" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1416" weight="84.39798633600437" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="1417" weight="87.5725969047036" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="1418" weight="80.2341206280841" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1419" weight="84.24529588865448" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1420" weight="86.20847328704035" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1421" weight="88.67687502811579" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1422" weight="87.21660356763277" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1423" weight="86.96268849382606" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1424" weight="89.59721160693508" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1425" weight="82.90713150671391" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1426" weight="82.98855479921421" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1427" weight="85.3628824324816" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1428" weight="88.99259638827148" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1429" weight="80.94515603514733" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1430" weight="84.13785451197107" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1431" weight="86.57105857125322" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="1432" weight="82.37004852486626" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1433" weight="81.82037748583429" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1434" weight="82.93093586200746" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="1435" weight="80.9453529509369" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="1436" weight="88.74241046164617" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1437" weight="83.8160155662455" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1438" weight="89.24829878303386" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1439" weight="80.52086350968027" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1440" weight="82.6397364132542" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1441" weight="87.84168050886932" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="1442" weight="80.46645808462402" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1443" weight="83.5761182220252" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1444" weight="88.21826876224218" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="1445" weight="81.19855939746299" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="1446" weight="80.64133156830063" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1447" weight="85.37368367194237" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1448" weight="81.04697154667456" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1449" weight="86.20877576521819" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="1450" weight="82.16567438489707" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1451" weight="89.03674888090336" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1452" weight="83.03391235332491" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="1453" weight="83.16214522231414" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1454" weight="82.34879349095448" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1455" weight="85.38950460844099" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1456" weight="82.30270385214926" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1457" weight="82.30186427230986" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1458" weight="83.93109189347325" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1459" weight="82.27243146353571" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1460" weight="82.39729055600039" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1461" weight="82.77589841344357" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1462" weight="80.50485083820847" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1463" weight="84.82352697981037" />
      <edge source="(koehn et al, 2003) used the following distortion model, which simply penalizes non-monotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter." target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1464" weight="83.2227337951529" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " id="1465" weight="82.54041718185915" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="1466" weight="90.31439860246427" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " id="1467" weight="81.1988512795174" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1468" weight="84.60670339002957" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1469" weight="83.18393613246835" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1470" weight="80.16215527509225" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="1471" weight="80.71266140651265" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1472" weight="87.78750463306444" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1473" weight="81.72641688331655" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="1474" weight="82.59447319269415" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1475" weight="83.65497854704513" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="1476" weight="83.10367460744929" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1477" weight="85.62254689327462" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="1478" weight="82.8839696083147" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1479" weight="85.35244873477232" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1480" weight="82.05642811913032" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="1481" weight="80.07271531049985" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1482" weight="80.21211649991835" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1483" weight="81.47319579381167" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1484" weight="83.92633859078549" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1485" weight="82.83821422478886" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="1486" weight="88.59975249865796" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="1487" weight="82.18857005997056" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="1488" weight="83.25621484554561" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1489" weight="80.17345761534085" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1490" weight="80.55797397839797" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1491" weight="81.59048452332208" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="1492" weight="82.404851496322" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1493" weight="84.14710083144908" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1494" weight="81.02911345175107" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1495" weight="81.57889188182293" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1496" weight="83.04261678543557" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1497" weight="85.04637186036656" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1498" weight="81.46667706403122" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1499" weight="81.38556550677114" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1500" weight="80.84307675266562" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1501" weight="81.63106565173726" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1502" weight="81.25778333804455" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1503" weight="81.79268798566267" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1504" weight="80.7805798101934" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1505" weight="82.79211542990284" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1506" weight="84.21263951455458" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="1507" weight="85.91218463645787" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="1508" weight="84.36482908578353" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1509" weight="85.61424109449798" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1510" weight="84.96829399770014" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1511" weight="83.48999637271962" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1512" weight="82.55674565840074" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1513" weight="82.25137057860262" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1514" weight="84.6365160937613" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1515" weight="84.6130846478806" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1516" weight="81.91486349706815" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1517" weight="80.87001345097586" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1518" weight="81.29285198695236" />
      <edge source="figure 4: n-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1519" weight="80.7673861702438" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " id="1520" weight="89.46496827636763" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="1521" weight="87.26660185233554" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1522" weight="86.82062951561964" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1523" weight="83.89076742249893" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1524" weight="83.0049576969244" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1525" weight="84.31732829720298" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="1526" weight="81.01225696680973" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1527" weight="83.26474814070315" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1528" weight="83.40760245865135" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="1529" weight="82.86175264223255" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1530" weight="84.67292519891775" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1531" weight="83.77653809538126" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1532" weight="83.6878147081454" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1533" weight="90.57493343081518" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="1534" weight="81.17593333387518" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1535" weight="87.23179389594877" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1536" weight="86.0477829308694" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1537" weight="83.64795227344956" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="1538" weight="81.78823119335736" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1539" weight="87.37356061014101" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1540" weight="86.64380593444771" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="1541" weight="80.66830378883012" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1542" weight="80.37052696496268" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1543" weight="87.38441324347066" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1544" weight="85.24994814127173" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1545" weight="81.23347506913375" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="1546" weight="83.83454864125616" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1547" weight="87.02919181548896" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1548" weight="87.66931891889315" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1549" weight="92.20878810947974" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1550" weight="91.51295384823912" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1551" weight="91.01686528328801" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1552" weight="85.63212205376878" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1553" weight="80.92470597485533" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="1554" weight="85.96905023417807" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1555" weight="82.12308450595731" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="1556" weight="87.06543574133782" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1557" weight="83.57281870960063" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1558" weight="86.92192940296812" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="1559" weight="80.42758597776498" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1560" weight="88.70186990896707" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1561" weight="89.14181026953662" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1562" weight="86.4305614260629" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1563" weight="88.77827731882294" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1564" weight="82.70220736122474" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1565" weight="82.61676160630715" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1566" weight="83.5846354154876" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1567" weight="90.74095340834134" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1568" weight="83.25800112161896" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1569" weight="83.11742785349072" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1570" weight="89.08982900623243" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="1571" weight="80.9122405016559" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1572" weight="83.36599848034274" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1573" weight="81.21854094049013" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="1574" weight="80.17303213476228" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="1575" weight="84.84287920407895" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1576" weight="84.71567142859406" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1577" weight="90.33229858792356" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1578" weight="81.43419793599695" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1579" weight="81.75551653430855" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1580" weight="87.07229387398647" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1581" weight="84.55574756158808" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1582" weight="89.78157962273482" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="1583" weight="83.73738411456773" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1584" weight="82.82836221656444" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1585" weight="80.60261074885283" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="1586" weight="80.50129747769745" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1587" weight="84.75919381847234" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="1588" weight="83.63866707253452" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1589" weight="90.36610381300179" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1590" weight="83.39791972308468" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="1591" weight="83.15738043092982" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1592" weight="82.4346716847908" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1593" weight="85.15298085503045" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1594" weight="83.840650022082" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="1595" weight="82.0714045974654" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1596" weight="86.4022377683183" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1597" weight="84.23286021102751" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1598" weight="81.45047903243712" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1599" weight="84.50365411537244" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1600" weight="81.49324958352997" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1601" weight="83.28280787923026" />
      <edge source="standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (koehn et al, 2003; och and ney, 2004). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1602" weight="83.74745406236694" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " id="1603" weight="86.57608776260348" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1604" weight="86.92360128563372" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1605" weight="81.90436061948647" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1606" weight="85.86480434694639" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1607" weight="85.27169196894356" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1608" weight="85.56833333415051" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1609" weight="83.48103854375411" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="1610" weight="80.79847909050555" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="1611" weight="81.2562858172872" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1612" weight="81.02200308456517" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1613" weight="85.44279911101216" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1614" weight="84.2231751437037" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1615" weight="89.34078311065005" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1616" weight="83.19019156919501" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1617" weight="83.95653037165276" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1618" weight="83.26815705301807" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="1619" weight="82.69127778098652" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1620" weight="87.69315084078396" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1621" weight="84.29759194417039" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="1622" weight="81.14927513401331" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1623" weight="80.29522100917366" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="1624" weight="82.49109235640431" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1625" weight="87.02154008699479" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1626" weight="84.25214156030438" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1627" weight="80.36517274909212" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="1628" weight="80.01043123130671" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="1629" weight="81.38081356502005" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1630" weight="86.34686357900907" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1631" weight="88.76778929795451" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1632" weight="90.86190865533075" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1633" weight="87.69965887933895" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1634" weight="88.5034941615904" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1635" weight="86.38908158774787" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="1636" weight="84.70958567747229" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1637" weight="81.56736192674417" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="1638" weight="86.9459878913298" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="1639" weight="80.45450088185497" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1640" weight="83.11436528979776" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1641" weight="88.68671745634029" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1642" weight="88.48519075283062" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1643" weight="86.15719641002424" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1644" weight="87.72965976546449" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1645" weight="88.17618568372289" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1646" weight="83.53620050237956" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1647" weight="85.37039836307376" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1648" weight="85.237369488255" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1649" weight="85.4495119580722" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1650" weight="81.10129577793272" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1651" weight="83.8125195504605" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1652" weight="85.30828263485517" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="1653" weight="82.32725938822372" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1654" weight="82.47355107654161" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1655" weight="85.19080500668603" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="1656" weight="80.54316813495493" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="1657" weight="84.10506905959335" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1658" weight="83.93471576929355" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1659" weight="88.12282789582208" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1660" weight="82.3991841424141" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1661" weight="83.01659188218011" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1662" weight="86.76761317969763" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1663" weight="81.59458424128316" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1664" weight="86.57233933020005" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="1665" weight="82.46822473187791" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1666" weight="85.37462933339708" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1667" weight="82.95800643144521" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1668" weight="88.26806745604578" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="1669" weight="82.41358429072605" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1670" weight="88.4113304117101" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1671" weight="83.11652925175946" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="1672" weight="82.56168286645662" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1673" weight="83.12164296814959" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1674" weight="82.6065694598328" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1675" weight="82.4350072712738" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1676" weight="82.43589052021878" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1677" weight="83.42023018304745" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1678" weight="81.69666573410734" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1679" weight="82.06907152724028" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1680" weight="82.78962032339292" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1681" weight="80.29287934042138" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1682" weight="84.2939588606109" />
      <edge source="here, ppicker� shows the accuracy when phrases are extracted by using the n-best phrase alignment method described in section 4.1, while growdiag-final� shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1683" weight="80.36762010296022" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="1684" weight="82.21699446463336" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1685" weight="82.21828604879286" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1686" weight="84.27918652343082" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1687" weight="80.97685523748284" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we also compared our model with pharaoh (koehn et al, 2003). " id="1688" weight="83.38191225382946" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="1689" weight="85.11063789115447" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1690" weight="83.46185981291538" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="1691" weight="81.86410556286697" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1692" weight="86.30399371494171" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1693" weight="81.29236867887938" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1694" weight="85.23255659163318" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="1695" weight="91.04035612485796" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1696" weight="83.69494204452398" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="1697" weight="86.67181876213573" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="1698" weight="82.33984171863604" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1699" weight="88.9416374308563" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="1700" weight="86.27769833734753" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="1701" weight="98.11516239508937" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="1702" weight="89.86988790605801" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="1703" weight="83.60774766576009" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1704" weight="81.62623464840595" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1705" weight="89.34988502076769" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="1706" weight="86.11052468722096" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1707" weight="87.0619934248549" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1708" weight="84.11390793129627" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="1709" weight="81.95218681017215" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="1710" weight="81.4497032051064" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1711" weight="86.11809351724477" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="1712" weight="86.26318569815106" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="1713" weight="88.93235604794809" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="1714" weight="90.53161118176905" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1715" weight="80.04827775278476" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1716" weight="90.00003275062444" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="1717" weight="89.95602630444601" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1718" weight="87.72454956478377" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="1719" weight="90.54074758747146" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1720" weight="87.9794090232825" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1721" weight="80.19945325798051" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="1722" weight="86.71515277083834" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1723" weight="84.18065644428236" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1724" weight="83.51813545519727" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="1725" weight="85.33070743390209" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="1726" weight="86.23239084642181" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="1727" weight="82.4209749138902" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="1728" weight="85.60970500103457" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1729" weight="84.2506859923905" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1730" weight="80.98166663976936" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1731" weight="91.775123000286" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1732" weight="82.05712033341047" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="1733" weight="90.13998018921656" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1734" weight="83.75887258113657" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="1735" weight="83.84274234358197" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="1736" weight="86.51568511104546" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1737" weight="82.37182068405313" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1738" weight="85.4244292419888" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1739" weight="84.22531006984038" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1740" weight="82.78031908411809" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="1741" weight="82.25870407481679" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1742" weight="81.10115522877504" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1743" weight="86.17212745967781" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1744" weight="82.79807912352331" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1745" weight="81.3315000270207" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1746" weight="84.78625844994991" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1747" weight="82.77341309477694" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="1748" weight="84.70389309070218" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1749" weight="80.73474846242146" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1750" weight="89.84190128700986" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="1751" weight="81.51870203548424" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1752" weight="83.0597121010964" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="1753" weight="88.13925116444727" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1754" weight="80.02630707887634" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1755" weight="86.74739285228996" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1756" weight="86.36259616147225" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1757" weight="83.37819668412749" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1758" weight="83.25720603879387" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1759" weight="81.40939894240569" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="1760" weight="82.52605870212753" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="1761" weight="83.2289261812" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="1762" weight="83.7744581795036" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="1763" weight="81.75740211007695" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1764" weight="80.56582466443622" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="1765" weight="84.84556274568533" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="1766" weight="80.5812567024947" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="details of this model are described by koehn et al (2003). " id="1767" weight="81.76789950192469" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="1768" weight="87.13380960151811" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1769" weight="87.29685931561475" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="1770" weight="80.74219416169804" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="1771" weight="87.02912254673154" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1772" weight="88.03530643722144" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="1773" weight="86.77819903704771" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1774" weight="87.68598099760337" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="1775" weight="85.4275569674925" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1776" weight="91.41826812562716" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1777" weight="85.85517241874348" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="1778" weight="88.3224199397251" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1779" weight="85.46286762834305" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1780" weight="91.46111864713271" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1781" weight="88.34023156870958" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1782" weight="80.2447267443843" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1783" weight="86.30961601436489" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="1784" weight="87.86148920373024" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1785" weight="83.99329119049249" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="1786" weight="80.1777936359706" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="1787" weight="82.737307492717" />
      <edge source="during the last few years, smt systems have evolved from the original word-based approach (brown et al, 1993) to phrase-based translation systems (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1788" weight="80.4578950246868" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " id="1789" weight="81.87382938300236" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1790" weight="89.40069303683025" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1791" weight="85.83913212139251" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1792" weight="85.31591157061045" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1793" weight="86.22801180765344" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1794" weight="87.66003339139645" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="1795" weight="80.14815539022291" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1796" weight="82.78133620027572" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1797" weight="88.33109343346892" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1798" weight="89.60553204409723" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1799" weight="84.32222861513753" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1800" weight="85.12104484608099" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1801" weight="81.01024417056016" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1802" weight="87.65548565507646" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1803" weight="82.0153270129053" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="1804" weight="89.7245457833544" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="1805" weight="80.42829293797114" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="1806" weight="84.88279121731152" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1807" weight="92.62702043654923" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1808" weight="84.98503976835485" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1809" weight="86.65738400948493" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="1810" weight="85.55696688946537" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1811" weight="89.14401540689245" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1812" weight="85.98742038518357" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1813" weight="88.74757261497233" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1814" weight="87.50850367866332" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1815" weight="91.33602503103941" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1816" weight="88.28080531762048" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="1817" weight="86.31338423640801" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1818" weight="84.9901595941638" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="1819" weight="82.35054525118821" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="1820" weight="83.03101448968467" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1821" weight="80.31329613354113" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1822" weight="83.92916240209709" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1823" weight="88.56206294769575" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1824" weight="86.94599230708744" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1825" weight="87.54879179726969" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1826" weight="85.91454800626109" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1827" weight="89.81184259827948" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1828" weight="83.74543177525908" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1829" weight="86.94711644852137" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1830" weight="85.83910870945482" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1831" weight="80.23991923255464" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1832" weight="86.85450922167858" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1833" weight="87.79671561889941" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="1834" weight="80.90587358237842" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1835" weight="83.25447826122027" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1836" weight="87.43591848279254" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="1837" weight="80.87764109985385" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="1838" weight="80.06405860588175" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1839" weight="91.18092344417028" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1840" weight="89.70021684993874" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1841" weight="82.14840072576115" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1842" weight="84.52306131639563" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="1843" weight="88.8628231430086" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="1844" weight="81.60790574545258" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="1845" weight="82.67795316975023" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="1846" weight="81.71458370596234" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1847" weight="89.84835812761185" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="1848" weight="83.19499137833655" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1849" weight="87.27018604760086" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="1850" weight="82.48625101964193" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="1851" weight="90.97181725678543" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="1852" weight="88.54841154792635" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1853" weight="81.04859405646624" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="1854" weight="87.35688764294589" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1855" weight="84.7038017340413" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="1856" weight="90.19729893625303" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1857" weight="83.89257136826147" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1858" weight="81.62724309830284" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1859" weight="85.88807979279598" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1860" weight="81.44883017577753" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1861" weight="80.58331109037607" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="1862" weight="91.6007814545265" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="1863" weight="80.66823836257224" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1864" weight="87.79707487927175" />
      <edge source="the process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (koehn et al, 2003), but it is not obvious which one should be chosen for a given language pair. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="1865" weight="80.41881443602091" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " id="1866" weight="83.72377738898369" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1867" weight="86.6594121800886" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1868" weight="80.17047470576108" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1869" weight="87.97377595451891" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we also compared our model with pharaoh (koehn et al, 2003). " id="1870" weight="82.060621932946" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="1871" weight="82.96638817868573" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1872" weight="81.78138985629482" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1873" weight="84.58663235500265" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1874" weight="81.70571971740961" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1875" weight="82.7832841807078" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1876" weight="81.07440109548693" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1877" weight="82.74048329557849" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="1878" weight="81.20394536165082" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="1879" weight="87.67383172652201" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1880" weight="82.67326697613832" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1881" weight="83.71766579159514" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1882" weight="86.52678797025621" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1883" weight="82.12121330835657" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="1884" weight="81.03191412620411" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="1885" weight="83.67312014961396" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1886" weight="82.83226623178435" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1887" weight="88.77866899166665" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="1888" weight="80.48651169703842" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1889" weight="88.30079214078894" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1890" weight="83.4720088103299" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1891" weight="82.15327296162505" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1892" weight="83.65655270278826" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1893" weight="83.6220632548394" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1894" weight="83.09444212967014" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1895" weight="80.31111427296086" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1896" weight="82.78096055346515" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1897" weight="89.43048335773061" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="1898" weight="84.18339457422155" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="1899" weight="81.7488667135769" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1900" weight="80.32342946368394" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1901" weight="83.17455247784041" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="1902" weight="80.2318857451495" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1903" weight="81.42974850505324" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1904" weight="80.77585603021942" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1905" weight="85.16157717160952" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1906" weight="86.96148573772946" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1907" weight="80.97124434280232" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1908" weight="84.79521447657925" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1909" weight="80.42013931996492" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="1910" weight="82.612134051603" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1911" weight="86.64483261646616" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="1912" weight="80.824519490462" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1913" weight="87.00198928021436" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="1914" weight="85.18006223502385" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1915" weight="83.96127440127121" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="1916" weight="84.74369652621428" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1917" weight="83.88634989964696" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="1918" weight="85.09781975632949" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="1919" weight="84.87591077274703" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="1920" weight="83.46348884413291" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="1921" weight="82.73073402538449" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="1922" weight="81.47808220329782" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="1923" weight="80.46533973765646" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="1924" weight="84.19725035575694" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="1925" weight="83.70066422617684" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="1926" weight="80.72313715197129" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="1927" weight="83.32396579750913" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="1928" weight="82.5727372025035" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="1929" weight="85.02789920774147" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="1930" weight="84.25393663870464" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="1931" weight="84.3437705604669" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="1932" weight="81.60647004977474" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="1933" weight="81.01946209989102" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="1934" weight="85.96192445267525" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="1935" weight="86.42588749849914" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="1936" weight="83.57224530125254" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="1937" weight="85.1734707391846" />
      <edge source="in the future, we plan to explore our discriminative framework on a full distortion model (koehn et al, 2003) or even a hierarchical model (chiang, 2005). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="1938" weight="81.62678525446975" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " id="1939" weight="83.7518610220052" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="1940" weight="85.56510050160826" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " id="1941" weight="81.5101929247105" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="1942" weight="86.47777663651775" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="1943" weight="81.72766705781078" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="1944" weight="85.40168703081967" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="1945" weight="81.40137995915921" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="1946" weight="82.61778515900899" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="1947" weight="84.29044870627915" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="1948" weight="85.21573644084539" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="1949" weight="84.34779191933792" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="1950" weight="90.11961253641275" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="1951" weight="82.7214861646226" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="1952" weight="81.78158302685988" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="1953" weight="80.83170418444914" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="1954" weight="83.19429465683781" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="1955" weight="86.31630306338096" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="1956" weight="86.8260086378774" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="1957" weight="80.84224247646748" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="1958" weight="90.66270558488925" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="1959" weight="84.92272172364979" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="1960" weight="83.87062305689112" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="1961" weight="82.7936109903171" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="1962" weight="84.01472385293418" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="1963" weight="81.71233194744649" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="1964" weight="89.55273796701402" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="1965" weight="87.16667163893577" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="1966" weight="84.39403395739195" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="1967" weight="81.49950028442763" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="1968" weight="86.59892749814739" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="1969" weight="89.70948399118781" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="1970" weight="90.68784454382866" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="1971" weight="86.85285851208737" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="1972" weight="81.47149590559238" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="1973" weight="89.84706269682106" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="1974" weight="88.12767514762592" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="1975" weight="80.53185089249155" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="1976" weight="86.62316452376938" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="1977" weight="85.455293255534" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="1978" weight="82.83122842582551" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="1979" weight="83.27370688446109" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="1980" weight="82.26892607526064" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="1981" weight="87.18398802926728" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="1982" weight="80.29455880804686" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="1983" weight="88.87087065502797" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="1984" weight="86.19349504027942" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="1985" weight="90.87077463266789" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="1986" weight="87.133216225332" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="1987" weight="85.35300869348657" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="1988" weight="88.39626081325065" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="1989" weight="90.93706968864055" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="1990" weight="87.84151656058532" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="1991" weight="88.48051433898594" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="1992" weight="87.57597284620726" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="1993" weight="83.31900809360113" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="1994" weight="85.16005554851805" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="1995" weight="83.650629098555" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="1996" weight="80.87803468730522" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="1997" weight="82.0652813846622" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="1998" weight="88.30230904888776" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="1999" weight="88.4167194708523" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2000" weight="87.34539615751167" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2001" weight="84.08416564439327" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2002" weight="86.71020256184956" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="2003" weight="82.53901876995408" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2004" weight="84.14958007928534" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2005" weight="85.05651291952651" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="2006" weight="80.34318942286558" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2007" weight="81.0333370775074" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2008" weight="86.53539564913575" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2009" weight="85.03635149066126" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="2010" weight="80.49447862909274" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="2011" weight="81.77946139404828" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2012" weight="90.80434683185683" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="2013" weight="83.27344330652804" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="2014" weight="86.52588141648711" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2015" weight="86.47427775113898" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2016" weight="87.28227139357496" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="2017" weight="85.90047407997834" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2018" weight="87.70517993869858" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="2019" weight="85.33869626603654" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2020" weight="85.41646700172907" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2021" weight="83.24673108384961" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2022" weight="86.81847007900086" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2023" weight="83.26000899103146" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2024" weight="82.6042894757852" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2025" weight="83.82043783367715" />
      <edge source="the heuristics in koehn et al (2003) decide whether to extract a given phrase pair based on the underlying word alignments (see figure 3 for three examples), which we call constellations. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2026" weight="89.1013189657695" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " id="2027" weight="83.10070138018304" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="2028" weight="86.18551179076125" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="2029" weight="86.49037796057102" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="2030" weight="82.56430894535991" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="2031" weight="86.23491902047367" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="2032" weight="80.21251707178511" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2033" weight="84.18467805499881" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2034" weight="86.10121629445393" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2035" weight="85.21345132767162" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="2036" weight="83.54381660709753" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2037" weight="84.80127438154396" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2038" weight="80.18691744905722" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2039" weight="88.42316244174056" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="2040" weight="82.76953899189441" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2041" weight="84.27578078869576" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2042" weight="83.47234828248102" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2043" weight="85.2050696058879" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2044" weight="85.18196611844076" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2045" weight="87.44746763395348" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2046" weight="86.33096382264367" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2047" weight="81.61178221916687" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="2048" weight="81.72113836502287" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="2049" weight="82.44156724145716" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2050" weight="84.28371974641024" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2051" weight="90.0872676655075" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2052" weight="83.01022528895827" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2053" weight="87.07355813119835" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="2054" weight="80.95128238782323" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2055" weight="87.58166691325711" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2056" weight="81.15437715959686" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2057" weight="86.24075815751884" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2058" weight="88.82456107798752" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2059" weight="86.01194717142128" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2060" weight="83.06750790962955" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2061" weight="84.16245167120103" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2062" weight="87.60434234921928" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="2063" weight="80.6365007635952" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="2064" weight="81.06476891025798" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2065" weight="84.35564239368732" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2066" weight="83.50341183607371" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2067" weight="86.9990421151878" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="2068" weight="81.33125170064521" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="2069" weight="80.25793922467261" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2070" weight="82.06344192199533" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2071" weight="83.63381427588786" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2072" weight="86.54105120606029" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2073" weight="88.15750369577229" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2074" weight="80.65531834246156" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2075" weight="82.87409236670345" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2076" weight="86.32176540383323" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2077" weight="80.52691045623904" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2078" weight="85.81308112431434" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2079" weight="83.36905495472013" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2080" weight="81.2395710270075" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="2081" weight="80.50991875461233" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2082" weight="85.40270831244922" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2083" weight="83.03131947950794" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2084" weight="82.32156923590594" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2085" weight="84.50781640218774" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="2086" weight="82.40185961981786" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2087" weight="87.93092422710393" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2088" weight="82.32895880048783" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2089" weight="86.66813982198987" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2090" weight="83.60744621431755" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="2091" weight="80.00255900744722" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2092" weight="81.59198849735705" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2093" weight="86.85852934329479" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="2094" weight="83.54594898389793" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2095" weight="80.98510112451798" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2096" weight="85.03832204297055" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2097" weight="80.49915796811507" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2098" weight="86.53014948335607" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="2099" weight="81.34193141859475" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2100" weight="84.69727069340323" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="2101" weight="83.15446401583944" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2102" weight="84.44043210624454" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="2103" weight="81.68895943968697" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2104" weight="85.44748924088933" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="2105" weight="80.57909558323846" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2106" weight="86.78781472489085" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2107" weight="85.31415782243326" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2108" weight="82.50822280602921" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2109" weight="82.1929443201207" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2110" weight="85.02925370371854" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2111" weight="87.49251744054914" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2112" weight="80.14039753289215" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2113" weight="81.98979474166109" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2114" weight="82.74564809693877" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2115" weight="87.24260200044955" />
      <edge source="the proposed system is phrase-based, as in koehn et al (2003), but uses an online perceptron training scheme to learn model parameters. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="2116" weight="83.94513311472342" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " id="2117" weight="85.56158873434494" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="2118" weight="87.45578806609062" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="2119" weight="82.31608447668148" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="2120" weight="80.29222479111213" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2121" weight="87.58486923205031" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2122" weight="83.39721441537256" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2123" weight="80.9694824394497" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2124" weight="83.1941379714567" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2125" weight="85.46222212289283" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2126" weight="84.76927437161463" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2127" weight="84.58955150527783" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2128" weight="81.16530272553963" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2129" weight="88.19581120157952" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2130" weight="84.41798689447688" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="2131" weight="80.2421872177383" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2132" weight="87.33093858133742" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2133" weight="84.94892045735831" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2134" weight="81.49703432480693" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2135" weight="82.13236842330369" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2136" weight="85.65310372062702" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2137" weight="86.74930487849896" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2138" weight="85.68088059570744" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2139" weight="85.0301769083601" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2140" weight="90.57678991867269" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2141" weight="84.92347593094114" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2142" weight="84.45768130646498" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2143" weight="85.13681840755358" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2144" weight="88.40747034085665" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2145" weight="87.5702999598874" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2146" weight="91.22578196755806" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2147" weight="84.70006988183812" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2148" weight="84.82128455781972" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2149" weight="86.06559638417369" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2150" weight="81.58031915137332" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2151" weight="84.61823744693335" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2152" weight="82.5689220777103" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2153" weight="89.31214108964537" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2154" weight="84.96020796373966" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2155" weight="87.17719454262762" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2156" weight="80.79166298251437" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2157" weight="80.950111045369" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2158" weight="86.53089949652765" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2159" weight="82.54342578921705" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2160" weight="86.90726310417038" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2161" weight="89.84041262234467" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2162" weight="82.32024600664269" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2163" weight="82.09068387603764" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2164" weight="85.45527917937406" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2165" weight="81.83638736272671" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2166" weight="85.27253461949216" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2167" weight="90.92272021618133" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="2168" weight="81.60568155572597" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2169" weight="86.43120942450201" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2170" weight="81.48395153717298" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="2171" weight="81.52862203274458" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2172" weight="84.98801935350366" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2173" weight="81.08371534163237" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2174" weight="81.39663975310705" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2175" weight="81.48313160024183" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2176" weight="80.46027756597145" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2177" weight="84.38309540091151" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2178" weight="80.71509878969458" />
      <edge source="to facilitate comparison with previous work, we created the translation tables using the same techniques as koehn et al (2003).3 " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2179" weight="84.26667356943128" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " id="2180" weight="85.60349596638301" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="2181" weight="81.23372118183023" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="2182" weight="83.61100500684834" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2183" weight="83.09182987127983" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2184" weight="83.41093388889544" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2185" weight="80.9262919320099" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2186" weight="81.65688296915141" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2187" weight="82.65891308811999" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2188" weight="82.2579236712282" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2189" weight="82.72413144705924" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2190" weight="87.06928915349216" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2191" weight="80.89938679258948" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2192" weight="83.05870756931593" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2193" weight="81.27461592241612" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2194" weight="80.97324520901708" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2195" weight="82.11951471469587" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2196" weight="80.54636494244032" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2197" weight="84.86908197909241" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2198" weight="80.89378550014752" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2199" weight="83.43360662238095" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2200" weight="80.0209228394561" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2201" weight="82.1201587140961" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2202" weight="80.2222680737761" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="2203" weight="80.8249618590248" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2204" weight="81.09553565564174" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2205" weight="80.17378794642511" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2206" weight="86.32736059053265" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2207" weight="85.61471798138139" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2208" weight="84.25615461241533" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2209" weight="87.50843451676423" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2210" weight="80.73314672056449" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2211" weight="83.43898741985218" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2212" weight="82.41302387061123" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2213" weight="82.2757471761407" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2214" weight="85.57914558548674" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2215" weight="85.48103639239571" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2216" weight="81.6331049424398" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2217" weight="81.18379065757412" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2218" weight="85.48324727671456" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2219" weight="85.8483430895693" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2220" weight="80.12443065155101" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2221" weight="86.35515155721694" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="2222" weight="80.99982109866455" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2223" weight="82.35925411222844" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2224" weight="80.846727586689" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2225" weight="84.25692506553088" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2226" weight="81.85077111201902" />
      <edge source="we used sentences of length 5-15 to facilitate comparisons with koehn et al (2003) and to enable rapid experimentation with various feature sets. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2227" weight="82.54638673272363" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the phrase-based model of koehn et al (2003) is an instance of this framework. " id="2228" weight="80.04254119822708" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="2229" weight="84.42000493596069" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="2230" weight="81.19096713653049" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="2231" weight="80.52956702211544" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2232" weight="84.53907735316457" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2233" weight="88.8039966483483" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2234" weight="84.09998144360762" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2235" weight="87.84841475033917" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2236" weight="80.35601939520942" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2237" weight="87.0691794755461" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="2238" weight="81.80877901064459" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2239" weight="87.75895858725937" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2240" weight="87.06891579759257" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2241" weight="83.34691612466332" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2242" weight="88.48561387824377" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2243" weight="87.016583741908" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="2244" weight="80.36289061824662" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2245" weight="87.72999144460036" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2246" weight="88.73547828506977" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2247" weight="85.24983817075432" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2248" weight="81.61550844883575" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2249" weight="86.62196552879627" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2250" weight="84.73270900195268" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2251" weight="88.16964892901855" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2252" weight="88.75972631120659" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2253" weight="89.47634325919663" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2254" weight="83.50323576031565" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2255" weight="82.44977899991272" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2256" weight="86.30121408894105" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2257" weight="89.0856654370581" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="2258" weight="85.76173982051071" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2259" weight="85.68090149676522" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2260" weight="84.28163967560873" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2261" weight="88.84051263847536" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="2262" weight="80.4965088685897" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2263" weight="88.01610500874584" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2264" weight="84.604355799283" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2265" weight="89.34469557889292" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2266" weight="88.02980002469873" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2267" weight="83.23432406723632" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2268" weight="83.99253180669626" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2269" weight="87.28355473685205" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2270" weight="85.08683254087757" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2271" weight="82.15666189651667" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2272" weight="89.7375482896691" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2273" weight="81.09563396432635" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="2274" weight="80.75650256495939" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2275" weight="85.2071611288302" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2276" weight="82.9973426003187" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="2277" weight="80.24457699108547" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="2278" weight="81.1302993404139" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2279" weight="86.0965123858266" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2280" weight="86.27713607033385" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2281" weight="87.68848823590267" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2282" weight="85.40760928029998" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2283" weight="85.01608858184437" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2284" weight="85.35510165289939" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="2285" weight="80.61664843879215" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2286" weight="80.8964194603799" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2287" weight="85.38466473238127" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2288" weight="84.46623576533956" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2289" weight="90.10449429807919" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="2290" weight="80.78172854111811" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="2291" weight="80.9564763538153" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2292" weight="84.73702804454666" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="for our experiments we used the following features, analogous to pharaoh's default feature set: • p(γ " id="2293" weight="80.7577515336894" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2294" weight="80.70016948253893" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="2295" weight="83.03202962849517" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2296" weight="85.60599146075715" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="2297" weight="80.3779678459357" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2298" weight="81.0022638210418" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2299" weight="81.9042430336765" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2300" weight="86.03221606373141" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2301" weight="86.98726322686258" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2302" weight="88.03970305433613" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2303" weight="83.9502045901168" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2304" weight="80.79001045544092" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2305" weight="84.77274576315199" />
      <edge source="at the end we ran our models once on test to get final numbers.2 4 models our experiments used phrase-based models (koehn et al, 2003), which require a translation table and language model for decoding and feature computation. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2306" weight="83.59505105023146" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2307" weight="81.0581450455077" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2308" weight="85.55982510950153" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="2309" weight="82.37231399734324" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="2310" weight="86.89250224425213" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="2311" weight="82.36587130869755" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2312" weight="82.19039338162833" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2313" weight="82.63289815959828" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2314" weight="82.64883747033898" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="2315" weight="85.14805658591588" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="2316" weight="83.22892681025758" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="2317" weight="81.17069380809532" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2318" weight="82.71006966280797" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="2319" weight="82.31858096428" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="2320" weight="80.9696295307986" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2321" weight="82.26391098812644" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2322" weight="81.41022565419571" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="2323" weight="84.06119488612491" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2324" weight="80.0167947386422" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="2325" weight="80.63679072592642" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="details of this model are described by koehn et al (2003). " id="2326" weight="84.4367996788324" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2327" weight="81.21744314296942" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="2328" weight="87.13813709134182" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2329" weight="80.44768077517936" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="2330" weight="84.0888456193481" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2331" weight="80.29231990172585" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2332" weight="82.10703181381014" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2333" weight="84.93371117603934" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2334" weight="81.30368445977363" />
      <edge source="we also compared our model with pharaoh (koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="2335" weight="88.58632055950906" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " id="2336" weight="82.42519845408196" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " id="2337" weight="82.36856557354784" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="2338" weight="80.55165912425117" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="2339" weight="84.22946599888424" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2340" weight="82.04747922543434" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2341" weight="83.42973954599064" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2342" weight="87.2703959471308" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="2343" weight="80.40500546650318" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2344" weight="84.2713433234353" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2345" weight="84.21764599815427" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2346" weight="85.068046865176" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2347" weight="86.83658047231721" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2348" weight="86.92722292658554" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2349" weight="90.0003689437461" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2350" weight="87.32082656146365" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2351" weight="85.03180480434476" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2352" weight="89.95839720379975" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="2353" weight="84.53621695367598" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2354" weight="82.35878219344808" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="2355" weight="82.63013278607244" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="2356" weight="80.16562772789817" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2357" weight="92.32113433810736" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2358" weight="89.37918407969197" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2359" weight="85.15646984938779" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="2360" weight="81.62316286916409" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2361" weight="86.0320980195112" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="2362" weight="82.49645705581263" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2363" weight="82.6592400377828" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2364" weight="83.79175561240635" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="2365" weight="82.79974764918683" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="2366" weight="83.2461376053159" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2367" weight="84.20126394723665" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2368" weight="84.93366969217723" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2369" weight="84.23422316765429" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2370" weight="84.90464201426833" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="2371" weight="80.13391178571952" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2372" weight="81.86464696380717" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="2373" weight="80.19135007840144" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2374" weight="80.22468838172514" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2375" weight="80.42102581646111" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2376" weight="81.72235736058215" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2377" weight="85.72005405850796" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2378" weight="84.91898020673598" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2379" weight="85.20887898902734" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2380" weight="80.63684181506086" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2381" weight="80.20206799486562" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2382" weight="80.98461171940072" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="2383" weight="81.64623593357116" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2384" weight="83.0847304343776" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2385" weight="80.03701181639022" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2386" weight="80.18938960243793" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="2387" weight="80.91876474076271" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2388" weight="80.26661243228513" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2389" weight="80.61360552597792" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2390" weight="80.6148693733609" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2391" weight="80.39157048607608" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2392" weight="80.37358958952643" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2393" weight="83.1898228082029" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="2394" weight="85.50675314683107" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2395" weight="86.57033622906395" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2396" weight="83.64903778748274" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2397" weight="81.43832408226585" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="details of this model are described by koehn et al (2003). " id="2398" weight="85.1741229005418" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="2399" weight="83.66128798619599" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2400" weight="81.20343241277028" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="2401" weight="82.2830751848879" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2402" weight="87.9255829706235" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2403" weight="80.96608653291277" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2404" weight="84.95266264359238" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2405" weight="85.53369164799254" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2406" weight="87.55448064269858" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2407" weight="84.24003490447565" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2408" weight="83.63955586483516" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2409" weight="80.74057619595048" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2410" weight="88.08094108613003" />
      <edge source="the phrase-based model of koehn et al (2003) is an instance of this framework. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="2411" weight="84.21976310959474" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2412" weight="83.49155755614089" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2413" weight="80.16706871874553" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2414" weight="81.45974170945279" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2415" weight="83.18493078862552" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2416" weight="83.31270513530518" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2417" weight="82.17054436914731" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2418" weight="84.34227252476751" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2419" weight="82.03784287555851" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2420" weight="86.70272542503518" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2421" weight="82.86459640205341" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="2422" weight="80.51038807954791" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2423" weight="83.2747937359228" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2424" weight="83.02087132524561" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2425" weight="83.6034598969394" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2426" weight="83.39206411636026" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2427" weight="80.62576450877228" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2428" weight="85.40582523658887" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2429" weight="82.29404068990537" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2430" weight="83.72408133405276" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2431" weight="83.56885203564262" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2432" weight="86.89965729943394" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2433" weight="84.18518657265588" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2434" weight="81.29071150723959" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2435" weight="82.37078699572832" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2436" weight="80.05267498393567" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2437" weight="83.13515870824797" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2438" weight="83.11322071025053" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2439" weight="84.37781707404208" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2440" weight="82.61726862795031" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2441" weight="82.00703766714597" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2442" weight="83.97522036164564" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2443" weight="81.58865571127232" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2444" weight="85.91128095110304" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2445" weight="83.84352549186715" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2446" weight="81.39893049965498" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="2447" weight="80.00612794729183" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2448" weight="84.06981535444939" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2449" weight="85.81958524605162" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2450" weight="84.20129169619617" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2451" weight="85.92539519561949" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2452" weight="81.03070870575561" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2453" weight="82.52524931840479" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2454" weight="84.69769733916044" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2455" weight="81.84947247509635" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2456" weight="80.78076820258808" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="2457" weight="80.40039862382302" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2458" weight="85.8093721251973" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2459" weight="85.79360093657434" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2460" weight="82.83844486234742" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2461" weight="85.24182144236873" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="2462" weight="81.38120289641687" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2463" weight="84.41676145154746" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2464" weight="84.06949119335785" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="2465" weight="83.32835616728073" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2466" weight="83.19082113144249" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="2467" weight="83.99315357824185" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2468" weight="83.83824745056681" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2469" weight="84.07737447326275" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2470" weight="81.0745903884021" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2471" weight="80.66676815268411" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2472" weight="80.99159325155357" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2473" weight="81.38143177210824" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2474" weight="80.44036966270917" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2475" weight="84.26936943965599" />
      <edge source="koehn et al (2003) demonstrated that choosing the appropriate heuristic for extracting phrases is very important. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="2476" weight="83.16459821001934" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " id="2477" weight="82.88691506601987" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="2478" weight="84.51184514518046" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2479" weight="84.30870156048141" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2480" weight="85.37399969970633" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2481" weight="93.55010420319199" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="2482" weight="81.25196471037216" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2483" weight="83.53917774276908" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2484" weight="81.76209438895177" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2485" weight="83.78838883047007" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="2486" weight="80.33968217039047" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2487" weight="84.46949545761045" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2488" weight="84.00979155341739" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2489" weight="85.77461132438677" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2490" weight="87.11881884579387" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2491" weight="84.00253960975735" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2492" weight="86.22467776095233" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2493" weight="84.06651644221196" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2494" weight="83.62433506657021" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="2495" weight="82.78156451225382" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="2496" weight="80.2655921985971" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2497" weight="83.77311628946455" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2498" weight="87.64391710300808" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2499" weight="87.07133582117497" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2500" weight="82.70146909119185" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="2501" weight="83.9673822571851" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2502" weight="81.76900662071603" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2503" weight="85.64523757863147" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2504" weight="83.34630358584303" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2505" weight="88.31948544933714" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2506" weight="87.77310103388064" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2507" weight="85.5250735555219" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2508" weight="85.00720152675623" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2509" weight="82.1200649645524" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2510" weight="83.91905162184156" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="2511" weight="82.37376955479002" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2512" weight="84.16955341262423" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2513" weight="81.24669275269525" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2514" weight="86.30778281228095" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="2515" weight="80.80663723739315" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="2516" weight="82.0869254179033" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2517" weight="85.5574996583914" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2518" weight="86.0045383561453" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2519" weight="87.40331493647935" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2520" weight="86.56193459895721" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2521" weight="82.44909028917233" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2522" weight="84.46894589837868" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2523" weight="83.04891457980237" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2524" weight="82.71343204982868" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2525" weight="87.07433028459623" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2526" weight="84.46752300355512" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2527" weight="80.95748670770544" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2528" weight="85.44613397135372" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2529" weight="80.6751596703056" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2530" weight="84.19969220997521" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2531" weight="81.60501022797337" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="2532" weight="83.3609229416961" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2533" weight="84.32021499475835" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2534" weight="86.27714360795238" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2535" weight="84.55201177579772" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2536" weight="86.11686295094303" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="2537" weight="81.301868274579" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2538" weight="81.7853568673367" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2539" weight="84.04464508146832" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2540" weight="82.73695381910898" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2541" weight="82.37438779283282" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="2542" weight="80.23693914834796" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2543" weight="86.07645902959906" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="2544" weight="81.8983104968247" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2545" weight="80.10655854576805" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="2546" weight="84.9015569660325" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2547" weight="87.77163670875613" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="2548" weight="82.22405987269967" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2549" weight="84.27867092293164" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="2550" weight="81.90049288086298" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2551" weight="83.14769361538397" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2552" weight="81.52787122339544" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2553" weight="82.39429675349461" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2554" weight="83.74309554254906" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2555" weight="86.09262115344154" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2556" weight="86.64119963951056" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2557" weight="80.32252641352058" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2558" weight="85.42598747914538" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2559" weight="80.1815509711712" />
      <edge source="the statistical components of our system are modeled on the phrase-based system of koehn et al (2003), and component weights are adjusted by minimum error rate training (och, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="2560" weight="82.95349436963735" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " id="2561" weight="83.05092755900993" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2562" weight="85.75781516340217" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2563" weight="82.83369028145987" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2564" weight="83.77024066695733" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2565" weight="83.78860223515838" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2566" weight="82.40293056874451" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2567" weight="86.33398913220047" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2568" weight="83.21703692590965" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2569" weight="83.9709847477599" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2570" weight="82.9107702572494" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="2571" weight="80.16802144182256" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2572" weight="80.46478895523191" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="2573" weight="81.27413457945791" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2574" weight="81.55977936335026" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2575" weight="83.5657297385477" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2576" weight="81.56034501697498" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2577" weight="80.84205200697927" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2578" weight="81.78046224251356" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2579" weight="81.98544280105085" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2580" weight="82.31610475479376" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2581" weight="81.64347767019238" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2582" weight="80.04174376083787" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2583" weight="80.52930048993726" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2584" weight="86.11226862311763" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2585" weight="81.29263857604765" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2586" weight="87.01238209765295" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2587" weight="80.62674823831013" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2588" weight="87.0937345677251" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2589" weight="82.13766561683332" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2590" weight="81.54073765633711" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2591" weight="90.27005787008528" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2592" weight="83.05883044009539" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2593" weight="83.59995984769142" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2594" weight="83.81975344036974" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2595" weight="83.07657583238048" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2596" weight="80.301970913286" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2597" weight="83.97529782015347" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2598" weight="81.83907366474503" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2599" weight="80.91715934798971" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2600" weight="81.18743492518408" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2601" weight="80.2637317137911" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2602" weight="83.94986984052754" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="2603" weight="83.20051326811296" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2604" weight="85.6204678184371" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2605" weight="81.79754600235736" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2606" weight="80.88072381546205" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2607" weight="80.75698752904523" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2608" weight="81.2069941583588" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2609" weight="82.645423677786" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2610" weight="80.10855122707893" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2611" weight="81.80602890575503" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2612" weight="81.10247202326244" />
      <edge source="final results are reported on the test set of 1,755 sentences of length 5-15 that was used in koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2613" weight="84.28695253784821" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " id="2614" weight="80.22420085980421" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2615" weight="92.51947278138279" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2616" weight="87.84511496915108" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2617" weight="82.09975468719728" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2618" weight="81.39058845660043" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2619" weight="80.19029902058237" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2620" weight="87.62073547847653" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2621" weight="86.3355763957363" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2622" weight="85.12763891370392" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2623" weight="84.64496309146705" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2624" weight="85.12147136197383" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2625" weight="81.36974747131079" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2626" weight="88.2183412342961" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2627" weight="83.05514252879591" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2628" weight="80.9908428081461" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2629" weight="84.18879413965546" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2630" weight="80.08890255509871" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2631" weight="86.78199667742837" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2632" weight="81.89455477635713" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2633" weight="86.243530310916" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2634" weight="84.39048238868511" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2635" weight="80.64724020409244" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2636" weight="83.94100903142969" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2637" weight="80.92088649609008" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2638" weight="82.67067808962021" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2639" weight="82.15483044561651" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2640" weight="83.17219647980674" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2641" weight="80.03055156921246" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2642" weight="82.94299104167398" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2643" weight="80.62128202411591" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2644" weight="82.58880091091292" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2645" weight="81.18096550211233" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2646" weight="81.10848524389964" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2647" weight="80.28548453331695" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2648" weight="80.69619589041255" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="2649" weight="88.99336014315136" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2650" weight="81.63900761628275" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2651" weight="85.6078075503129" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2652" weight="81.06598262515877" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2653" weight="81.16735217196454" />
      <edge source="under the nist measure, we achieve results in the range of the state-of-the-art phrase-based system of koehn et al (2003) for in-coverage examples of the lfgbased system. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2654" weight="80.35356467664015" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " id="2655" weight="83.36812503307793" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2656" weight="86.40719726757335" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="2657" weight="80.8048699433682" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2658" weight="82.22781209775466" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2659" weight="83.55487682017515" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2660" weight="88.87080109047878" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="2661" weight="81.31848644627007" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2662" weight="86.34588628671362" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="2663" weight="81.4605339659498" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2664" weight="85.36567422392976" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2665" weight="86.7782171049251" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2666" weight="87.01766721079807" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2667" weight="87.8007276737305" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2668" weight="88.2839002745841" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2669" weight="82.84512773578894" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="2670" weight="83.79639515668454" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="2671" weight="85.62954702300519" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2672" weight="85.78946076455382" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2673" weight="87.68138694853663" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2674" weight="81.70839321709164" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2675" weight="85.43069134374745" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="2676" weight="81.70620503279906" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2677" weight="82.67741057424199" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2678" weight="87.92508745231302" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2679" weight="86.78532832061275" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="2680" weight="80.85326667874196" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2681" weight="87.40566565638888" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2682" weight="87.35204434529622" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="2683" weight="81.68159740751602" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2684" weight="90.1050365148074" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2685" weight="83.18946625271843" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2686" weight="84.45355816266323" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2687" weight="81.49589144453626" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2688" weight="85.1471716649615" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="2689" weight="81.42278105462744" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2690" weight="85.20774006151208" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2691" weight="85.90368845349627" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2692" weight="89.63265029771286" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="2693" weight="89.89405478824149" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2694" weight="85.68280729863041" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2695" weight="87.98420897306212" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2696" weight="85.65762289578802" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2697" weight="84.46463917052891" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2698" weight="84.45197308893049" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2699" weight="85.01487211107721" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2700" weight="88.15306139016758" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2701" weight="86.74498073749402" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2702" weight="80.12484559067066" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2703" weight="87.6215433905306" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="2704" weight="82.17606625925711" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2705" weight="83.81511762062385" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2706" weight="85.76871395077094" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2707" weight="82.23019113112866" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2708" weight="82.48105258617653" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2709" weight="85.15609064571362" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="2710" weight="84.07014301062208" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2711" weight="87.82769348446865" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2712" weight="83.71261518029756" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2713" weight="85.84622516525933" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2714" weight="86.18676863755041" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2715" weight="81.73433525205087" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2716" weight="82.35591532678099" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2717" weight="85.40133898231821" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2718" weight="83.43413835163867" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="2719" weight="80.76396217868509" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="2720" weight="80.9442130137593" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="2721" weight="83.97726387277207" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2722" weight="86.17999615160743" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="2723" weight="80.60966813891719" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2724" weight="83.9736953867161" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2725" weight="86.8128132369686" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="2726" weight="80.4626342746962" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2727" weight="86.52985793291448" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="2728" weight="81.32016560907537" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2729" weight="83.8753185533182" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2730" weight="82.12851338395919" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2731" weight="83.98594601584482" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2732" weight="82.79811614389003" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2733" weight="88.20298233706458" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2734" weight="82.62580550773089" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2735" weight="83.40067048403546" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2736" weight="85.07285324510579" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2737" weight="87.27140406487186" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2738" weight="84.7961278919382" />
      <edge source="recent approaches to statistical machine translation (smt) piggyback on the central concepts of phrasebased smt (och et al, 1999; koehn et al, 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="2739" weight="85.57658721994599" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " id="2740" weight="86.17788793989081" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="2741" weight="81.01017812595678" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2742" weight="86.67673396610147" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2743" weight="82.07863089565986" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2744" weight="83.50646504784969" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2745" weight="84.1678080863602" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2746" weight="90.29723135049181" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2747" weight="85.4114652167536" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2748" weight="83.03480351700274" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2749" weight="88.57497391522166" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2750" weight="88.03609365396309" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="2751" weight="80.32537852764712" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="2752" weight="85.38132065027091" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2753" weight="88.01151965947078" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2754" weight="90.32337294673982" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2755" weight="80.3559929816869" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2756" weight="84.25555173705597" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2757" weight="83.66732858404222" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2758" weight="87.8537919332552" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2759" weight="83.48718155282957" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2760" weight="88.56937744828788" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2761" weight="87.1942098635774" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2762" weight="89.08119847350761" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2763" weight="83.42962571868482" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2764" weight="82.03040400658352" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2765" weight="86.83961212991589" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2766" weight="84.92058940433137" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="2767" weight="80.41063623730463" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2768" weight="86.53695836932964" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2769" weight="85.59264023022575" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="2770" weight="80.92231569512427" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="2771" weight="80.46051296312524" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2772" weight="87.2395622498992" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2773" weight="83.84000770920295" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2774" weight="87.97022953557186" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2775" weight="84.82994753650345" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2776" weight="85.5090365870225" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2777" weight="85.05970817609835" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2778" weight="86.52356675187673" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2779" weight="83.49462477713784" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2780" weight="83.0490187876723" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2781" weight="87.485911648978" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2782" weight="84.79830920630722" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2783" weight="83.16010069401854" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2784" weight="85.13024590646943" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2785" weight="82.2055007785619" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2786" weight="88.46874213847138" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2787" weight="87.00949405161246" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2788" weight="84.11174597818977" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2789" weight="85.72225356193795" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2790" weight="84.37320389725733" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2791" weight="84.44125894128891" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2792" weight="84.19716914058391" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2793" weight="86.1428701871773" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="2794" weight="83.20502823363785" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="2795" weight="83.49826847594149" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="2796" weight="82.85711814228354" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="2797" weight="85.05677005730152" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2798" weight="83.17510967408283" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="2799" weight="80.39415271183954" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2800" weight="82.4406784145618" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2801" weight="81.36656221014178" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2802" weight="80.32679997048055" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2803" weight="82.52857597656514" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2804" weight="85.22891126389834" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2805" weight="84.00425863288538" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2806" weight="82.62542203731678" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="2807" weight="85.45447806909456" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2808" weight="81.60070419689178" />
      <edge source="in an experimental evaluation on the test-set that was used in koehn et al (2003) we show that for examples that are in coverage of the grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation measures. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2809" weight="85.10690424929584" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " id="2810" weight="81.10058427675717" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2811" weight="83.89578888290232" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2812" weight="81.04319570397335" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2813" weight="83.63765015634992" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="2814" weight="80.24719924199482" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2815" weight="86.66614548176345" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="2816" weight="80.05165096455569" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2817" weight="86.11573691088776" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2818" weight="89.58367796053876" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2819" weight="89.91418946447611" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2820" weight="86.52517887696823" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2821" weight="86.9981194637648" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2822" weight="86.70998536980488" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="2823" weight="81.50570827530652" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2824" weight="83.1790033561226" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="2825" weight="81.06950068372302" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="2826" weight="81.18828001334954" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2827" weight="83.76060167405926" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2828" weight="91.08976620428832" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2829" weight="87.36581939566742" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2830" weight="83.85660313522007" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="2831" weight="86.16035529285836" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2832" weight="81.78826163784325" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2833" weight="86.20259879681417" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2834" weight="85.44291922794412" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2835" weight="89.34510010797196" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2836" weight="86.67039999097246" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2837" weight="88.22135981250587" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2838" weight="82.49713892757988" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2839" weight="84.47251503905728" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2840" weight="83.0201598180494" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2841" weight="85.74462401807897" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="2842" weight="80.78710878532252" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="2843" weight="81.23620699438273" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="2844" weight="83.60768518933843" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2845" weight="82.54927924682116" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2846" weight="86.83607416772372" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="2847" weight="83.1055253578111" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2848" weight="84.50174792455098" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2849" weight="86.0206518883003" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2850" weight="87.17774719018591" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2851" weight="87.48703575923615" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2852" weight="81.12780705204233" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2853" weight="87.1403801066559" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2854" weight="85.92500678156594" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2855" weight="82.8513691560141" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2856" weight="86.8302024058853" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2857" weight="83.82699555348158" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2858" weight="82.5948645355413" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="2859" weight="80.66206359262449" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2860" weight="86.17594901843293" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="2861" weight="85.34736502223834" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2862" weight="81.0267977014956" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2863" weight="84.09230475009015" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="2864" weight="82.91120851565653" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2865" weight="84.14393902132598" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2866" weight="84.50236697587489" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2867" weight="82.72513472295297" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2868" weight="86.17447060855137" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2869" weight="85.2287715687259" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2870" weight="84.62088812453192" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="2871" weight="81.29755782082147" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="2872" weight="84.93302702390291" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="2873" weight="80.73955098835653" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2874" weight="85.69252641532591" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="2875" weight="82.07776877698234" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="2876" weight="86.38379060379306" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2877" weight="89.15297705103708" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="2878" weight="83.92177748360376" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2879" weight="82.23167657603052" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2880" weight="82.89070117703923" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2881" weight="81.3400789008939" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2882" weight="83.84398210141141" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2883" weight="82.62056479703578" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2884" weight="85.63667345211819" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2885" weight="87.56019910266045" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2886" weight="80.59214472692531" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2887" weight="84.00501469354182" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="2888" weight="83.50445656986463" />
      <edge source="the statistical components of our system are modeled on the statistical components of the phrase-based system pharaoh, described in koehn et al (2003) and koehn (2004). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="2889" weight="84.33236337789604" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " id="2890" weight="81.6137645016847" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " id="2891" weight="82.22703033110392" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2892" weight="85.40591314631847" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="2893" weight="84.10476606571946" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2894" weight="90.200915322949" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="2895" weight="84.41129893579091" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2896" weight="82.9312817794436" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2897" weight="81.26106726977105" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2898" weight="84.0052856778059" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2899" weight="86.44401570262947" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="2900" weight="80.82197690441653" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="2901" weight="83.06852446953985" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="2902" weight="84.24546321295443" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2903" weight="86.22578836361994" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2904" weight="84.92156815848413" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2905" weight="81.541759434307" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="2906" weight="83.27610148906514" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2907" weight="86.37894459530173" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2908" weight="81.04601706775851" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2909" weight="80.93283213083208" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="2910" weight="80.19501349291833" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="2911" weight="80.72142877265196" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="2912" weight="81.31150213463756" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="2913" weight="84.95813308704561" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2914" weight="80.17340046377561" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2915" weight="89.08775029132303" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="2916" weight="82.85211931532272" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="2917" weight="82.07319661898926" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2918" weight="81.0102560242756" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2919" weight="81.59955804633829" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2920" weight="81.7105951126839" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2921" weight="84.03632078005485" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2922" weight="81.64214843998894" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="2923" weight="80.13654818080124" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2924" weight="80.95457788732922" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2925" weight="83.34196929420288" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2926" weight="81.05231173476145" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="2927" weight="80.23414556583393" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="2928" weight="83.26639102658461" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="2929" weight="80.20883501311766" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="2930" weight="82.12001527620185" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="2931" weight="82.62130582055607" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="2932" weight="82.78251635168216" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="2933" weight="81.63085426954397" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="2934" weight="80.33125412095599" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="2935" weight="82.15092319811363" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="2936" weight="86.77747215833675" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="2937" weight="82.91908046025019" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="2938" weight="80.8785357956618" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="2939" weight="82.73028693486486" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="2940" weight="85.88089714940898" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="2941" weight="84.54804507968197" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="2942" weight="83.90351807760035" />
      <edge source="phrase-based smt systems have been shown to outperform word-based approaches (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="2943" weight="80.84219228750753" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="2944" weight="82.89255403908624" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="2945" weight="87.9286282284304" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="2946" weight="83.24063017615173" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="2947" weight="81.32177990460295" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="2948" weight="86.38058070559664" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="2949" weight="85.46275958210867" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="2950" weight="84.6977999951938" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="2951" weight="87.87366743527389" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="2952" weight="86.25137758381128" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="2953" weight="81.22855554285728" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="2954" weight="81.82441232439945" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="2955" weight="82.05100642363303" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="2956" weight="83.09249937063865" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="2957" weight="82.8705454492608" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="2958" weight="88.25115451970254" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="2959" weight="86.71569278638313" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="2960" weight="81.05640761424564" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="2961" weight="86.27087604125092" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="2962" weight="80.51364328208489" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="2963" weight="81.4310040606196" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="2964" weight="88.85397764137488" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="2965" weight="88.4218101210152" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="2966" weight="90.97954669327855" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="2967" weight="91.72263286695403" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="2968" weight="84.16657913302006" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="2969" weight="80.63805161365882" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="2970" weight="82.091566167021" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="2971" weight="89.66961026164195" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="2972" weight="90.41030616110952" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="2973" weight="83.02272239368207" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="2974" weight="88.18331811296866" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="2975" weight="84.55606926836457" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="2976" weight="85.9203251629517" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="2977" weight="80.99240591550671" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="2978" weight="87.39594255957117" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="2979" weight="81.13036224030697" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="2980" weight="89.15604329311113" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="2981" weight="88.2045134051371" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="2982" weight="89.99832189054911" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="2983" weight="89.4406494521483" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="2984" weight="84.06536723821772" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="2985" weight="87.92483533518633" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="2986" weight="87.06374141211846" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="2987" weight="88.29704189276694" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="2988" weight="82.17801367015043" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="2989" weight="84.84305671019723" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="2990" weight="87.93147207549639" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="2991" weight="82.95147686987401" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="2992" weight="86.33792494868256" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="2993" weight="85.79133631304342" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="2994" weight="80.3641552766853" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="2995" weight="85.31067746356197" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="2996" weight="86.2717155553126" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="2997" weight="83.88622694319416" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="2998" weight="85.46285115267465" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="2999" weight="87.91798093822783" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="3000" weight="81.40160356811525" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3001" weight="86.18770705062589" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3002" weight="88.66042816150788" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3003" weight="88.19072139048411" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="3004" weight="86.75358306933364" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3005" weight="81.70095587478936" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3006" weight="86.96705788262724" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3007" weight="84.90813005188478" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="3008" weight="80.98119539096895" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3009" weight="88.6473527066562" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="3010" weight="82.20011768990891" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="3011" weight="84.00582038747055" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3012" weight="89.57994692807335" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3013" weight="84.0242276162377" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="3014" weight="82.81384163988213" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3015" weight="85.5882677189379" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="3016" weight="86.16378629113841" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3017" weight="88.83883937256122" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3018" weight="84.47820723344786" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3019" weight="83.25457787300535" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3020" weight="88.99201088276602" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3021" weight="86.52076143529874" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3022" weight="85.04522898839359" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="3023" weight="86.77439853018221" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3024" weight="81.85959482141976" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3025" weight="80.40087551321716" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3026" weight="88.32328335783468" />
      <edge source="a phrase-based translation model can be estimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3027" weight="84.02698156953878" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " id="3028" weight="84.44591972320119" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="3029" weight="89.63280770262334" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="3030" weight="86.25555665558535" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="3031" weight="85.67214785879781" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="3032" weight="91.2279065235956" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="3033" weight="81.00961232478767" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3034" weight="82.55944800091497" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3035" weight="80.0227790122293" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3036" weight="84.66121065281578" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3037" weight="80.22841782462574" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="3038" weight="81.00604756542691" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3039" weight="84.27692075897262" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3040" weight="86.72460791605354" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3041" weight="88.58971005585161" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3042" weight="85.3600731906082" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3043" weight="83.78706327701373" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3044" weight="87.27566212285798" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="3045" weight="86.57227488152608" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3046" weight="86.65959122627791" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3047" weight="82.30819732357124" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3048" weight="83.30760977001279" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3049" weight="81.30063156392058" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3050" weight="83.90759190863193" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="3051" weight="86.56979028059395" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3052" weight="82.3625523554606" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3053" weight="90.29612799235069" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3054" weight="81.54705511319891" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3055" weight="84.78872493636544" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3056" weight="91.84228457504288" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3057" weight="87.72990288821916" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3058" weight="80.58616165711467" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3059" weight="83.39179826797627" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="3060" weight="86.37309856754331" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3061" weight="87.9338983333452" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3062" weight="80.75768502645089" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3063" weight="89.60650805770649" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3064" weight="82.20462632099262" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3065" weight="87.87166333076262" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="3066" weight="81.72497926829803" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3067" weight="80.79388117392534" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3068" weight="85.28136964781024" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3069" weight="83.44597301164146" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3070" weight="81.1774958778753" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3071" weight="80.05931013284776" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3072" weight="86.73932890326064" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3073" weight="81.98871474955534" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="3074" weight="80.72584130090765" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3075" weight="89.01227060260686" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3076" weight="84.42118152980981" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3077" weight="83.10179192239877" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3078" weight="87.05300869054635" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3079" weight="89.84542159535896" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3080" weight="86.23730660471665" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3081" weight="82.74952666769973" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3082" weight="89.97014309337388" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3083" weight="87.5519950495279" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3084" weight="92.36009142381513" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3085" weight="86.37112918916854" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3086" weight="85.71401609532853" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3087" weight="91.08343893693093" />
      <edge source="today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (koehn et al, 2003; zens and ney, 2004; och and ney, 2003). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="3088" weight="82.72665309045829" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " id="3089" weight="80.06884270503618" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="3090" weight="82.24163031011472" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3091" weight="84.89623449274117" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3092" weight="80.35185101191986" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3093" weight="84.07057456231352" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="3094" weight="81.80389662075204" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3095" weight="80.74264644139674" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3096" weight="82.76803400827497" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3097" weight="89.08642239662889" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3098" weight="81.44805488072555" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="3099" weight="81.43787587888336" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3100" weight="81.1766575238089" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3101" weight="81.94802679364585" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="3102" weight="80.23376087834191" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3103" weight="80.35048622766709" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3104" weight="88.96091997429856" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3105" weight="81.29456707656688" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " id="3106" weight="81.02698726683757" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3107" weight="80.4359808694198" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3108" weight="85.04011545597925" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="3109" weight="80.34297258868696" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3110" weight="84.78910739885734" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3111" weight="83.70536048007997" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3112" weight="83.38171406514662" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3113" weight="86.37928787641775" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3114" weight="81.21258291024765" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3115" weight="89.05704848025655" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3116" weight="81.27296112362157" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="3117" weight="87.12220009737581" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3118" weight="81.84087052442013" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3119" weight="87.82457684069011" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3120" weight="81.57421524683437" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3121" weight="84.0185383794636" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3122" weight="82.48950192166664" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3123" weight="84.07154673264384" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="3124" weight="81.66584521951266" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3125" weight="82.27217748043793" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3126" weight="83.93006427851262" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3127" weight="81.12356334089996" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3128" weight="80.4295120775605" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3129" weight="86.4116421778699" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3130" weight="84.10605427485824" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3131" weight="88.36091119004654" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3132" weight="86.11411892250777" />
      <edge source="we collect bidirectional (bi) refined word alignment by growing the intersection of chinese-to-english (ce) alignments and english-to-chinese (ec) alignments with the neighboring unaligned word pairs which appear in the union similar to the final-and� approaches (koehn, 2003; och and ney, 2003; tillmann, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3133" weight="81.69385812065417" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " id="3134" weight="91.60128022193837" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="3135" weight="88.29782778242125" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="3136" weight="88.98079385383821" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="3137" weight="83.45386972227527" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="3138" weight="85.51943052463673" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3139" weight="85.42180715391254" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3140" weight="83.75576767019692" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3141" weight="88.76511148512006" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3142" weight="87.54651543385879" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="3143" weight="82.36888097164376" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="3144" weight="80.1602825269551" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3145" weight="85.29244207533284" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3146" weight="88.64061926513631" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3147" weight="87.62160908950302" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3148" weight="86.13380803945041" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3149" weight="83.91621418585791" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3150" weight="88.71921069019761" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3151" weight="84.25086545799101" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3152" weight="89.66228280508584" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="3153" weight="82.27194841680546" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="3154" weight="85.27196146090468" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3155" weight="90.19375491251058" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3156" weight="82.84206019648346" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3157" weight="83.26907625837237" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3158" weight="87.6327072916248" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3159" weight="89.30852542972522" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3160" weight="87.61937528194343" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3161" weight="84.54068560812654" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3162" weight="80.94863500590188" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3163" weight="90.12004138377058" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="3164" weight="84.41014869630912" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3165" weight="92.12275007912514" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="3166" weight="80.72685505836776" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3167" weight="84.69966818181337" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="3168" weight="80.6573653375239" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3169" weight="85.30931425820145" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="3170" weight="82.27735949865153" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="3171" weight="84.56595723078932" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3172" weight="88.00704487263911" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3173" weight="81.34063331679859" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3174" weight="90.42040576078143" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3175" weight="85.61837895095721" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3176" weight="91.01727104902895" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3177" weight="87.07817730652987" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3178" weight="89.12865810715833" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3179" weight="82.76417859628786" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3180" weight="83.73822509275905" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3181" weight="84.96119059809182" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3182" weight="84.79177177976767" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3183" weight="85.73486782053223" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3184" weight="84.2099400289499" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="3185" weight="82.80299645707801" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3186" weight="83.2754252318112" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3187" weight="90.38963125809896" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="3188" weight="81.60847285533355" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3189" weight="85.80190389539798" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3190" weight="86.4679288907994" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3191" weight="87.00175123182355" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3192" weight="83.61042119184847" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3193" weight="86.98353205930856" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3194" weight="87.01132631273032" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="3195" weight="80.13574528505262" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3196" weight="86.80538282874191" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3197" weight="86.89934957333132" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3198" weight="87.04269611494291" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="3199" weight="82.36827061147636" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3200" weight="82.60415576198821" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3201" weight="83.72888083196379" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3202" weight="83.26295759732898" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="3203" weight="80.07643778744504" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3204" weight="86.38010676752626" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3205" weight="88.0030526443075" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="3206" weight="80.90782901239973" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3207" weight="87.81528959659934" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3208" weight="84.9249069959144" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3209" weight="85.5152861505183" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3210" weight="83.514840007885" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="3211" weight="81.30278883457393" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3212" weight="89.3132847520236" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3213" weight="87.0639003568844" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="3214" weight="82.7647332580294" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3215" weight="89.8137566501084" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3216" weight="88.33544370946436" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3217" weight="89.19014097546261" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3218" weight="88.12393035748445" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3219" weight="93.69117264093268" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3220" weight="90.71735306937916" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="3221" weight="86.33007924428642" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3222" weight="92.37580877045457" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3223" weight="89.1337830784164" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3224" weight="84.80802647599009" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="3225" weight="80.56845562876596" />
      <edge source="currently, the most successful such systems employ so-called phrase-based methods that translate input text by translating sequences of words at a time [och, 2002; zens et al, 2002; koehn et al, 2003; vogel et al, 2003; tillmann, 2003] phrase-based machine translation systems make use of a language model trained for the target language and a translation model trained from a parallel corpus. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3226" weight="85.83260140173661" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " id="3227" weight="87.57313806889566" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="3228" weight="88.75140666212762" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="3229" weight="82.19066422931643" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3230" weight="81.66381977737754" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3231" weight="83.21014583588438" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3232" weight="83.63426454257134" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3233" weight="85.98519553142216" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3234" weight="84.12686175455266" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3235" weight="86.52628035690225" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3236" weight="85.31658854580999" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3237" weight="83.93633398848164" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3238" weight="82.81061502160429" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="3239" weight="83.73643460241664" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3240" weight="83.85394587711477" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3241" weight="80.90122902002025" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3242" weight="84.09426965103866" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3243" weight="81.63668754071642" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3244" weight="80.55845184656675" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3245" weight="81.92259713761312" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3246" weight="89.08537878720611" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3247" weight="80.3485976866451" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3248" weight="80.88957026939102" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3249" weight="85.09220027458836" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3250" weight="81.23043347661056" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3251" weight="81.32735961860418" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3252" weight="81.87566527174421" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3253" weight="83.73707584838638" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3254" weight="81.31697290843043" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3255" weight="82.68879166604464" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3256" weight="80.4859799922028" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3257" weight="81.02273207088757" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3258" weight="80.60982887625829" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3259" weight="81.5399128796438" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3260" weight="82.95011295500854" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3261" weight="81.17658842033113" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3262" weight="82.30207060124646" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3263" weight="83.99945936888254" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3264" weight="81.40487147547202" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3265" weight="84.09647884640647" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3266" weight="86.14653387188001" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3267" weight="80.77025117475148" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3268" weight="88.18276456116479" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3269" weight="88.56026843396417" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3270" weight="90.13070518572641" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3271" weight="84.77599069804536" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="3272" weight="81.50840462038991" />
      <edge source="we carry out experiments using a phrase-based statistical machine translation system [koehn et al, 2003; koehn, 2004]. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3273" weight="81.74264525198214" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " id="3274" weight="89.38109667408467" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="we use the model of koehn et al (2003) as a baseline for our experiments. " id="3275" weight="82.21269002488201" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="3276" weight="80.64450988331906" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3277" weight="89.92774090157415" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3278" weight="86.29140500702835" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3279" weight="85.61225441448808" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3280" weight="84.28874631957237" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="3281" weight="83.50899630291977" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="3282" weight="80.21524474362994" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3283" weight="87.10699614283439" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3284" weight="84.90313521275286" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3285" weight="85.66674899300412" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3286" weight="91.29714840492538" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3287" weight="88.97462921555514" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3288" weight="90.015940632351" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3289" weight="85.7953797830493" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="3290" weight="88.74883203125205" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3291" weight="87.27915799763484" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3292" weight="86.06382107568393" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3293" weight="84.39427419767813" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3294" weight="84.48991943845574" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="3295" weight="85.13983316675007" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3296" weight="84.45453823089697" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3297" weight="83.72150328861656" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3298" weight="88.97627681777738" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3299" weight="83.67897220284337" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3300" weight="90.42668896538954" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3301" weight="80.63550669796959" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3302" weight="92.5212447114987" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3303" weight="83.92460936959924" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3304" weight="83.7079062955817" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3305" weight="87.12957136319986" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3306" weight="80.05356162685413" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3307" weight="85.36165351520914" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="3308" weight="81.3085436851129" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3309" weight="83.60463152101228" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3310" weight="83.98265666169577" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="3311" weight="80.0186010776591" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3312" weight="85.31676910544002" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3313" weight="81.70241307903264" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3314" weight="80.37855674923532" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3315" weight="85.90140554006724" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3316" weight="80.1398902678766" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="3317" weight="82.74070976776919" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3318" weight="80.02055370528358" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3319" weight="88.90488955669507" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3320" weight="88.10462483035666" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3321" weight="85.54237263848714" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3322" weight="85.51079306480906" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3323" weight="83.50756815624165" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3324" weight="84.59189690866017" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3325" weight="82.61416080787343" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3326" weight="84.31537905853081" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="3327" weight="84.73848798252202" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3328" weight="85.01486327452183" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="3329" weight="85.38837785455291" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3330" weight="86.49305605833759" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="3331" weight="83.16746525278191" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="details of this model are described by koehn et al (2003). " id="3332" weight="80.7330644242447" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3333" weight="84.79255392581528" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3334" weight="85.84901562166674" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3335" weight="80.25348767590552" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3336" weight="85.26332998256876" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3337" weight="87.54740442815239" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3338" weight="85.44582873323591" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3339" weight="85.15094998027553" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3340" weight="82.84784389590918" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3341" weight="91.46971019572005" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3342" weight="84.60494442572492" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3343" weight="86.55065542083283" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3344" weight="83.54156096971899" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3345" weight="91.27695690178086" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3346" weight="88.41331304973605" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3347" weight="86.39925674579976" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3348" weight="86.27054281885478" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3349" weight="82.75234676299846" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="3350" weight="81.02820457592894" />
      <edge source="during the last decade, statistical machine translation (smt) systems have evolved from the original word-based approach (brown et al, 1993) into phrase-based translation systems (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3351" weight="84.24966179491304" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3352" weight="81.4304493804098" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3353" weight="81.00825015142318" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3354" weight="80.13505187842101" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3355" weight="82.62244447088653" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3356" weight="91.3254022802815" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3357" weight="89.53685111523014" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3358" weight="93.30539209628277" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3359" weight="83.78628120950901" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3360" weight="87.4193393653916" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3361" weight="84.08475937387749" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="3362" weight="92.61326967521416" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3363" weight="81.50230994164404" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3364" weight="87.58082886317207" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3365" weight="86.17250437782423" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3366" weight="80.17077268622563" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="3367" weight="89.22078899963641" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3368" weight="93.22090673662744" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3369" weight="83.0600892027911" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3370" weight="89.23745997771837" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3371" weight="81.57254573024775" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="3372" weight="83.0537466893544" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3373" weight="81.45863411600655" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3374" weight="85.48809194393563" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3375" weight="86.4391218903266" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3376" weight="88.1020708658603" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3377" weight="85.73026757481183" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3378" weight="81.40803653987254" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3379" weight="83.38610418817476" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3380" weight="82.15315661008842" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3381" weight="85.4654832877907" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3382" weight="85.48414746960391" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3383" weight="84.62359032328683" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3384" weight="87.42326838934551" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3385" weight="90.3562252474774" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3386" weight="86.31054179118789" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3387" weight="86.08581926040284" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3388" weight="87.58093323923899" />
      <edge source="in recent years, phrase-based systems for statistical machine translation (och et al, 1999; koehn et al, 2003; venugopal et al, 2003) have delivered state-of-the-art performance on standard translation tasks. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="3389" weight="90.93144491957376" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " id="3390" weight="87.53835007184374" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3391" weight="85.89900475684014" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3392" weight="80.25519537691146" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3393" weight="87.51145524984436" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3394" weight="86.37162593937542" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3395" weight="84.70993007974157" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3396" weight="84.08229093691195" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3397" weight="83.22493698221946" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="3398" weight="81.06904467659497" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3399" weight="80.44255838819004" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3400" weight="80.9386913110043" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3401" weight="90.6262697796648" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3402" weight="86.69292397606863" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3403" weight="83.88099360300276" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="3404" weight="81.98788122576089" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3405" weight="84.02839466711636" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3406" weight="83.77710965243517" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3407" weight="80.54298207395061" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3408" weight="81.35631172895114" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3409" weight="81.65307542221667" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3410" weight="80.91258866639417" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3411" weight="84.09466414771063" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="3412" weight="83.00128650405232" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3413" weight="83.95791003202322" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="3414" weight="81.90556073638768" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3415" weight="89.2459239239189" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="3416" weight="85.77247497834722" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3417" weight="85.16453231437045" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3418" weight="82.52396383340997" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3419" weight="87.25152125139645" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3420" weight="83.01148814366177" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3421" weight="80.55845230158627" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3422" weight="84.63540306272176" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3423" weight="87.48643797553271" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3424" weight="82.1375189125868" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3425" weight="89.09105213797616" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="3426" weight="85.68912031222699" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3427" weight="82.46171704428727" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="3428" weight="82.1849056341241" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="3429" weight="87.03974826543912" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3430" weight="83.01052591759175" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3431" weight="83.43414897657821" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3432" weight="82.31039655739477" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3433" weight="85.1335875080107" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3434" weight="83.51997262662267" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3435" weight="81.491804704552" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3436" weight="82.62472521968178" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3437" weight="83.78832484090468" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3438" weight="81.68199222121974" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="details of this model are described by koehn et al (2003). " id="3439" weight="83.92339910159356" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3440" weight="86.58318698640551" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="3441" weight="80.9517801056709" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3442" weight="87.25665194731147" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3443" weight="83.88604977965974" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3444" weight="85.77207763001411" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3445" weight="81.37756554035221" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3446" weight="81.12376690542457" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3447" weight="83.3859008838385" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3448" weight="80.28991788589872" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3449" weight="84.02374801688663" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3450" weight="87.07340690846337" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3451" weight="82.48848363717667" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3452" weight="85.30509155177195" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="3453" weight="83.93945407560442" />
      <edge source="we use the model of koehn et al (2003) as a baseline for our experiments. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3454" weight="80.29607465339694" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " id="3455" weight="85.42004923920491" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3456" weight="83.62258621294929" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3457" weight="87.8342294737926" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3458" weight="90.44596393224165" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="3459" weight="80.11553526028938" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="3460" weight="80.88124696351015" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3461" weight="81.4838773824596" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3462" weight="80.31320601576499" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="3463" weight="83.54226574880923" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3464" weight="86.65749662275834" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3465" weight="90.70691145862786" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3466" weight="83.72228044373801" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3467" weight="84.93025764286597" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="3468" weight="85.12322797606937" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3469" weight="88.16386464093213" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3470" weight="85.20924802911205" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3471" weight="88.073215466199" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3472" weight="89.0453016684185" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3473" weight="89.24590643014518" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="3474" weight="85.84540287345528" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3475" weight="83.71957497649778" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="3476" weight="87.28291621501567" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3477" weight="86.84455807704963" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="3478" weight="86.1981543736767" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3479" weight="85.99011148158138" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3480" weight="82.52069615570296" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3481" weight="86.51987201863938" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3482" weight="85.79229176738757" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3483" weight="85.93511247492933" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3484" weight="85.29400773621036" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3485" weight="85.00396124351752" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3486" weight="86.13692333419469" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3487" weight="87.63759956973489" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3488" weight="88.19406373103138" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3489" weight="80.41960267517747" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3490" weight="87.2005645048888" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3491" weight="84.69930355360016" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3492" weight="83.13058833876785" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="3493" weight="84.81761983904823" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="3494" weight="85.27141516016516" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3495" weight="88.89565105004398" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3496" weight="86.53506996450007" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3497" weight="83.15883703363396" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3498" weight="84.34115821959962" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3499" weight="86.0536079135174" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3500" weight="86.12421953019779" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3501" weight="81.17100277452887" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3502" weight="84.91078787263788" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3503" weight="81.2579898835807" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3504" weight="80.23885975440737" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3505" weight="85.85210893634468" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="3506" weight="80.56674729706617" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="3507" weight="81.00852503630807" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3508" weight="83.26654439769261" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3509" weight="82.61668345138327" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3510" weight="85.38659819755978" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="3511" weight="82.09455657862723" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3512" weight="83.84296484659896" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3513" weight="80.98688867323163" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3514" weight="80.68599270681966" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3515" weight="83.960699996596" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3516" weight="85.15362973449719" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3517" weight="86.4965580004849" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3518" weight="83.00087383166901" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="3519" weight="84.64376581172823" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3520" weight="81.65673987877462" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3521" weight="83.1873476384009" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3522" weight="83.96712936628825" />
      <edge source="evaluation in terms of both bleu scores and human judgments shows that our system performs similarly to the phrase-based model of koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3523" weight="80.11786965032974" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " id="3524" weight="89.47313444450825" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3525" weight="93.10066688232746" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3526" weight="88.97461826739065" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="3527" weight="86.54416104826785" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="3528" weight="80.23849793110259" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3529" weight="84.334867351862" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3530" weight="81.00798774642067" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3531" weight="83.36927397188987" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3532" weight="84.68424207203846" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3533" weight="93.36007087255173" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3534" weight="88.99684512434736" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3535" weight="86.23646492610284" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="3536" weight="82.61481738887548" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3537" weight="88.03205883864177" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3538" weight="85.11958058211616" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3539" weight="82.76560705320347" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3540" weight="89.69107664471319" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3541" weight="85.60464031030295" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="3542" weight="80.73572894274275" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3543" weight="81.97338085630523" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3544" weight="81.66193977484781" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3545" weight="86.71259929938006" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3546" weight="87.57110959202497" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="3547" weight="82.7483373654761" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3548" weight="85.32889349817607" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="3549" weight="81.67009360597332" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3550" weight="84.12330198711948" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="3551" weight="82.68283846226254" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3552" weight="84.86815975246739" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="3553" weight="81.31919481362982" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="3554" weight="81.74921371487483" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3555" weight="89.06687217783194" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3556" weight="85.75995572207573" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3557" weight="86.20108257738362" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " id="3558" weight="82.25121733084086" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3559" weight="86.49883283887694" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3560" weight="86.31961246689042" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3561" weight="89.09904845619879" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3562" weight="88.99554676600043" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3563" weight="81.04128917424731" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3564" weight="89.59538803689584" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3565" weight="86.34800960395037" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3566" weight="84.86389545781776" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3567" weight="87.26126992665894" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3568" weight="84.55466769123692" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="3569" weight="81.2943689419746" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3570" weight="82.08467985487083" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="3571" weight="80.3710474663208" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3572" weight="89.32920353693862" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="3573" weight="81.03103656091315" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3574" weight="82.24414178223138" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3575" weight="83.8246430078331" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="3576" weight="80.70992977133909" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3577" weight="84.32813657015366" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3578" weight="90.32855386519863" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3579" weight="84.63163746533394" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3580" weight="85.47099186422793" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3581" weight="83.77526103748917" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3582" weight="83.51920493753508" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3583" weight="85.1944213944893" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3584" weight="85.03679282712267" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="3585" weight="80.14234249702676" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3586" weight="81.97794687465223" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3587" weight="86.65200927754427" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="3588" weight="80.37239521193133" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="details of this model are described by koehn et al (2003). " id="3589" weight="81.91382210179974" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3590" weight="84.34029338530009" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3591" weight="87.61316422748327" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="3592" weight="83.07261629455644" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3593" weight="82.72915059003338" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3594" weight="85.09736914108798" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3595" weight="91.3989597624991" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3596" weight="80.2848635785135" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3597" weight="85.27582418456454" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3598" weight="81.10490247035446" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3599" weight="89.30711917708814" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3600" weight="84.82640315847847" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3601" weight="87.02852811591953" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3602" weight="84.4806147132908" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3603" weight="87.99447977555891" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3604" weight="85.64118342512019" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3605" weight="80.44377607556892" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3606" weight="82.24690547943668" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3607" weight="88.77416238856021" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="3608" weight="80.06922547270585" />
      <edge source="in this paper, we implement the translation of modifiers (step 3) with the phrase-based system of koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3609" weight="84.33418241840162" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " id="3610" weight="86.54804823048974" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3611" weight="87.03823016137615" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="3612" weight="84.92277066483567" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3613" weight="82.11497272178457" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3614" weight="87.21330378288363" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3615" weight="87.88397881090188" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="3616" weight="81.53415313382379" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3617" weight="85.3709620399975" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3618" weight="85.36032160117185" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3619" weight="81.26412401867394" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="3620" weight="82.47476241916974" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3621" weight="83.533402207482" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3622" weight="81.14485669405262" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3623" weight="84.73761800067827" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="3624" weight="82.03334547584737" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3625" weight="85.27593717801514" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3626" weight="81.23403794407568" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3627" weight="81.13002080935526" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3628" weight="81.32523658249305" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3629" weight="82.39074308139259" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3630" weight="82.31606306965924" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3631" weight="81.79576423009208" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3632" weight="80.89452524212885" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3633" weight="85.72754480424682" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3634" weight="80.70248446353028" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3635" weight="80.79420777593376" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3636" weight="82.06811452878273" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3637" weight="82.73939668572925" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3638" weight="80.20795251728879" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3639" weight="82.8223327898127" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3640" weight="80.52488729417186" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3641" weight="83.87026111653817" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3642" weight="82.75182228412179" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="3643" weight="80.16374497273407" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3644" weight="86.23686364721675" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3645" weight="81.87968395877658" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="details of this model are described by koehn et al (2003). " id="3646" weight="82.11286906948172" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3647" weight="81.41237003792992" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3648" weight="82.02811559869741" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3649" weight="80.54954351867126" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3650" weight="81.80997856011084" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3651" weight="86.38762345875462" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3652" weight="84.1991804059828" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3653" weight="83.52357248719532" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3654" weight="87.34411202134112" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3655" weight="82.05426876977423" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3656" weight="85.83344078280237" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3657" weight="82.0846858453967" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3658" weight="80.18702422460827" />
      <edge source="each list contained the n-best translations produced by the phrase-based system of koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3659" weight="83.0458585498629" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " id="3660" weight="87.6878795621198" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="3661" weight="83.91562603425002" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." id="3662" weight="81.66728461290826" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " id="3663" weight="84.19178070838036" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " id="3664" weight="80.8901783674767" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3665" weight="88.21457998746416" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3666" weight="81.96802825585445" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3667" weight="80.7117849207919" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="3668" weight="82.61678061998612" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3669" weight="80.09767332822805" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3670" weight="88.1563441435643" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3671" weight="92.84327509286456" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3672" weight="85.43819121447488" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3673" weight="87.80659643343607" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="3674" weight="81.03143534913629" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="3675" weight="82.50315050130314" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="3676" weight="83.8188791750121" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3677" weight="90.44666602223201" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3678" weight="88.68723083188247" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3679" weight="81.71847756303696" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3680" weight="91.58779913581529" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3681" weight="88.07334511816438" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="3682" weight="82.34692259796456" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3683" weight="84.63421999318881" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3684" weight="83.02201646393807" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3685" weight="81.60573069336454" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3686" weight="90.67880048349227" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="3687" weight="84.54125923712306" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3688" weight="88.26251306666796" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="3689" weight="85.03094246106406" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3690" weight="87.87139505731155" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="3691" weight="85.48678550601645" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3692" weight="82.66086494886167" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="3693" weight="85.97514061047913" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="3694" weight="85.10970872350609" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3695" weight="89.75087153965491" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3696" weight="86.64687853419446" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3697" weight="84.71484477984923" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3698" weight="89.3438380898619" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3699" weight="89.789320453144" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3700" weight="91.17616335604761" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3701" weight="89.51717430728169" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3702" weight="86.89583749750618" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3703" weight="88.22839521522485" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3704" weight="90.04814453297149" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3705" weight="88.41216831410492" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3706" weight="85.85551928763554" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3707" weight="88.1356653915124" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="3708" weight="80.27769341233683" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3709" weight="86.55714608968586" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="3710" weight="81.16906143068496" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3711" weight="89.88627899966556" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="3712" weight="84.97804577475453" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="3713" weight="83.44570037230785" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3714" weight="87.65157615013324" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3715" weight="83.76284053081096" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="3716" weight="82.35774245089166" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3717" weight="90.55026977541063" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3718" weight="90.31630226247485" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3719" weight="88.45845546168603" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3720" weight="87.56293752569964" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="3721" weight="84.68145382624968" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3722" weight="85.69986072743487" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3723" weight="86.48791251186887" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3724" weight="82.7104614451398" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="3725" weight="80.1215025786945" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3726" weight="83.59988094400302" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3727" weight="85.55570204976128" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3728" weight="86.53304308739101" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="3729" weight="83.39597869320919" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3730" weight="83.18700759863961" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3731" weight="91.61335169002678" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="3732" weight="84.1439841965868" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="3733" weight="85.09082961806276" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3734" weight="87.2938441717819" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3735" weight="83.90469690718758" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3736" weight="90.39896134131938" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3737" weight="82.62488196871935" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="3738" weight="85.1176086208786" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3739" weight="90.19126576570207" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3740" weight="86.25514363217293" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="3741" weight="83.07587746467216" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3742" weight="89.63578415579812" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3743" weight="89.86706752530486" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3744" weight="84.5569568013865" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3745" weight="88.94631754478048" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3746" weight="89.20948049795942" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3747" weight="87.7874978171184" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="3748" weight="83.81305223220366" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3749" weight="83.0886534075334" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3750" weight="85.6215916602335" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3751" weight="89.57749349072355" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="3752" weight="81.66811797907351" />
      <edge source="in this paper, we use the phrase-based system of koehn et al (2003) to generate n-best translations for each of the modifiers, and we then use a discriminative reranking algorithm (bartlett et al, 2004) to choose between these modifiers. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3753" weight="82.33628456537525" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " id="3754" weight="85.17097821021893" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3755" weight="82.94430219366784" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="3756" weight="81.45068466042366" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3757" weight="82.01323151085995" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3758" weight="89.73459690695607" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3759" weight="83.58303301105549" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3760" weight="83.25577031716686" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="3761" weight="80.87855663099293" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3762" weight="87.93164771057435" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3763" weight="83.95048387609691" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3764" weight="87.75955461422352" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3765" weight="87.69161603896106" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3766" weight="89.75505017842835" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="3767" weight="84.55112926789896" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3768" weight="83.1848324915787" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="3769" weight="86.25068744583042" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3770" weight="86.04869105706763" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="3771" weight="80.59590692934053" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="3772" weight="82.6749775615111" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="3773" weight="82.399492979313" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3774" weight="87.41805227870275" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3775" weight="84.97877721212517" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3776" weight="87.65221125437073" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3777" weight="84.07868611289571" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3778" weight="86.92958420497243" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3779" weight="85.88331561076158" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3780" weight="81.38511527507129" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3781" weight="87.30652688671776" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3782" weight="88.36739904306077" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3783" weight="87.47621004546073" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3784" weight="85.42765295400869" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3785" weight="80.96845698034873" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="3786" weight="80.3069380591923" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3787" weight="82.6010068506184" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="3788" weight="85.42646021398991" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="3789" weight="82.2591912200957" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3790" weight="82.31614787973763" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3791" weight="86.08834567894219" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3792" weight="82.23075959632355" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3793" weight="86.37993214938629" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3794" weight="84.63330112595675" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3795" weight="80.46321931795686" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3796" weight="85.60452974910673" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3797" weight="84.16145607013863" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3798" weight="84.07039327003112" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3799" weight="84.34299850837431" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3800" weight="82.76261734310788" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="3801" weight="80.37770169609149" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3802" weight="85.93937129598508" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="3803" weight="80.86809752712935" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3804" weight="88.17961262508527" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3805" weight="86.50349526651328" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3806" weight="82.48110827394201" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="3807" weight="81.27336070215534" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3808" weight="83.38571091964711" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3809" weight="82.19154712862588" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="3810" weight="84.55968828261268" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3811" weight="82.15924908785928" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3812" weight="86.97496880515847" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3813" weight="84.40733358190148" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="3814" weight="81.95839054829631" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3815" weight="82.2623392403811" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3816" weight="80.08431917774752" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3817" weight="87.33289117657108" />
      <edge source="an evaluation of the method on translation from german to english shows similar performance to the phrase-based model of koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3818" weight="84.55294242691697" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " id="3819" weight="84.53652836467063" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3820" weight="83.75232880407428" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3821" weight="80.76751955496341" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3822" weight="80.28378166728645" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3823" weight="82.21041774775924" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3824" weight="83.23663864705182" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3825" weight="84.14770463148307" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3826" weight="82.06631595180605" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3827" weight="81.061909152331" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3828" weight="82.18200599036112" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3829" weight="82.58105799214653" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3830" weight="80.62065059678014" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3831" weight="81.34165013616928" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3832" weight="82.39589577853208" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3833" weight="80.3458217334456" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="3834" weight="80.09576213428046" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3835" weight="83.15455651077934" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3836" weight="82.06216600448502" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="details of this model are described by koehn et al (2003). " id="3837" weight="80.27419774571318" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3838" weight="81.67966680937067" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3839" weight="80.55985305561524" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3840" weight="81.40026812035181" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3841" weight="81.55271914487925" />
      <edge source="modifiers within german clauses were translated using the phrase-based model of koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3842" weight="84.18355801826432" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " id="3843" weight="81.62261450676579" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3844" weight="88.26980344895155" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3845" weight="80.7186992376292" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="3846" weight="86.75198524290906" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3847" weight="83.96033735503936" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3848" weight="82.3380475855689" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3849" weight="82.51214722088909" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3850" weight="82.98619792113253" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3851" weight="84.6993366013443" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="3852" weight="83.17933701776565" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3853" weight="80.70573782845176" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3854" weight="83.89629217194192" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3855" weight="85.60602178839991" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3856" weight="82.81900873193831" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3857" weight="88.58141661183056" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3858" weight="83.28381501487405" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3859" weight="84.17966696144714" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3860" weight="85.23383283156171" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="3861" weight="82.43235609649444" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="3862" weight="87.78160740251082" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3863" weight="83.76744537504395" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3864" weight="81.60825414190921" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3865" weight="83.72599123217705" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="3866" weight="83.52604444116696" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="3867" weight="83.34538342771083" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3868" weight="83.12225590536421" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="3869" weight="85.48960260445372" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="3870" weight="86.42375258508723" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3871" weight="81.67792656397145" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="3872" weight="85.26150443468572" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3873" weight="84.77028908306326" />
      <edge source="for example, koehn et al (2003) reported that requiring constituents to be syntactically motivated does not lead to better constituent pairs, but only fewer constituent pairs, with loss of a good amount of valuable knowledge." target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="3874" weight="86.60876606736696" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3875" weight="81.35650029426064" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3876" weight="80.60952594892592" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3877" weight="81.5714521455867" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3878" weight="84.79766776858241" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3879" weight="80.45924670631712" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3880" weight="84.48365371890691" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3881" weight="80.4768017788981" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3882" weight="81.90580936830301" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="3883" weight="83.71855097861611" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3884" weight="86.3230452703105" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="3885" weight="81.03634044119339" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3886" weight="80.66803318504965" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3887" weight="80.0285059692216" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3888" weight="81.06004889017602" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3889" weight="82.14247678766853" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="3890" weight="80.71095543047555" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3891" weight="80.05246834798572" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3892" weight="82.03144779208209" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3893" weight="83.25824234741721" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3894" weight="82.0559887599693" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3895" weight="82.80585240553981" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3896" weight="84.05887809565384" />
      <edge source="is relevant to finite-state phrase-based models that use no parse trees (koehn et al, 2003), tree-tostring models that rely on one parse tree (yamada and knight, 2001), and tree-to-tree models that rely on two parse trees (groves et al, 2004, e.g.). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3897" weight="81.59042442414477" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="3898" weight="80.77295208369846" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3899" weight="83.94360736142568" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="3900" weight="82.6359785802321" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3901" weight="86.71871752450666" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3902" weight="85.86197296544339" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3903" weight="83.91549595911346" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3904" weight="81.8716575875064" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3905" weight="84.35275806125794" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="3906" weight="80.85170304896043" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3907" weight="80.53841827118531" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3908" weight="82.15607192798493" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3909" weight="81.83312802226052" />
      <edge source="for maximum phrase length, we used 3 (based on what was suggested by (koehn etal., 2003)and 7(the default maximum phrase length in pharaoh). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3910" weight="80.09224405226752" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " id="3911" weight="87.389434318857" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3912" weight="80.86830995077439" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3913" weight="83.28367065433318" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3914" weight="83.97543459351564" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3915" weight="85.20199636317167" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3916" weight="81.10115993227058" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="3917" weight="82.13783587440079" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="3918" weight="83.13633840446859" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3919" weight="83.56552071539187" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="3920" weight="81.66767390629582" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3921" weight="84.66495407337572" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="3922" weight="82.2578545755922" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="3923" weight="83.59338195776841" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="3924" weight="84.21063649426381" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3925" weight="86.94736423605217" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="3926" weight="82.46072618509442" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="3927" weight="86.77909518217173" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="3928" weight="81.4801447695928" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3929" weight="89.28433838914086" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="3930" weight="80.46910531424942" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3931" weight="84.42891870329916" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="3932" weight="82.20844245266785" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="3933" weight="82.76063146598689" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="3934" weight="80.31088956077814" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3935" weight="83.83392296134045" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="3936" weight="83.7928556384127" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3937" weight="85.09899730280313" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="traditionally, maximum-likelihood estimation from relative frequencies is used to obtain conditional probabilities (koehn et al, 2003), eg, p(˜s" id="3938" weight="82.8042795815275" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="3939" weight="80.70813764260485" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3940" weight="83.27660831586508" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3941" weight="85.22796324108222" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="3942" weight="82.58671528581564" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="3943" weight="80.90467492793259" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="3944" weight="81.8398844453608" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3945" weight="83.76844828678524" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3946" weight="82.48514994575294" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="3947" weight="80.79121608646054" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="3948" weight="82.25299618440222" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="3949" weight="83.41248117978759" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="3950" weight="81.93189550508258" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="3951" weight="81.5791761020917" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="3952" weight="84.24778769894994" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="3953" weight="83.81100987324837" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="3954" weight="80.90611407866035" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="3955" weight="82.48173413051832" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3956" weight="87.33459745605754" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="3957" weight="81.26861869680093" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3958" weight="85.69779274202314" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="details of this model are described by koehn et al (2003). " id="3959" weight="80.479989165037" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="3960" weight="85.49938803889216" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="3961" weight="82.6049491644555" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="3962" weight="87.69188982188092" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="3963" weight="80.82457200470512" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="3964" weight="85.10754756270637" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="3965" weight="83.51830763971653" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="3966" weight="86.82096795736723" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="3967" weight="88.54863791186231" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="3968" weight="81.70624207807928" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="3969" weight="86.49882984522823" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="3970" weight="85.08822794076633" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="3971" weight="83.89871111999032" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="3972" weight="80.96305313059884" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="3973" weight="83.36889135293862" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="3974" weight="81.8850430625196" />
      <edge source="different approaches have been suggested as using relative frequencies (zens et al 2002), calculate probabilities based on a statistical word-to-word dictionary (vogel et al 2003) or use a linear interpolation of these scores (koehn et al 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="3975" weight="81.47074223579602" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " id="3976" weight="90.33141018731963" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="3977" weight="91.94772581291848" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="3978" weight="84.03231784238095" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="3979" weight="85.18935080207393" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="3980" weight="87.15663082128005" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="3981" weight="80.48762616811058" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="3982" weight="91.26238587882503" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="3983" weight="82.03305728325871" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="3984" weight="88.79974966755024" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="3985" weight="90.3201483951172" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="3986" weight="85.58357986029776" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="3987" weight="90.60840985044373" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="3988" weight="82.67135760023147" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="3989" weight="88.4771069460057" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="3990" weight="82.05216579334254" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="3991" weight="80.82545459630018" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="3992" weight="82.20267898052155" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="3993" weight="81.85087293178957" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="3994" weight="80.88626778490406" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="3995" weight="84.69664415745055" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="3996" weight="85.95471253511656" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="3997" weight="85.74443377493837" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="3998" weight="83.41545035690694" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="3999" weight="82.74148995068099" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="details of this model are described by koehn et al (2003). " id="4000" weight="83.3120177915994" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4001" weight="88.90071243299332" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4002" weight="85.2731121223245" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4003" weight="84.64431434733004" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4004" weight="83.92538678266035" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4005" weight="86.08203542745262" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4006" weight="83.97693927611347" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4007" weight="85.71931020375368" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4008" weight="85.59516531252555" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4009" weight="88.10790488203592" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4010" weight="85.06234531771229" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4011" weight="86.99232668139399" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4012" weight="87.34345793661986" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4013" weight="81.1305350434959" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="4014" weight="90.54710014058944" />
      <edge source="the advantage of using phrase-based translation in a statistical framework has been shown in many studies such as (koehn et al 2003; vogel et al 2003; zens et al 2002; marcu and wong, 2002). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4015" weight="81.49096699205896" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " id="4016" weight="91.23664260874745" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="4017" weight="84.41342112633916" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="4018" weight="83.01960840952718" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="4019" weight="90.05844057448516" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="4020" weight="80.00947628843984" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="4021" weight="92.76656134716784" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4022" weight="81.72395536365462" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4023" weight="86.63260323569912" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4024" weight="86.8574469194953" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="4025" weight="86.33918632619222" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4026" weight="90.82009702221676" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4027" weight="81.9550565338736" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4028" weight="85.34891521460948" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4029" weight="85.02795280845517" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4030" weight="81.03521764988169" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4031" weight="80.5698680599088" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4032" weight="84.67657246966492" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4033" weight="80.53381367166715" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4034" weight="84.90794536429738" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4035" weight="89.54395381680852" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4036" weight="81.46152875040045" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4037" weight="91.20455034447217" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4038" weight="81.47354710362616" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4039" weight="80.37914600052751" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="details of this model are described by koehn et al (2003). " id="4040" weight="82.04235482516017" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4041" weight="86.85538112047556" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4042" weight="82.25320050885105" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4043" weight="81.90480320142251" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4044" weight="81.53870728514234" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4045" weight="83.15874696443673" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4046" weight="88.59345464108233" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4047" weight="87.82161788834348" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4048" weight="90.43021973651636" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4049" weight="86.48650773473081" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4050" weight="84.55221193286104" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4051" weight="86.0852400923019" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4052" weight="80.39014138688316" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4053" weight="90.43659963380885" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4054" weight="87.68274124906128" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4055" weight="84.07524708703444" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4056" weight="89.88322744248778" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="4057" weight="87.78300136855567" />
      <edge source="more recently, phrase-based models (och et al, 1999; marcu and wong, 2002; koehn et al, 2003) have been proposed as a highly successful alternative to the ibm models. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4058" weight="83.63011803235008" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " id="4059" weight="84.40142818737047" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="4060" weight="82.4652239170271" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="4061" weight="83.93416213686709" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4062" weight="86.02966656853039" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="4063" weight="81.26836635445795" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4064" weight="83.83799616072982" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4065" weight="82.50155183675678" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4066" weight="83.17127741492652" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4067" weight="81.05124546983559" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4068" weight="81.81993776781087" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4069" weight="80.15599531452125" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4070" weight="80.65916354691622" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4071" weight="82.98712394689515" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4072" weight="85.43444035514808" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4073" weight="81.35194616867221" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4074" weight="83.45281375795899" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4075" weight="82.15466298491027" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4076" weight="81.35226981521792" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4077" weight="80.415465841708" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4078" weight="83.99148874665876" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4079" weight="80.83797395972567" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4080" weight="83.55724344720947" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4081" weight="83.79772333729245" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4082" weight="83.70454332347761" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4083" weight="83.45173792190349" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4084" weight="80.39823029405504" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4085" weight="85.90196532627394" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4086" weight="81.27240517169538" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4087" weight="83.83834552346008" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="4088" weight="80.61616000771848" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4089" weight="83.53377007608482" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4090" weight="81.63709001712347" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4091" weight="80.37176350203774" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4092" weight="82.48094501159476" />
      <edge source="results using the method show an improvement from 25.2% bleu score to 26.8% bleu score (a statistically significant improvement), using a phrase-based system (koehn et al, 2003) which has been shown in the past to be a highly competitive smt system. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4093" weight="82.99479275664181" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="4094" weight="83.20688992461322" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="4095" weight="87.86970968216662" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="4096" weight="86.08203292195569" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="4097" weight="81.8587476825417" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="4098" weight="93.07017202595702" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4099" weight="80.96563751265242" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4100" weight="88.94469227844455" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4101" weight="87.14833807737318" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4102" weight="82.46110258058343" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="4103" weight="88.25037868152307" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4104" weight="90.05653736479901" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4105" weight="86.9224811473424" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4106" weight="90.98980464879097" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4107" weight="81.99794925331574" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="4108" weight="83.91327802827303" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="791 and score the alignment template model phrases (koehn et al, 2003). " id="4109" weight="80.35016521581615" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4110" weight="83.4522754901097" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4111" weight="80.5107603070631" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4112" weight="82.53504709672245" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4113" weight="87.6889990146678" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4114" weight="91.19537061568424" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4115" weight="81.01631472759769" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4116" weight="80.47382824478882" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4117" weight="80.9727221529061" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4118" weight="81.17466078383397" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="details of this model are described by koehn et al (2003). " id="4119" weight="81.31821886188415" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4120" weight="87.89917335752801" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4121" weight="81.37439194513809" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4122" weight="85.97868077603945" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4123" weight="85.84971160668684" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4124" weight="84.04759366198553" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4125" weight="86.2802462411062" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4126" weight="86.25158268241509" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4127" weight="82.75032813746044" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4128" weight="86.39846433699374" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4129" weight="89.94730934179613" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4130" weight="85.24947320248282" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4131" weight="84.30674829444138" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4132" weight="89.52856449066482" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="4133" weight="91.16218999831796" />
      <edge source="recent research on statistical machine translation (smt) has lead to the development of phrase-based systems (och et al, 1999; marcu and wong, 2002; koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4134" weight="81.43968049289731" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " id="4135" weight="85.83391118490928" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="4136" weight="85.42862523686014" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="4137" weight="88.97497219672456" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4138" weight="88.63597593955453" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="4139" weight="89.26128367192389" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4140" weight="90.09946311534122" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4141" weight="89.74287964411562" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4142" weight="90.85892218214782" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4143" weight="87.16402443635249" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4144" weight="87.59127149041805" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4145" weight="85.04185093824408" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="4146" weight="83.86981057042193" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4147" weight="85.74314145734185" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4148" weight="82.6082106777893" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4149" weight="87.81133738689721" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4150" weight="80.66609826890327" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4151" weight="89.86123346807172" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4152" weight="89.81773836000254" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4153" weight="89.52773032066807" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4154" weight="87.05245436752125" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4155" weight="90.53875241927736" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4156" weight="87.67933729721875" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4157" weight="87.9609877591577" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4158" weight="86.67791177059874" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4159" weight="83.02265966182323" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4160" weight="90.03346166396247" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4161" weight="87.6905477634784" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4162" weight="81.51533548612058" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4163" weight="85.84377707351256" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4164" weight="86.47479236098047" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="4165" weight="83.91154352630517" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="4166" weight="81.95971659809832" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4167" weight="82.515191497633" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4168" weight="90.68710306046952" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4169" weight="88.21833986754773" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4170" weight="85.93248665142208" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4171" weight="85.27070806455099" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4172" weight="91.5251478181549" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4173" weight="84.21234791568497" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4174" weight="80.31321599207182" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4175" weight="82.63305575232074" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4176" weight="89.14756600713744" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4177" weight="80.98421930826719" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="4178" weight="83.92867155652833" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="4179" weight="81.23014818069298" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4180" weight="89.65184897154002" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4181" weight="85.054008706884" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4182" weight="89.23329362237608" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4183" weight="87.26324490816563" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4184" weight="83.91672618521314" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4185" weight="87.41935493096973" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4186" weight="85.52581689050562" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4187" weight="80.40187258479752" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4188" weight="85.47928283696172" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4189" weight="83.241074271766" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4190" weight="87.98681265012182" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4191" weight="84.09931997712681" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4192" weight="82.07543021333427" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4193" weight="90.64833820237507" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4194" weight="80.6395485370023" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4195" weight="83.40464797349532" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4196" weight="86.17844800471181" />
      <edge source="in experiments with the system of (koehn et al, 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e., have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4197" weight="81.33237225917934" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="our baseline is the phrase-based mt system of (koehn et al, 2003). " id="4198" weight="90.27342090116683" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="4199" weight="89.79950753305133" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="4200" weight="82.4383587900751" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="4201" weight="81.91535121895879" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4202" weight="90.84045620436127" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="4203" weight="85.92991217553141" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4204" weight="82.76092140350957" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4205" weight="88.4823439960237" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4206" weight="87.80269585818176" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4207" weight="82.85373713634547" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="4208" weight="80.84654908646786" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4209" weight="81.76764839002428" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4210" weight="89.85596083103242" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4211" weight="86.87375353608029" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4212" weight="89.02990574337547" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4213" weight="84.00130613808454" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4214" weight="90.09994936363866" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="4215" weight="81.86131440162534" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4216" weight="83.28993685447" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4217" weight="85.36847981724436" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4218" weight="81.550512562985" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4219" weight="87.73124976888094" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4220" weight="82.5635713906055" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4221" weight="85.68915895219062" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4222" weight="86.7182146598623" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4223" weight="85.90522363833463" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4224" weight="87.39840779700907" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4225" weight="89.32237242600056" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4226" weight="80.97557882240147" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4227" weight="83.37051210302135" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4228" weight="87.93558616803165" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4229" weight="89.20742765409719" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4230" weight="85.66128012711623" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4231" weight="86.10583418154401" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4232" weight="88.44604578889297" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4233" weight="81.4931186189935" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4234" weight="84.76273311627243" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4235" weight="89.22450664805692" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4236" weight="84.54085231570781" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4237" weight="84.1286273873266" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4238" weight="88.14876145639879" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4239" weight="85.04626436614345" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4240" weight="87.2977130492228" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4241" weight="87.67039331489721" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4242" weight="88.15071485055658" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4243" weight="86.43449341801539" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4244" weight="82.39966338297819" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4245" weight="83.08384915682898" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4246" weight="87.30794970496605" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4247" weight="83.1881283839116" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4248" weight="84.57665886042545" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4249" weight="86.10415817107568" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4250" weight="83.99169654587072" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="details of this model are described by koehn et al (2003). " id="4251" weight="81.99574476253404" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4252" weight="85.79627085939212" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4253" weight="88.9136702041337" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4254" weight="83.80298958618921" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4255" weight="82.95438498460955" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4256" weight="84.13515559705102" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4257" weight="88.63241558568996" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4258" weight="89.74423949863579" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4259" weight="83.77589012378147" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4260" weight="80.8881779487838" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4261" weight="88.6894791448781" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4262" weight="84.09292114248868" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4263" weight="80.06942872347562" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4264" weight="88.54559901636195" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4265" weight="86.74237985153847" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4266" weight="88.12123624505517" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4267" weight="85.62637466291517" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4268" weight="89.64697186351944" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4269" weight="88.90451984561129" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4270" weight="83.44286619859449" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4271" weight="83.66589080398555" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4272" weight="84.91521739434273" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4273" weight="90.48472099753806" />
      <edge source="in this paper we use the phrase-based system of (koehn et al, 2003) as our underlying model. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4274" weight="83.10315408269926" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " id="4275" weight="83.65678504019218" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " id="4276" weight="81.62685550081417" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="4277" weight="83.02117277538336" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4278" weight="85.76318744337637" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4279" weight="86.70350074973283" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4280" weight="81.89833421163783" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4281" weight="80.94109130905409" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="4282" weight="81.16039755310487" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4283" weight="85.23166564263975" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4284" weight="83.51527299236562" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4285" weight="80.73340164166109" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="on smaller data sets (koehn et al, 2003) the joint model shows performance comparable to the standard model, however the joint model does not reach the level of performance of the stan156 en-es es-en joint 3-gram, dl4 20.51 26.64 5-gram, dl6 26.34 27.17 + lex. " id="4286" weight="80.35483453004599" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4287" weight="89.26088012810997" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4288" weight="81.91752934499004" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4289" weight="80.12104501756599" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4290" weight="82.84812905179405" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4291" weight="83.84281633053592" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4292" weight="81.76280514262749" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4293" weight="81.88665140741507" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="791 and score the alignment template model phrases (koehn et al, 2003). " id="4294" weight="80.62625799306369" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4295" weight="82.42647276359524" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4296" weight="80.54314797363989" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4297" weight="83.76971200866035" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4298" weight="80.15369680379199" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4299" weight="82.99150165694729" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4300" weight="82.28907693823808" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4301" weight="84.69060626463718" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4302" weight="85.5455589326125" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4303" weight="83.98113104093234" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4304" weight="83.47019477331187" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4305" weight="80.32326711741977" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4306" weight="81.71400670371641" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4307" weight="81.46879155811872" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4308" weight="81.72251011180734" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4309" weight="85.64655324496391" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4310" weight="81.36638330131731" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="details of this model are described by koehn et al (2003). " id="4311" weight="82.38026796643479" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4312" weight="86.92402044614099" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4313" weight="80.58950446381353" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4314" weight="89.05315652989752" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4315" weight="88.9979491117143" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4316" weight="84.16292591622437" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4317" weight="83.64315418057171" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4318" weight="82.96092359019917" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4319" weight="87.11366767025193" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4320" weight="85.25029965649622" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4321" weight="87.86100975177618" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4322" weight="86.50783390943195" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4323" weight="87.3608982631866" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4324" weight="81.45850151600928" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4325" weight="81.91180258710426" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4326" weight="81.89196371857234" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4327" weight="81.78312840457865" />
      <edge source="our baseline is the phrase-based mt system of (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4328" weight="82.990986732142" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="for further information on these parameter settings, confer (koehn et al, 2003). " id="4329" weight="81.42354899531827" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " id="4330" weight="86.25051269643636" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " id="4331" weight="80.51270807625683" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4332" weight="89.53349299612749" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="4333" weight="83.49669727860353" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4334" weight="83.48948932761704" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4335" weight="86.8853330011453" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4336" weight="86.86916368524335" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4337" weight="85.65872171360742" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4338" weight="87.51618416492431" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4339" weight="84.61670872950566" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4340" weight="87.22437659554221" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4341" weight="86.7594322823616" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4342" weight="85.8931169537485" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4343" weight="82.03234092567557" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4344" weight="84.13276092021549" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4345" weight="82.83162622395643" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4346" weight="89.9824491183693" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4347" weight="86.48216531421156" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4348" weight="89.59084115955889" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4349" weight="85.5724194182567" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4350" weight="89.49714527256114" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4351" weight="84.04648270724017" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4352" weight="85.79530476989999" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4353" weight="87.97796741937218" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4354" weight="86.53419858203833" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4355" weight="84.62025533183908" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4356" weight="85.83005208201956" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4357" weight="86.43558447125119" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4358" weight="83.88675219767082" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4359" weight="82.87611606648144" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4360" weight="93.60111380460143" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4361" weight="83.94885768341523" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4362" weight="85.81684424270699" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4363" weight="87.77289980477107" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4364" weight="86.8640133925939" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4365" weight="84.79251948510264" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4366" weight="86.60707250841186" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4367" weight="86.78733977696626" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4368" weight="85.20148379777312" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4369" weight="82.07531047515326" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4370" weight="85.18579601232943" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4371" weight="83.49664315464895" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4372" weight="85.22450920053137" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4373" weight="81.4022904767501" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="4374" weight="80.59389972935213" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4375" weight="85.01737542624616" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4376" weight="84.95587561580915" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="4377" weight="82.75997295672894" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="details of this model are described by koehn et al (2003). " id="4378" weight="81.3662075669208" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4379" weight="89.39265151484128" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4380" weight="87.44102902657207" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4381" weight="88.24033850841602" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4382" weight="84.51829986420776" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4383" weight="82.4724391259479" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4384" weight="83.7647623549578" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4385" weight="87.50304740217985" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4386" weight="87.07574701378857" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4387" weight="82.45515729073682" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4388" weight="90.09179389020576" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4389" weight="90.17431546298711" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4390" weight="84.2457690533525" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4391" weight="91.43746780523954" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4392" weight="85.6821787569508" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4393" weight="88.82909034226107" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4394" weight="87.42596604617123" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4395" weight="92.73483742819309" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4396" weight="89.36954147199954" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4397" weight="87.66439658615157" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4398" weight="86.08306278742441" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4399" weight="90.65969182779182" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4400" weight="89.21809792335564" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4401" weight="81.51778960308258" />
      <edge source="under a phrase based translation model (koehn et al, 2003; marcu and wong, 2002), this distinction is important and will be discussed in more detail. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4402" weight="82.56703060947" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4403" weight="83.47012157868976" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="4404" weight="82.3524606992606" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4405" weight="83.31882050071424" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4406" weight="80.10945073355313" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4407" weight="83.76609698649358" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4408" weight="81.83345473247586" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4409" weight="80.81142085334827" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4410" weight="83.58716607367714" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4411" weight="81.91668326113579" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4412" weight="83.18730682681634" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4413" weight="80.73429881835106" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4414" weight="81.4591627360421" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4415" weight="84.03256338778303" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4416" weight="80.60849492446387" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4417" weight="80.98462128486898" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4418" weight="81.83495092995578" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4419" weight="80.22710098814738" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4420" weight="82.12890509969522" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4421" weight="81.17674094203005" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4422" weight="82.5087748857741" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4423" weight="80.5707659619802" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="4424" weight="83.39848530071443" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4425" weight="83.42204063687248" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4426" weight="83.11136454332535" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4427" weight="82.9376931725434" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4428" weight="81.34434192216327" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4429" weight="80.13351400675023" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4430" weight="84.74567718431581" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4431" weight="83.3265693075524" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4432" weight="81.78235351333154" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4433" weight="81.95545586945539" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4434" weight="81.6524258049732" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4435" weight="86.86760535606537" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4436" weight="84.22204372699926" />
      <edge source="the first system is the pharaoh decoder provided by (koehn et al, 2003) for the shared data task. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4437" weight="82.74781668098011" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4438" weight="82.30467816303637" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4439" weight="84.13866117843905" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4440" weight="81.35743876014638" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4441" weight="81.46233402601668" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="for details, please refer to koehn et al (2003). " id="4442" weight="83.3080520134704" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4443" weight="80.38247160016473" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4444" weight="81.54060528917614" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4445" weight="81.15540394431979" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4446" weight="83.5244673265779" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4447" weight="84.05574306947756" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4448" weight="81.07302796159681" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4449" weight="81.85843557267485" />
      <edge source="for further information on these parameter settings, confer (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4450" weight="80.0533893336763" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4451" weight="88.12555648840514" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="4452" weight="82.00448693357212" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4453" weight="88.74898305865662" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4454" weight="82.20261034095006" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="4455" weight="89.60670837063225" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4456" weight="90.8769642332501" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4457" weight="88.41802073631517" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4458" weight="86.16282356498928" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="4459" weight="82.73828627080113" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4460" weight="83.8438749780399" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4461" weight="81.38826171706168" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4462" weight="88.19956792367174" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4463" weight="87.89054391051035" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4464" weight="81.13376636602409" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="4465" weight="82.98021833551013" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="for details, please refer to koehn et al (2003). " id="4466" weight="81.934071244952" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4467" weight="80.59622244917941" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="details of this model are described by koehn et al (2003). " id="4468" weight="81.36251105975023" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4469" weight="87.05004499450884" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4470" weight="81.7478649819734" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4471" weight="84.7222903753303" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4472" weight="83.92663610514957" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4473" weight="88.44031083250611" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4474" weight="88.0637748183013" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4475" weight="83.49810504135596" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4476" weight="85.0707338963528" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4477" weight="90.6097185337708" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4478" weight="84.47661559782577" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4479" weight="83.87868069852556" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4480" weight="86.76593996290963" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="4481" weight="91.78849145623987" />
      <edge source="in recent years, various phrase translation approaches (marcu and wong, 2002; och et al, 1999; koehn et al, 2003) have been shown to outperform word-to-word translation models (brown et al, 1993). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4482" weight="81.95747367051132" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " id="4483" weight="84.13343964987843" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="4484" weight="84.61780577517833" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4485" weight="84.69372237834651" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4486" weight="85.78258099392686" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4487" weight="87.3484326342429" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4488" weight="86.9811025088346" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4489" weight="84.40637895701437" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4490" weight="80.81868763085407" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4491" weight="80.94279382125733" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4492" weight="88.60319121474267" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4493" weight="85.98985498871488" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4494" weight="82.81533796640713" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4495" weight="83.12527085550154" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4496" weight="88.07243126648329" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4497" weight="83.65634471523803" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4498" weight="82.09716919214958" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4499" weight="86.64424797093658" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4500" weight="84.14808078184164" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4501" weight="82.31510460716824" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4502" weight="81.16504312486515" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4503" weight="80.99578967560505" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4504" weight="86.61497688873507" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4505" weight="84.46360907657589" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4506" weight="80.19771585647624" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4507" weight="81.25322967374015" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4508" weight="83.59288666980554" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4509" weight="83.73360748803773" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4510" weight="81.87920272118845" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4511" weight="80.6299870977768" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4512" weight="82.05556454974257" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4513" weight="84.91153740994908" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4514" weight="80.31022866356665" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4515" weight="81.13037544902745" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4516" weight="86.23498935483929" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4517" weight="80.8698152278056" />
      <edge source="the huge increase in computational and storage cost of including longer phrases does not provide a significant improvement in quality (koehn et al, 2003) as the probability of reappearance of larger phrases decreases. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4518" weight="80.5793578564785" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " id="4519" weight="85.14392808029973" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " id="4520" weight="80.40198479468911" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4521" weight="90.27561566207427" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4522" weight="88.72743834758782" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4523" weight="84.76376299549861" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="4524" weight="82.2278344698006" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4525" weight="91.11216347928948" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4526" weight="88.10862422910668" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4527" weight="86.99691802202152" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4528" weight="84.50242400649637" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4529" weight="85.6216703631163" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="4530" weight="81.15686115060039" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4531" weight="82.16140323019525" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4532" weight="84.29949723644856" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4533" weight="82.04363404408947" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4534" weight="86.1941379334137" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4535" weight="84.03339940669102" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4536" weight="86.09184482847736" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4537" weight="87.6161223281948" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4538" weight="90.23360960037559" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4539" weight="87.89506479805308" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4540" weight="86.64888428440976" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4541" weight="86.84521974611563" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4542" weight="87.3889953932566" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4543" weight="87.01411806051209" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4544" weight="86.56164481889192" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4545" weight="86.34819573566404" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4546" weight="87.72520746939996" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4547" weight="81.22536142739717" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4548" weight="89.04599060785065" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4549" weight="80.22183232319526" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4550" weight="88.49437742329003" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4551" weight="88.89195254921634" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4552" weight="84.74007099320427" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4553" weight="90.0153230372898" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4554" weight="81.74733644553392" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4555" weight="89.15183525235608" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4556" weight="87.08314871792528" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4557" weight="89.2799843905304" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4558" weight="91.2332970138982" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4559" weight="82.61074270516401" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4560" weight="84.30244710683199" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4561" weight="86.41417404290277" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4562" weight="86.33982780766421" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4563" weight="80.2877445076134" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4564" weight="83.7411019570528" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4565" weight="87.7505587891749" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4566" weight="84.58238790842738" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="4567" weight="81.51946010845069" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="4568" weight="81.94069989726991" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4569" weight="82.5919116769074" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4570" weight="89.11149247807077" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4571" weight="83.87745315086173" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4572" weight="87.241439526989" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4573" weight="86.44214457675633" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4574" weight="86.72630737117306" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4575" weight="88.94887720916962" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4576" weight="83.55112882252493" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4577" weight="85.2711080841733" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4578" weight="86.423369498742" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4579" weight="84.22612867274444" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4580" weight="85.70422047132567" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4581" weight="90.04465169613897" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4582" weight="86.59775960325815" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4583" weight="87.86234044274472" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4584" weight="87.76354002497398" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4585" weight="88.77259715674619" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4586" weight="87.49390944637541" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4587" weight="89.28155682704906" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4588" weight="87.9130072640059" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4589" weight="86.21518313194953" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4590" weight="88.17523848496201" />
      <edge source="it has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4591" weight="86.18921677264272" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " id="4592" weight="89.31370931702102" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4593" weight="87.68609895027804" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4594" weight="88.31395596517217" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4595" weight="88.34298489914146" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4596" weight="86.19792635088126" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4597" weight="87.02865414751615" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="4598" weight="82.8417390047645" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4599" weight="82.9805345566646" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4600" weight="84.20183915679303" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4601" weight="87.84108373688466" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4602" weight="88.59079998983049" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4603" weight="86.66541832297503" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4604" weight="87.91356858213032" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4605" weight="87.51403887379674" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4606" weight="84.61741250971082" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4607" weight="86.70018125460545" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4608" weight="89.84525542362469" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4609" weight="87.07574958761812" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4610" weight="89.11849129374292" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4611" weight="85.54192335171847" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4612" weight="81.47550315262002" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4613" weight="84.96069932020274" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4614" weight="84.48140094769909" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="4615" weight="80.43181255972192" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="4616" weight="82.23316265832274" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4617" weight="82.3841803782757" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4618" weight="85.44530717439993" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4619" weight="88.18362915196649" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4620" weight="83.35851194315956" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4621" weight="84.95012647878066" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4622" weight="88.11852630156778" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4623" weight="83.51571325442966" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4624" weight="82.86139250415059" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4625" weight="81.04930428668682" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4626" weight="81.12260339522004" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4627" weight="90.44000794912029" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4628" weight="86.09133153698285" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4629" weight="88.41598426519863" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4630" weight="82.89747366838516" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4631" weight="83.08366096380139" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4632" weight="86.03431339015705" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4633" weight="86.04687940775509" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4634" weight="81.14911118041044" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4635" weight="86.22706558591378" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4636" weight="81.40240997296415" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4637" weight="82.48760805039251" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4638" weight="82.42217477820166" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4639" weight="82.41920669625777" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4640" weight="82.26624135204057" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4641" weight="81.6745352622154" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4642" weight="83.31595365423314" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4643" weight="81.05154360046292" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4644" weight="89.38737263677703" />
      <edge source="we collected the pp parameters bys imply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4645" weight="83.64690018604486" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4646" weight="88.79559997690623" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4647" weight="81.13050263058213" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="4648" weight="85.38047052001743" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4649" weight="88.62494602376366" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4650" weight="84.73945669750724" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4651" weight="85.12029593030417" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4652" weight="82.2856967759479" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="791 and score the alignment template model phrases (koehn et al, 2003). " id="4653" weight="80.66364056562303" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4654" weight="80.71557928510384" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4655" weight="84.8834328886001" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4656" weight="83.07372003114489" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4657" weight="86.10005779527428" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4658" weight="89.50224435689675" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4659" weight="81.32477263174384" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4660" weight="80.15359725653441" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4661" weight="80.89810471188639" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="4662" weight="81.35071046391693" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4663" weight="80.78694810084275" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="details of this model are described by koehn et al (2003). " id="4664" weight="83.12891570581067" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4665" weight="85.22089404496695" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4666" weight="85.12191587931737" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4667" weight="84.84404130649712" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4668" weight="83.74953265866598" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4669" weight="87.51808904769898" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4670" weight="85.62740757517979" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4671" weight="87.2046768611761" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4672" weight="83.85266591961683" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4673" weight="85.98279647016496" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4674" weight="84.20567246984618" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4675" weight="80.49308542743225" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4676" weight="82.16387326857317" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="4677" weight="86.18407267652017" />
      <edge source="this includes the standard notion of phrase, popular with phrasedbased smt (koehn et al, 2003; vogel et al, 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4678" weight="84.14830173487302" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " id="4679" weight="91.8876496691717" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " id="4680" weight="80.01689267280234" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="4681" weight="80.507008767227" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4682" weight="91.86846370898377" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4683" weight="87.17327758442966" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4684" weight="84.16816071866423" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4685" weight="88.03739784081588" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4686" weight="85.2651429275931" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="4687" weight="90.63690988237292" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4688" weight="80.54852582302654" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4689" weight="84.7613242874828" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4690" weight="85.9423122301247" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4691" weight="89.58150070687086" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4692" weight="86.11593207956503" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4693" weight="84.66160581816797" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4694" weight="91.006672484791" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4695" weight="92.09214300295498" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4696" weight="93.75620709704245" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4697" weight="92.41770949408503" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4698" weight="85.92233286605004" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4699" weight="88.87270262697888" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4700" weight="87.39440226962863" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4701" weight="89.48485271469482" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4702" weight="90.16551527773169" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4703" weight="89.05625447934307" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4704" weight="87.00312413676568" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4705" weight="86.16904896518504" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4706" weight="90.31461395292834" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4707" weight="85.95253241429963" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="4708" weight="86.57548093652122" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="4709" weight="86.11445158913543" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4710" weight="82.71503402983878" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4711" weight="88.31468270059608" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4712" weight="81.68776808724367" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="4713" weight="82.21022597444141" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4714" weight="92.62278993430857" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4715" weight="89.39429399993848" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4716" weight="87.26981091461725" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4717" weight="89.87906852045735" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4718" weight="82.51475398238699" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4719" weight="86.16310366264383" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4720" weight="88.44456186238729" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4721" weight="83.10828352661335" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4722" weight="80.62661145739725" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4723" weight="85.78154592548674" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4724" weight="86.85226388480696" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="4725" weight="82.99503896784282" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="4726" weight="83.47280308638368" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4727" weight="81.00930337341478" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4728" weight="91.34432121807102" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4729" weight="84.67361763740524" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4730" weight="86.2842200019385" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4731" weight="88.85693141844533" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4732" weight="85.23343323974797" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4733" weight="88.58343480777506" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4734" weight="83.45612508713853" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4735" weight="86.70058903627044" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4736" weight="82.74059774433616" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4737" weight="82.56143314908286" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4738" weight="87.62002670774318" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4739" weight="83.25650809995264" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4740" weight="85.58793147502656" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4741" weight="89.28548294774122" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4742" weight="88.63552895713262" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4743" weight="86.57747441090622" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4744" weight="84.92565266036966" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4745" weight="81.6363738497703" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4746" weight="85.63802812128387" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4747" weight="86.54049849653282" />
      <edge source="accordingly, in this section we describe a set of experiments which extends the work of (way and gough, 2005) by evaluating the marker-based ebmt system of (gough &amp; way, 2004b) against a phrase-based smt system built using the following components: • giza++, to extract the word-level correspondences; • the giza++ word alignments are then refined and used to extract phrasal alignments ((och &amp; ney, 2003); or (koehn et al, 2003) for a more recent implementation); • probabilities of the extracted phrases are calculated from relative frequencies; • the resulting phrase translation table is passed to the pharaoh phrase-based smt decoder which along with sri language modelling toolkit5 performs translation. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4748" weight="84.53508001946967" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " id="4749" weight="90.45529023969752" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4750" weight="85.52653627097249" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4751" weight="83.71260908397022" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4752" weight="85.86396066753296" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4753" weight="87.31265597145894" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="4754" weight="86.74832123648257" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4755" weight="81.84630312619079" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4756" weight="83.2875742931805" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4757" weight="85.490958513744" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4758" weight="89.83307593198688" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4759" weight="80.87720242363297" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4760" weight="84.7514265953548" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4761" weight="88.6592290903198" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4762" weight="91.07599132944131" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4763" weight="88.70025416719534" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4764" weight="92.0881360733699" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4765" weight="85.20990322608154" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4766" weight="86.30441237996862" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4767" weight="86.70608714821948" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4768" weight="88.63341322103919" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4769" weight="85.70612405257359" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4770" weight="85.53196319817937" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4771" weight="87.29092211918082" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4772" weight="82.4803259837658" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4773" weight="86.83558039325257" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4774" weight="86.95154888331558" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="4775" weight="81.12104543280915" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="4776" weight="84.5089741348502" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4777" weight="85.08508284955822" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4778" weight="87.23323422475777" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4779" weight="80.20149475833843" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4780" weight="90.14559022957782" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4781" weight="85.50317884380942" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4782" weight="87.72271955999531" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4783" weight="87.4692788383941" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4784" weight="84.40895844177756" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4785" weight="84.36674103617958" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4786" weight="90.65763136993282" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4787" weight="84.71438865840571" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4788" weight="86.82570609475471" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4789" weight="84.766193759316" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="4790" weight="82.61599125583452" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="4791" weight="82.22806559557476" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4792" weight="88.70757951759258" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4793" weight="81.69151013556049" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4794" weight="83.42736344898066" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4795" weight="89.06550534431013" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4796" weight="81.0864726475113" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4797" weight="83.6987725174746" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4798" weight="83.30423675010663" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4799" weight="86.56500060609504" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4800" weight="81.02132949640533" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4801" weight="84.45982585341302" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4802" weight="85.54293859471645" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4803" weight="82.58058256049692" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4804" weight="82.90416537782288" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4805" weight="88.65951286580567" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4806" weight="88.13132676929045" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4807" weight="85.58099787633569" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4808" weight="85.02127928227006" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4809" weight="83.86514006932708" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4810" weight="85.47204055187187" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4811" weight="85.13552709395414" />
      <edge source="this translation model differs from the well known phrase-based translation approach (koehn et al, 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4812" weight="85.69358198675138" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " id="4813" weight="82.58491782686887" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " id="4814" weight="83.45299022613202" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4815" weight="81.49286071528618" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4816" weight="85.39247509802846" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4817" weight="80.79002449825087" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4818" weight="80.60288913338123" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4819" weight="83.99444210622971" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4820" weight="80.03552403607432" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4821" weight="84.21462467412044" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4822" weight="92.92157690938787" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4823" weight="81.12080643399547" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="4824" weight="80.69265489071884" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4825" weight="86.31834201942796" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4826" weight="82.70125546103549" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4827" weight="83.8885476380812" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4828" weight="80.94176386630929" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4829" weight="80.45743174653389" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4830" weight="86.03808719401785" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4831" weight="83.45176057059504" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4832" weight="82.65324625859792" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4833" weight="82.46884704949473" />
      <edge source="phrase-pairs are then extracted from the word alignments (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4834" weight="80.07511020074757" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4835" weight="81.45498364325788" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " id="4836" weight="83.02137996255598" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4837" weight="88.55684542121071" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4838" weight="81.9405557449221" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4839" weight="81.71950060795568" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4840" weight="82.7196769948108" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4841" weight="82.57690161228888" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4842" weight="81.51192482877725" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4843" weight="85.24181277713568" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4844" weight="80.57205826848981" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4845" weight="80.08533060745438" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="4846" weight="85.40230280638403" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4847" weight="86.95172918753826" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4848" weight="86.03711353764957" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4849" weight="80.2566040225417" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4850" weight="83.58358198592977" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4851" weight="81.98073914506648" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4852" weight="84.79522360634488" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4853" weight="82.48846097634912" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="4854" weight="81.97300148745477" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4855" weight="82.31831811460934" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4856" weight="86.34323236678507" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4857" weight="80.5584406309938" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4858" weight="80.54096742135523" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4859" weight="86.86744761079561" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="4860" weight="84.39247381926683" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4861" weight="86.59140779520611" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4862" weight="87.13283620661795" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4863" weight="89.89324300782286" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4864" weight="90.2094338285125" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4865" weight="86.51099641922598" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4866" weight="85.95112261250948" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4867" weight="84.66677153436383" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4868" weight="83.70115974937924" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4869" weight="82.79675042950704" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4870" weight="83.92029039716189" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="4871" weight="84.81033339920312" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="4872" weight="82.682235588593" />
      <edge source="the second one is heuristic and tries to use a word-aligned corpus (zens et al, 2002; koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4873" weight="80.19593916037647" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " id="4874" weight="83.54303985444335" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4875" weight="85.21717919137912" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4876" weight="80.71206417084792" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4877" weight="81.19539378503762" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4878" weight="81.26504258685874" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4879" weight="85.3955442115024" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4880" weight="81.13203482579559" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4881" weight="81.2526286243928" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4882" weight="81.32377770858068" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="4883" weight="80.69622529780098" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4884" weight="80.12199374047182" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4885" weight="82.23178774267971" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4886" weight="85.50290729024077" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4887" weight="83.54873633642674" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4888" weight="83.30040287611897" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4889" weight="85.41125255731399" />
      <edge source="we generate widl-expressions from chinese strings by exploiting a phrase-based translation table (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4890" weight="82.07423768693903" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4891" weight="84.07719037762953" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="4892" weight="87.5546222334322" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="4893" weight="84.77304488880154" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " id="4894" weight="82.43642474266322" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="4895" weight="82.84143370200891" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4896" weight="81.7571094656819" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4897" weight="81.08195338841988" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4898" weight="82.67659702349029" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4899" weight="82.16324804285871" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4900" weight="80.66378421662253" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4901" weight="83.4623026092382" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="4902" weight="80.8696145992887" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4903" weight="83.38724561929993" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="4904" weight="88.40537288265425" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4905" weight="82.91869237761946" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4906" weight="83.04710875782324" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4907" weight="88.81280184135845" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4908" weight="83.20905015395819" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4909" weight="83.3350059860759" />
      <edge source="a similar argument applies to phrase-based translation methods (e.g., koehn et al (2003)). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4910" weight="81.95212260908636" />
      <edge source="see (och and ney, 2000), (yamada and knight, 2001), (koehn and knight, 2002), (koehn et al, 2003), (schafer and yarowsky, 2003) and (gildea, 2003). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="4911" weight="84.11946935682846" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4912" weight="84.86935380906058" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4913" weight="81.43956670243814" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="4914" weight="84.84434941767516" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4915" weight="80.81893490444799" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="4916" weight="84.22167558615183" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4917" weight="83.64784652903536" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="4918" weight="86.08257971856628" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4919" weight="81.8204356304577" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4920" weight="81.14533362684078" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4921" weight="81.07114048945677" />
      <edge source="nowadays, most of the state-of-the-art smt systems are based on bilingual phrases (bertoldi et al, 2004; koehn et al, 2003; och and ney, 2004; tillmann, 2003; vogel et al, 2004; zens and ney, 2004). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="4922" weight="91.3195587646347" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " id="4923" weight="87.61406845361495" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " id="4924" weight="82.85707253277015" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4925" weight="89.66095095795498" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4926" weight="86.36665731263994" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="4927" weight="83.42785175804164" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4928" weight="87.03617045150847" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="4929" weight="85.38350840408793" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4930" weight="90.02872638258506" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="4931" weight="85.1912621181358" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4932" weight="91.83454480441466" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4933" weight="91.35606230908317" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4934" weight="90.5572549179753" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4935" weight="88.03496778499829" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4936" weight="88.68533357426386" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4937" weight="88.45768262762093" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4938" weight="90.85103669459164" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4939" weight="89.78683749569001" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="4940" weight="83.57112381993946" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4941" weight="87.85175101353599" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4942" weight="87.55376976501606" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="4943" weight="81.39261748390561" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4944" weight="86.00461846376253" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4945" weight="86.83009798759922" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="4946" weight="83.34332969312837" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="4947" weight="81.15975956377977" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="4948" weight="81.911431581925" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="4949" weight="90.40807204587095" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="4950" weight="90.13785554998353" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="4951" weight="85.6459327435187" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="4952" weight="85.9433951284817" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="4953" weight="89.37277417003607" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="4954" weight="81.030815569906" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="4955" weight="82.79549477272678" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="4956" weight="87.72583347731539" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="4957" weight="83.94757489585429" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="4958" weight="81.58901594000407" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="4959" weight="87.21961540962795" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="4960" weight="80.77567972876997" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="4961" weight="80.74901534708235" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="4962" weight="82.2565361631983" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="4963" weight="81.19296956674735" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="4964" weight="90.4590971839367" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="4965" weight="82.19408588311991" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="4966" weight="87.586008477007" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="4967" weight="90.13751211016266" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="4968" weight="82.07682043347164" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="4969" weight="85.24154924685212" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="4970" weight="86.0534460342071" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="4971" weight="86.20307655050308" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="4972" weight="85.67383840349618" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="4973" weight="85.45897420013975" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="4974" weight="83.25374991313295" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="4975" weight="84.3958645557662" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="4976" weight="87.3083120469966" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="4977" weight="88.16536601602745" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="4978" weight="85.8034370047942" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="4979" weight="90.6655631713081" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="4980" weight="86.73927323624102" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="4981" weight="84.85456986863709" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="4982" weight="88.52001831383835" />
      <edge source="the focus of the task was to build a probabilistic phrase translation table, since most of the other resources were provided — for more on phrase-based statistical machine translation, refer to koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="4983" weight="85.72487382151435" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " id="4984" weight="85.59957008919798" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="4985" weight="85.96702626843683" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="4986" weight="82.25099054904037" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="4987" weight="84.51906873775081" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="4988" weight="85.63382373588351" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="4989" weight="83.75558772348657" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="4990" weight="85.3693428320304" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="4991" weight="83.44360120216953" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="4992" weight="84.2653554796643" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="4993" weight="86.48615744975656" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="4994" weight="89.69363981393266" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="4995" weight="84.21032268751172" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="4996" weight="87.5389999289533" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="4997" weight="86.20236380129799" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="4998" weight="82.4343038838228" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="4999" weight="87.65578924308106" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5000" weight="80.58643914265353" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5001" weight="86.06945144669386" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5002" weight="84.57956658213004" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5003" weight="82.16174842337279" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5004" weight="90.92850011015732" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5005" weight="83.43064779795411" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5006" weight="81.55057178329676" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5007" weight="83.19073699869261" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="5008" weight="81.32140837067574" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5009" weight="83.94533159195791" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5010" weight="88.48408562851684" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5011" weight="84.03781404446164" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5012" weight="88.04493240862301" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5013" weight="84.62798845631563" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5014" weight="86.28248655015899" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5015" weight="85.12126502516806" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5016" weight="82.05842347706084" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5017" weight="82.76124703000652" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5018" weight="84.51686111000672" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5019" weight="83.26152722213213" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5020" weight="81.40062487090125" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5021" weight="81.1740741086872" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5022" weight="82.08043602503143" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5023" weight="80.99277938558306" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5024" weight="88.22313694375256" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5025" weight="81.32280677930414" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5026" weight="89.67704331225323" />
      <edge source="in this project we use the model described by koehn et al (2003) which extracts its phrase alignments from a corpus that has been word aligned. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5027" weight="83.32171860249515" />
      <edge source="on smaller data sets (koehn et al, 2003) the joint model shows performance comparable to the standard model, however the joint model does not reach the level of performance of the stan156 en-es es-en joint 3-gram, dl4 20.51 26.64 5-gram, dl6 26.34 27.17 + lex. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="5028" weight="82.10142868900196" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="5029" weight="82.30285221655755" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="5030" weight="86.14535948318806" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="5031" weight="82.15945809132225" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="5032" weight="83.75882092461097" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="5033" weight="87.52273774474624" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5034" weight="80.4638095200584" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5035" weight="86.39681013486302" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5036" weight="82.89631123326117" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="791 and score the alignment template model phrases (koehn et al, 2003). " id="5037" weight="80.5472300797576" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5038" weight="86.15529640837217" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="5039" weight="83.01023072362015" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5040" weight="80.78935387710166" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5041" weight="82.29925656455191" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5042" weight="82.22568589384251" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5043" weight="81.13338567470872" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5044" weight="84.66220858690485" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5045" weight="81.20537150496767" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="5046" weight="82.56157668976736" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5047" weight="81.33442374190571" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5048" weight="90.75772185666867" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5049" weight="82.54703418899342" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5050" weight="89.03733750638546" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="5051" weight="80.56257763139428" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5052" weight="81.13911202121527" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5053" weight="85.09033593196264" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5054" weight="85.23824526507222" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5055" weight="82.03927051810535" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5056" weight="80.29534376511211" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5057" weight="85.39559030435701" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5058" weight="85.00969115270985" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5059" weight="80.44306677027389" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="5060" weight="82.24176185666701" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5061" weight="83.29050313022903" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5062" weight="84.10143129576286" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5063" weight="80.11312760891268" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="details of this model are described by koehn et al (2003). " id="5064" weight="81.60016887370172" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5065" weight="87.93163634599566" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5066" weight="85.27884215761252" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5067" weight="87.18155412434785" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5068" weight="87.90238173577316" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5069" weight="85.75370064366028" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5070" weight="88.90710223700897" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5071" weight="90.11887538789219" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5072" weight="90.04944045890126" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5073" weight="89.83494497664385" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5074" weight="88.61097374128317" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5075" weight="86.95641715027533" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5076" weight="93.26605972402979" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5077" weight="90.39953803924725" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5078" weight="87.98023942878484" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5079" weight="89.14639193696677" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5080" weight="80.6629918513692" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="5081" weight="84.9974291294068" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="5082" weight="83.36191580876022" />
      <edge source="most phrase-based translation models (och, 2003; koehn et al, 2003; vogel et al, 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5083" weight="80.16316321980736" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " id="5084" weight="86.04211727820021" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="5085" weight="83.2890196603682" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="5086" weight="81.43131440780746" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="5087" weight="84.27682581387307" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5088" weight="90.97687250958116" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5089" weight="83.87499856644378" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5090" weight="88.35948461625888" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5091" weight="82.96544920825255" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5092" weight="84.03731629567875" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5093" weight="88.57298664595376" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5094" weight="84.7550963581489" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5095" weight="87.99062042948218" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5096" weight="88.05763227578308" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5097" weight="82.4853197090501" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5098" weight="80.44131889274688" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5099" weight="83.24824098255084" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5100" weight="80.81162422396504" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5101" weight="82.28432391434231" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5102" weight="84.03525383228904" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5103" weight="84.43712039933855" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5104" weight="81.75195453788898" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5105" weight="82.71325497211618" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5106" weight="85.8371582429858" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5107" weight="83.78165173510534" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5108" weight="87.02562204694264" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5109" weight="80.90035675043221" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5110" weight="83.69473412314466" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5111" weight="82.77793206170061" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5112" weight="80.8777191016993" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5113" weight="83.61303135864206" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5114" weight="81.56908974238885" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5115" weight="81.41864351996753" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5116" weight="84.60022188639553" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5117" weight="80.29485578063904" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5118" weight="86.59126125429222" />
      <edge source="the impact of constraining the joint model trained on 10,000 sentences of the german-english europarl corpora and tested with the europarl test set used in koehn et al (2003) than 10 million times that of the phrase pair with the highest count, are pruned from the phrase table. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5119" weight="83.32549565127401" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " id="5120" weight="81.25995852604075" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " id="5121" weight="81.13194634387841" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " id="5122" weight="83.59575527725029" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="5123" weight="83.06984821192773" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="5124" weight="85.25572887410911" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="5125" weight="80.51653933542038" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5126" weight="85.12887460351912" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5127" weight="84.20605396434372" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5128" weight="85.4359268345664" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5129" weight="87.77270220408309" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5130" weight="83.74364032626373" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5131" weight="85.05849997579472" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5132" weight="88.29330621734182" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5133" weight="83.49882105096718" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5134" weight="80.4007157563727" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5135" weight="88.44624255421645" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5136" weight="82.70371625748143" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5137" weight="86.61075568439622" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5138" weight="82.11402142091629" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5139" weight="80.08363709876944" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5140" weight="80.07721044330872" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5141" weight="88.07495479055909" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5142" weight="85.9289697277797" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5143" weight="84.39005069005366" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5144" weight="86.66943218313254" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5145" weight="83.17628023794848" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5146" weight="84.51284853662338" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5147" weight="85.30019252888232" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5148" weight="81.71024120063639" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5149" weight="80.70024834452308" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5150" weight="81.7878053390163" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5151" weight="85.1240441279048" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5152" weight="82.67885313237633" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5153" weight="87.27095461890046" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5154" weight="83.58782445696158" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5155" weight="81.1873148206198" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5156" weight="80.52095850535672" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5157" weight="85.30291656009265" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5158" weight="83.37863193897749" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5159" weight="81.00436766739254" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5160" weight="86.46871193251187" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5161" weight="82.42079379416656" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5162" weight="81.06344155502603" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5163" weight="82.3765922250573" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5164" weight="82.11337480791074" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5165" weight="80.28226069429965" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5166" weight="82.74419133970015" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5167" weight="84.67431290659933" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5168" weight="87.23048101000512" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5169" weight="82.45113020028074" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5170" weight="80.58435803345544" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5171" weight="84.436713918082" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5172" weight="87.03346313004445" />
      <edge source="for the future, the joint model would benefit from lexical weighting like that used in the standard model (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5173" weight="80.55480322714159" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="5174" weight="82.45091624028571" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="5175" weight="85.28539867805843" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5176" weight="84.24345150889532" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5177" weight="83.35866547415564" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5178" weight="88.42684609770129" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5179" weight="88.13600618813398" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5180" weight="80.05332339975185" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5181" weight="82.4657521553874" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5182" weight="83.62247850178512" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5183" weight="82.81504967495732" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5184" weight="80.14396475407372" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="5185" weight="87.82735171925057" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5186" weight="81.31279272213128" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5187" weight="80.73400148744926" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5188" weight="84.79301638098245" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5189" weight="86.12205164325262" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5190" weight="82.82791214649869" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5191" weight="80.46612689985686" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5192" weight="81.45356944637885" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5193" weight="81.57997418493832" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5194" weight="81.03263738537896" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5195" weight="84.53445511148605" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5196" weight="80.32371226195811" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5197" weight="85.74609334154371" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5198" weight="83.6329236309404" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5199" weight="80.64618692215288" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5200" weight="80.95789479761777" />
      <edge source="baseline pharaoh with phrases extracted from ibm model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (koehn et al, 2003a) lex phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with lhs x, the glue rule, and a binary reordering rule with its own reordering-feature • xcat all nonterminals merged into a single x nonterminal: simulation of the system hiero (chiang, 2005). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5201" weight="80.56695903233286" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="5202" weight="80.7699316129725" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " id="5203" weight="81.35864840530391" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="5204" weight="83.9969401826917" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5205" weight="84.27033475099424" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="5206" weight="86.59110480410968" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5207" weight="84.42890797038294" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5208" weight="81.77994669981261" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5209" weight="83.64722401423236" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5210" weight="89.52961526196128" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5211" weight="88.63491764291003" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5212" weight="83.85258294972951" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5213" weight="85.1472009790039" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5214" weight="81.14897125878531" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="5215" weight="83.59225029086836" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5216" weight="81.02729964960761" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="5217" weight="87.60238044847814" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5218" weight="86.9531015217639" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5219" weight="81.34691352495788" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5220" weight="84.2765794442514" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5221" weight="83.90005296318132" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5222" weight="83.17461088200291" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5223" weight="81.91015904898869" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5224" weight="85.1742811743222" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5225" weight="89.54598877011676" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5226" weight="81.20822247880939" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5227" weight="81.56821077878955" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5228" weight="83.48014591463047" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5229" weight="89.95357187938015" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5230" weight="86.42361179716367" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5231" weight="82.94976181597742" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5232" weight="84.3355262619642" />
      <edge source="recent work in machine translation has evolved from the traditional word (brown et al, 1993) and phrase based (koehn et al, 2003a) models to include hierarchical phrase models (chiang, 2005) and bilingual synchronous grammars (melamed, 2004). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="5233" weight="80.18153164869332" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " id="5234" weight="82.59210536865484" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="5235" weight="89.06127418719845" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5236" weight="82.96926134073637" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5237" weight="83.31937108756848" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5238" weight="86.75715907549497" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5239" weight="82.77471317956436" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5240" weight="80.86122174313" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5241" weight="86.7166058418" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5242" weight="80.36589348573018" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5243" weight="88.01732066023243" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5244" weight="85.80309314329779" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5245" weight="80.75138168169404" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5246" weight="84.79858565161021" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5247" weight="87.22151705648584" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5248" weight="85.80601336003359" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5249" weight="83.5530235024973" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5250" weight="83.74248533887877" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5251" weight="83.71850446140061" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5252" weight="82.98143275185947" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5253" weight="87.01979365066366" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5254" weight="80.47373594724701" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5255" weight="82.54035601696567" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5256" weight="81.25784103451885" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5257" weight="80.06267248428784" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5258" weight="84.62898737991826" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5259" weight="80.81173798836969" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5260" weight="82.99876427300387" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5261" weight="81.24891495335449" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5262" weight="82.50236251870294" />
      <edge source="we present results that compare our system against the baseline pharaoh implementation (koehn et al, 2003a) and mer training scripts provided for this workshop. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5263" weight="82.09191462800626" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " id="5264" weight="90.03806730200581" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5265" weight="81.66894872521355" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5266" weight="84.66761128965699" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5267" weight="83.3251129534393" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5268" weight="83.98118329477676" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5269" weight="83.49501572442384" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5270" weight="80.46430579275463" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5271" weight="80.47858147948315" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5272" weight="80.87518607324955" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5273" weight="82.77284919225363" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5274" weight="82.32527801288545" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5275" weight="80.12867442975084" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5276" weight="88.91205798062593" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5277" weight="80.38768257420128" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5278" weight="83.28498734375145" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5279" weight="80.98636883925272" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5280" weight="81.36758711837375" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5281" weight="81.39902942632733" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5282" weight="84.72994807618848" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5283" weight="84.83930640323041" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5284" weight="80.50526066258851" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5285" weight="80.67160734646255" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5286" weight="82.00209605622324" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5287" weight="80.74064319078404" />
      <edge source="the hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (koehn et al, 2003a). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5288" weight="81.54894625719662" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " id="5289" weight="83.0885037113408" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5290" weight="88.08977899385775" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5291" weight="88.17086756982162" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5292" weight="90.27908339356831" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5293" weight="87.8942113498207" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5294" weight="83.83543674398494" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5295" weight="86.1077303342416" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5296" weight="87.64583348260062" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5297" weight="86.96780962500287" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5298" weight="83.2157861319946" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5299" weight="86.9386365865293" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5300" weight="84.0214155289941" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="5301" weight="81.23702993233073" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5302" weight="85.56944377356601" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5303" weight="84.49266527306017" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5304" weight="81.42526795464403" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5305" weight="81.17287333936262" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5306" weight="82.35048633384568" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5307" weight="84.76762857580502" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5308" weight="80.34320464412501" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5309" weight="89.86325830212267" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5310" weight="87.37363010310821" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5311" weight="84.60983524709809" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5312" weight="86.40104833071464" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5313" weight="81.08272419688359" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5314" weight="82.0670651709144" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5315" weight="84.62101763631958" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5316" weight="82.98653154538731" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5317" weight="84.78498900008653" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5318" weight="84.56915817219024" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5319" weight="90.85790786740617" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5320" weight="80.22416062482161" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5321" weight="81.13118422882852" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5322" weight="87.13443646199099" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5323" weight="86.08018564300484" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5324" weight="80.71631212694727" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5325" weight="86.52642969084474" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5326" weight="83.36816051879936" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5327" weight="83.3390548364124" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5328" weight="80.67561639282115" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5329" weight="85.17730314669598" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5330" weight="85.49581482756408" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5331" weight="84.15904141781667" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5332" weight="82.81491123680351" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5333" weight="82.33325349130018" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5334" weight="83.74833757292788" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5335" weight="85.17923087092123" />
      <edge source="138 2 rule generation we start with phrase translations on the parallel training data using the techniques and implementation described in (koehn et al, 2003a). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5336" weight="83.82434887007241" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " id="5337" weight="82.81164461573216" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5338" weight="82.92459611401102" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="5339" weight="82.01010914156419" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5340" weight="84.42636510535482" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5341" weight="84.40069073318736" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="5342" weight="81.75724875648056" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5343" weight="81.05086344039667" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5344" weight="88.94405006226904" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5345" weight="87.64884716647907" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5346" weight="84.64229618149173" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="5347" weight="96.29268484041135" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5348" weight="84.58682070555798" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5349" weight="88.5196432332804" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5350" weight="82.7458030847031" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5351" weight="83.06377929418281" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="5352" weight="82.25723231963553" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5353" weight="82.50027242670708" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5354" weight="84.05972018261245" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5355" weight="82.40266692870715" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5356" weight="83.48430784761563" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5357" weight="85.68899609150509" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5358" weight="83.57028108159183" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5359" weight="83.67107575091599" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5360" weight="89.8906405280369" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5361" weight="83.13454971493029" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5362" weight="83.44844464051006" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5363" weight="85.25795558272031" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5364" weight="85.43865435671636" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5365" weight="82.72226531580615" />
      <edge source="to evaluate neuralign, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)) as input and a refined alignment approach (och and ney, 2000) that uses a heuristic combination method called grow-diagfinal (koehn et al, 2003) for comparison. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5366" weight="80.10306731002785" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " id="5367" weight="83.99861590767034" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5368" weight="89.30366022929823" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5369" weight="81.25693208756712" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5370" weight="86.30763385761104" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="5371" weight="83.11152540077494" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5372" weight="80.18001343075368" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5373" weight="85.36139438905627" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5374" weight="81.06605046957675" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5375" weight="82.61278385128313" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5376" weight="83.97207524367059" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5377" weight="82.93097935746007" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5378" weight="90.12513339025882" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5379" weight="87.97645078494583" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5380" weight="80.82935347838354" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5381" weight="85.15110342687224" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5382" weight="83.73273368942309" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5383" weight="81.99762036554243" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5384" weight="82.08910351473442" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5385" weight="81.10075714159439" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5386" weight="84.31988634690444" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5387" weight="89.78727823643304" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5388" weight="81.95253012665505" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5389" weight="82.4893087881875" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5390" weight="80.02320586458671" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5391" weight="81.6200739399766" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5392" weight="86.85738265001761" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5393" weight="81.87656139076216" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5394" weight="86.15152135735349" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5395" weight="86.6762210918212" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5396" weight="86.11981507237527" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5397" weight="81.36784950024362" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5398" weight="89.05476627398707" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5399" weight="84.7928056199658" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5400" weight="93.27160921933428" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5401" weight="86.60279511330211" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5402" weight="81.6408986678973" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5403" weight="86.63862867309288" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5404" weight="92.44478454747758" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5405" weight="81.80146379487394" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="5406" weight="83.33449381679947" />
      <edge source="2 the problem of coverage in smt statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5407" weight="83.17029484972582" />
      <edge source="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " target="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " id="5408" weight="84.41415535714548" />
      <edge source="for comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) intersection of both directions (aligner(int)); (2) union of both directions (aligner(union)); and (3) the previously bestknown heuristic combination approach called growdiag-final (koehn et al, 2003) (aligner(gdf)). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5409" weight="82.85776347904911" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " id="5410" weight="89.9640303468332" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5411" weight="90.794892549562" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5412" weight="88.05768225572008" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5413" weight="87.8940664678018" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5414" weight="91.18827447135868" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5415" weight="86.80452906040014" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5416" weight="91.92537863685017" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5417" weight="81.61851040736592" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5418" weight="89.4595197212559" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5419" weight="86.32157784915783" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="5420" weight="81.63771078069824" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5421" weight="86.1106044986452" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5422" weight="84.37393512119723" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5423" weight="82.0851817345696" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5424" weight="82.49173866257064" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5425" weight="86.24018283461517" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5426" weight="86.47407133004961" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5427" weight="87.6158901910115" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5428" weight="84.17589661883702" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5429" weight="87.54068377218458" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5430" weight="81.18247781037648" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5431" weight="83.71271214380668" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5432" weight="80.68467928264266" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5433" weight="80.42912033260701" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5434" weight="87.04970072560508" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5435" weight="81.3549895155494" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5436" weight="80.11170060011672" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5437" weight="88.60636999823342" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5438" weight="84.18451047378296" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5439" weight="86.628129467578" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5440" weight="87.01141774677987" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5441" weight="85.15921198434222" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5442" weight="86.78237104937469" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5443" weight="86.84055682473833" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5444" weight="82.23281984386752" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5445" weight="84.63615941053997" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5446" weight="84.42719793027014" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5447" weight="82.01998974051993" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5448" weight="82.1105824377276" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5449" weight="88.3628252547341" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5450" weight="87.67893718195587" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5451" weight="84.8121260903163" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5452" weight="88.60863531421965" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5453" weight="83.04379286141712" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5454" weight="84.67709494569621" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5455" weight="87.40674951964493" />
      <edge source="during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4. based on the observations in (koehn et al, 2003), we also limited the phrase length to 3 for computational reasons. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5456" weight="80.06844046845332" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " id="5457" weight="88.69283177767093" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5458" weight="89.85121009847028" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5459" weight="88.0222737593585" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5460" weight="87.81966485669169" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5461" weight="83.82759770999839" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5462" weight="88.15207864832615" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5463" weight="89.44209720783407" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5464" weight="86.39191004916363" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5465" weight="87.47784079729742" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5466" weight="92.23141209578594" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5467" weight="83.84664241244337" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5468" weight="81.26663111807808" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5469" weight="80.34329514124805" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5470" weight="87.66585780604433" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5471" weight="86.31327251500494" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5472" weight="88.81719432602387" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5473" weight="88.98221440041875" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5474" weight="85.44393619550807" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5475" weight="90.52229715754459" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5476" weight="83.32335872391714" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5477" weight="86.61388132666734" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5478" weight="85.19384669556302" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5479" weight="83.7109284549516" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="5480" weight="84.70560530675071" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5481" weight="84.34170837240818" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5482" weight="87.49527134891657" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5483" weight="85.13352469018727" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5484" weight="84.27814176003758" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5485" weight="89.82167799561816" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5486" weight="86.12497441977058" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5487" weight="84.90600125973317" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5488" weight="86.58729902914266" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5489" weight="83.20793360561434" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5490" weight="88.26137963154127" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5491" weight="84.22440667502653" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5492" weight="85.01209925766" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5493" weight="88.73180404309082" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5494" weight="88.05553091680454" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5495" weight="85.87204210551953" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5496" weight="89.09594256613913" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5497" weight="85.72196472400033" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5498" weight="86.50566475123536" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5499" weight="91.65715870938966" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5500" weight="92.02476766381812" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5501" weight="87.34538111172895" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5502" weight="87.82918303136988" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5503" weight="87.05259396703953" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5504" weight="89.40794905287366" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5505" weight="84.7447472151967" />
      <edge source="word alignment—detection of corresponding words between two sentences that are translations of each other—is usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; och and ney, 2003; koehn et al, 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5506" weight="86.8379113271204" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5507" weight="81.28393296584966" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5508" weight="84.79673865407129" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5509" weight="85.23930035343061" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5510" weight="80.26506235428062" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="5511" weight="82.35229898788015" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5512" weight="80.59097555071604" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5513" weight="80.44118554861457" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5514" weight="83.18420589350242" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5515" weight="81.71905502624273" />
      <edge source="limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure (niessen and ney, (2004), lee,(2004), yamada and knight (2001), marcu and wong (2002), och and ney (2004),koehn et al (2003), among others.) " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5516" weight="81.5324047883239" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " id="5517" weight="89.57594942080951" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5518" weight="85.2046936069941" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5519" weight="89.25836562435762" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5520" weight="87.83174817571965" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5521" weight="87.87001844278446" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5522" weight="86.33928099272374" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5523" weight="89.8403089798161" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="5524" weight="80.05089713029001" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5525" weight="83.63433810835417" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="5526" weight="86.7891043658946" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5527" weight="88.36065253295659" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5528" weight="84.87356216390813" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5529" weight="82.68755841688278" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5530" weight="83.21261536412025" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5531" weight="84.73376512843357" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5532" weight="87.62612634958103" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5533" weight="80.32297582876807" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5534" weight="89.80306636175628" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5535" weight="89.68078596943889" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5536" weight="86.64930580244562" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5537" weight="86.34950999430386" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5538" weight="82.05030410289196" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5539" weight="85.18629988514594" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5540" weight="84.64195344970109" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5541" weight="81.77682601252678" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5542" weight="86.26914130618648" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="5543" weight="80.10186267362332" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5544" weight="85.5789952946216" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5545" weight="80.64483940175775" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="5546" weight="82.13763595514175" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5547" weight="92.80865943773635" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5548" weight="86.09071430726571" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5549" weight="82.91940375896749" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5550" weight="86.87709663705026" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5551" weight="83.95571851594823" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5552" weight="88.41222923603587" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5553" weight="84.20314979108807" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5554" weight="84.15299736734671" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5555" weight="88.3407163587781" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5556" weight="81.97863799556929" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5557" weight="81.39510624191995" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5558" weight="88.01700335932314" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5559" weight="83.88301166179856" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5560" weight="81.8387659681462" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5561" weight="86.86836509064155" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5562" weight="87.10245341168921" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5563" weight="88.8150674003657" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5564" weight="84.11853764465147" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5565" weight="81.2161695092196" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5566" weight="84.71899875113044" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5567" weight="87.29670457489615" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="5568" weight="80.85354235041319" />
      <edge source="we proceeded with the following sequence of experiments: (1) baseline: as a baseline system, we used a pure word-based approach and used pharaoh training tool (2004), to train on the 22,500 sentences, and decoded using pharaoh (koehn et al, 2003) to obtain translations for a test set of 50 sentences. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5569" weight="83.15318638678959" />
      <edge source="791 and score the alignment template model phrases (koehn et al, 2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5570" weight="81.09865906375371" />
      <edge source="791 and score the alignment template model phrases (koehn et al, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5571" weight="82.01704572421991" />
      <edge source="791 and score the alignment template model phrases (koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="5572" weight="83.13862016883166" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " id="5573" weight="80.05207436950256" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " id="5574" weight="82.51195515537204" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5575" weight="87.57903863095235" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5576" weight="86.03664640739336" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5577" weight="86.76781292953476" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5578" weight="88.9091362741292" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5579" weight="85.04544572398818" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5580" weight="84.22064487218366" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="5581" weight="83.63825847099824" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5582" weight="91.56154387258803" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5583" weight="80.9731099780417" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5584" weight="85.36749866218156" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5585" weight="81.66145135233958" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5586" weight="84.22614247363553" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5587" weight="84.76783907647389" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5588" weight="88.55546441992135" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5589" weight="87.18758418227597" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5590" weight="85.30799504626133" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5591" weight="85.12094968699225" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5592" weight="84.5510702589294" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5593" weight="86.82568920446263" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5594" weight="88.56961236170532" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5595" weight="84.43341090818129" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5596" weight="81.6183406739585" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="5597" weight="81.23063498080639" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5598" weight="84.72138904641801" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5599" weight="86.66671956202947" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5600" weight="82.21254583770757" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5601" weight="83.66113511527577" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5602" weight="88.28914687053626" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5603" weight="84.6637743107933" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5604" weight="81.565459345742" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5605" weight="86.8654195474709" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5606" weight="83.48116955558575" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5607" weight="87.18773187061157" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5608" weight="82.23177283926061" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5609" weight="81.13261079175706" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5610" weight="87.52590187305404" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5611" weight="85.7517134085023" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5612" weight="82.99520393027234" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5613" weight="88.50061077742122" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5614" weight="86.6258335877094" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5615" weight="84.89384214040834" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5616" weight="88.59295536432086" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5617" weight="89.96939776549515" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5618" weight="89.39349003039155" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5619" weight="82.71256855594554" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5620" weight="83.87974349805205" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5621" weight="86.57329723222504" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5622" weight="88.02349329076789" />
      <edge source="the features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (koehn et al, 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using kneser-ney smoothing as implemented in the srilm toolkit (stolcke, 2002). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5623" weight="83.80024391025414" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5624" weight="80.2475206774409" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5625" weight="86.96900449031946" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5626" weight="86.97221528283721" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5627" weight="81.57255974815078" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5628" weight="84.40275739705348" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5629" weight="81.71214082554035" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5630" weight="83.22186570860428" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5631" weight="81.96521318872003" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5632" weight="81.48053516070402" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5633" weight="87.98835386697333" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5634" weight="82.01145665581151" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5635" weight="81.80655723832172" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5636" weight="84.72662138163498" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5637" weight="83.47073880698184" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5638" weight="82.13235585956818" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5639" weight="83.06236459617095" />
      <edge source="this is the traditional approach for glass-box smoothing (koehn et al, 2003; zens and ney, 2004). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="5640" weight="80.47776537412483" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " id="5641" weight="84.89787131821613" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5642" weight="86.6555291808076" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5643" weight="87.29240606226305" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5644" weight="86.61767318460936" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5645" weight="84.78120599179265" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5646" weight="84.64122502378481" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5647" weight="85.93326836415834" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5648" weight="83.70271050669318" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5649" weight="88.74530851392439" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5650" weight="86.4443521097885" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5651" weight="83.50636523853177" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5652" weight="84.70050529657146" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5653" weight="89.66845771482177" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5654" weight="80.12050887470248" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5655" weight="84.01299774173685" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5656" weight="80.35540725929997" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5657" weight="83.73440700629405" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5658" weight="88.13313631228894" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5659" weight="81.31180628083736" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5660" weight="87.42316732794902" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5661" weight="85.16919271985337" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5662" weight="80.87746561926643" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5663" weight="87.90086791647471" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5664" weight="84.98593959352971" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5665" weight="81.3438782947481" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5666" weight="83.97060689458051" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5667" weight="83.01181515758711" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5668" weight="86.40046919311628" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5669" weight="84.63281783644075" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5670" weight="81.16400563896788" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5671" weight="91.59283295523042" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5672" weight="83.66939257751802" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5673" weight="84.73676175415024" />
      <edge source="1while the improvements to translation quality reported in koehn et al (2003) are minor, their evaluation metric may not have been especially sensitive to adding longer phrases. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5674" weight="82.57912358632598" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " id="5675" weight="88.7994966462446" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5676" weight="86.65436034204252" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " id="5677" weight="80.77814910290041" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5678" weight="87.61866339638007" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5679" weight="83.42055340745928" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5680" weight="88.64017195340257" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5681" weight="84.03587307344993" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5682" weight="83.55820221464315" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5683" weight="82.9567199639311" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5684" weight="80.10673574831712" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5685" weight="82.26072335320845" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5686" weight="87.60159784982523" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5687" weight="86.1381416321146" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5688" weight="86.15768260794661" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5689" weight="80.51032394741245" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5690" weight="80.98507863381445" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5691" weight="81.49774054057386" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5692" weight="82.81282299967496" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="5693" weight="81.2897274009457" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5694" weight="82.80852518677312" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5695" weight="86.7488070741534" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5696" weight="86.68891546704191" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5697" weight="84.63766428907849" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5698" weight="89.80371590225302" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5699" weight="87.01765182062078" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5700" weight="85.24693064903184" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5701" weight="84.64243046917443" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5702" weight="80.05712893973826" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5703" weight="89.44453518578088" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5704" weight="81.99248355357551" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5705" weight="85.02193311418102" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5706" weight="85.52376857394685" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5707" weight="82.7063660231136" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5708" weight="81.35589618501444" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5709" weight="88.41403932119638" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5710" weight="82.6267145652797" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5711" weight="84.70070901500183" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5712" weight="86.67364800857065" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5713" weight="88.01133618108705" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5714" weight="85.1158262838665" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5715" weight="85.39785435033191" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5716" weight="82.62022740274224" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5717" weight="85.4950553597918" />
      <edge source="table 4 gives statistics about phrases which occur more than once in the english section of the europarl corpus (koehn, 2002) which was used in the koehn et al (2003) experiments. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5718" weight="89.2876644060764" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " id="5719" weight="85.93003239283749" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5720" weight="88.88316149454482" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="5721" weight="80.22714281145626" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5722" weight="82.58759143445565" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5723" weight="83.98286200184262" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5724" weight="87.47546507219752" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5725" weight="84.09112106982164" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5726" weight="85.81095726098138" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5727" weight="87.21940005841631" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5728" weight="82.03707813981092" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5729" weight="85.19306961815876" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5730" weight="87.15722774354002" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5731" weight="82.22716751382693" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5732" weight="80.73543756426737" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5733" weight="83.9228460227871" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5734" weight="80.72790946455063" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5735" weight="83.12617850034098" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5736" weight="88.84568903590771" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5737" weight="83.8880714993287" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5738" weight="80.81913597184128" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5739" weight="88.96904787042" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5740" weight="80.44170654510224" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5741" weight="84.83808275418514" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5742" weight="88.15816097601376" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5743" weight="87.13281415510974" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5744" weight="82.65834411756276" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5745" weight="86.75827651648247" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5746" weight="82.35750972006046" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5747" weight="84.28528509182908" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5748" weight="84.22265959305749" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5749" weight="80.67134006878429" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5750" weight="80.81233716612539" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5751" weight="84.77254785780286" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5752" weight="84.65890362618545" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5753" weight="84.98856055034632" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5754" weight="81.65943063041404" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5755" weight="82.71153159745712" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5756" weight="90.53458036193666" />
      <edge source="the framework that we used to calculate the translation probabilities was similar to that detailed in koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5757" weight="82.96006469110104" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " id="5758" weight="86.70307472722787" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5759" weight="87.01452283434878" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5760" weight="84.25506774021837" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5761" weight="84.13284002829855" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5762" weight="80.07474089034703" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5763" weight="81.8606384521052" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5764" weight="85.63317845446419" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5765" weight="86.57307412230675" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5766" weight="84.45391499542758" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5767" weight="82.48232198498637" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5768" weight="86.47832761420557" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5769" weight="81.516182263682" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5770" weight="84.90165244231602" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5771" weight="80.14403763758109" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5772" weight="80.21622777320563" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5773" weight="84.05930517615292" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5774" weight="81.22684678636085" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5775" weight="80.7032885582813" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5776" weight="86.63215951746979" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5777" weight="84.03071044886327" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5778" weight="85.89394075519614" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5779" weight="84.21588183354898" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5780" weight="88.45672946226453" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5781" weight="84.92590224049647" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5782" weight="80.08281931103834" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5783" weight="84.59024770772692" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5784" weight="82.94995956873493" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5785" weight="80.22355200417628" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5786" weight="87.41340841986623" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5787" weight="86.29397847238145" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5788" weight="81.3111221212409" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5789" weight="87.29056224288104" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5790" weight="82.12986782491004" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5791" weight="81.99888742811177" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5792" weight="84.87428890982069" />
      <edge source="based on their analysis of the relationship between translation quality and phrase length, koehn et al (2003) suggest limiting phrase length to three words or less. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5793" weight="80.83235358832927" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5794" weight="81.2713491637429" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5795" weight="91.11321693632834" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5796" weight="82.41094289686642" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5797" weight="86.74855636580358" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="5798" weight="83.90620855183577" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5799" weight="85.29551767953467" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5800" weight="87.49066453207564" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5801" weight="82.55821738851029" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5802" weight="82.40792587126711" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5803" weight="84.7098167974323" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5804" weight="83.19264654548955" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5805" weight="80.35898597844037" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="5806" weight="83.21864408436583" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5807" weight="82.51450376055469" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5808" weight="81.4124305439194" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5809" weight="80.5088056631227" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5810" weight="84.38386180031867" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5811" weight="83.42890305269263" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5812" weight="90.13227696207254" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5813" weight="85.59746717002838" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5814" weight="83.27446783631282" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5815" weight="82.7117718451217" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5816" weight="84.34046361444155" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5817" weight="88.95729738795002" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5818" weight="81.52290876298277" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5819" weight="85.85407353469454" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5820" weight="87.47133527052809" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5821" weight="88.33869401936542" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5822" weight="87.97315302881712" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5823" weight="80.19275947087314" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5824" weight="84.48773575437785" />
      <edge source="our system is a re-implementation of the phrase-based system described in koehn (2003), and uses publicly available components for word alignment (och and ney, 2003)1, decoding (koehn, 2004a)2, language modeling (stolcke, 2002)3 and finite-state processing (knight and al-onaizan, 1999)4. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5825" weight="81.2511741074547" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="for acquiring a pbm, we followed the approach described by koehn et al (2003). " id="5826" weight="80.49668514470127" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " id="5827" weight="82.8042928229391" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " id="5828" weight="81.2590269085407" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5829" weight="86.54667319341326" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5830" weight="86.2879273344762" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5831" weight="87.98928791411296" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5832" weight="88.56259735683838" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5833" weight="83.66013005398794" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5834" weight="89.1094216984859" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5835" weight="88.44101969136176" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5836" weight="86.97692015990259" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5837" weight="88.42546952368092" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5838" weight="82.22149103209074" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5839" weight="81.95381245103619" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5840" weight="87.76352174442219" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5841" weight="82.38207399698054" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5842" weight="80.76344611597665" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5843" weight="92.66646883342986" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5844" weight="85.34734919868447" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5845" weight="84.96583071383397" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5846" weight="82.55479582446516" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5847" weight="87.3096526861097" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5848" weight="82.61947748289504" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5849" weight="85.3011550138478" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5850" weight="89.94582418444502" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5851" weight="83.55586927533109" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5852" weight="81.90249498528337" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5853" weight="82.13737206351112" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5854" weight="80.3232454212905" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5855" weight="81.89701670282989" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5856" weight="85.11634316764254" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5857" weight="87.28825947124488" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5858" weight="84.55383195480893" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5859" weight="86.43050333235851" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5860" weight="80.66002417305187" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5861" weight="86.73970633727683" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5862" weight="85.88802030504061" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="5863" weight="80.85969986425702" />
      <edge source="we used the word alignment produced by giza (och and ney, 2000) out of an ibm model 2. we did try to use the alignment produced with ibm model 4, but did not notice significant differences over our experiments; an observation consistent with the findings of koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5864" weight="80.6562675758855" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5865" weight="83.43101347101735" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5866" weight="80.16039842639215" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5867" weight="82.13498761206527" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5868" weight="80.03729887478619" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5869" weight="81.14242907208349" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5870" weight="84.24070039452631" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5871" weight="81.29087039087293" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5872" weight="80.89747540920871" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="details of this model are described by koehn et al (2003). " id="5873" weight="84.53357486583104" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5874" weight="82.62998511375147" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5875" weight="81.09345211863379" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5876" weight="85.47864819496303" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5877" weight="85.22588644993515" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5878" weight="83.76904956496358" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5879" weight="81.35599688353581" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5880" weight="83.43289458621221" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5881" weight="83.69874407190952" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5882" weight="83.15668405240191" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5883" weight="82.59727414997451" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5884" weight="83.0945151711249" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5885" weight="80.57672374019266" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5886" weight="81.73424936075733" />
      <edge source="for acquiring a pbm, we followed the approach described by koehn et al (2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="5887" weight="81.65466001330739" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " id="5888" weight="84.04913175629392" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " id="5889" weight="82.28101046632487" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5890" weight="87.24783823810411" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5891" weight="85.10056909939068" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5892" weight="81.72871132016195" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5893" weight="82.7641276392374" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5894" weight="87.58263636806775" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5895" weight="81.64515216371836" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5896" weight="82.9975911166596" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5897" weight="83.64834797817362" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5898" weight="80.42621305939744" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5899" weight="80.25879086417073" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5900" weight="83.70887915850527" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5901" weight="81.17938858242123" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5902" weight="84.1063798850676" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5903" weight="84.58405796152424" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5904" weight="85.4819442562619" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5905" weight="84.23533327141068" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5906" weight="83.74695344634378" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5907" weight="86.61944638673451" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5908" weight="81.89648039344539" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5909" weight="85.6053575236964" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5910" weight="83.82519656580084" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5911" weight="81.26755494560886" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5912" weight="80.02038098235253" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5913" weight="86.63558975979014" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5914" weight="82.58630151658284" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5915" weight="85.64917807668371" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5916" weight="83.50904691370624" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5917" weight="83.37416778316748" />
      <edge source="(koehn et al, 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5918" weight="81.26792203704984" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " id="5919" weight="83.1812586463257" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5920" weight="82.950465206676" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5921" weight="84.49421260249797" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5922" weight="80.51143898042778" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5923" weight="82.48891876094862" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5924" weight="80.45303779763506" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5925" weight="80.68766242888168" />
      <edge source="the pharaoh decoder (koehn, 2003) use an alternative 66 figure 2: flow chart associated to the expansion of a hypothesis when using a multi-stack algorithm. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5926" weight="82.0618380724961" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5927" weight="83.7783872708147" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5928" weight="85.35856399303515" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5929" weight="91.464592496433" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " id="5930" weight="82.5354789650063" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5931" weight="85.79261784083188" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5932" weight="91.03066319732139" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5933" weight="85.43763971972733" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5934" weight="86.32129111034672" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="5935" weight="82.46993774399907" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="5936" weight="87.70815466164024" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="5937" weight="83.09885805792882" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="5938" weight="82.58793417658823" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="5939" weight="83.68771434471445" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="5940" weight="80.49663978342964" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="5941" weight="84.08347461587621" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5942" weight="82.2530534673165" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5943" weight="88.4876592053517" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="5944" weight="84.40238925411501" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="details of this model are described by koehn et al (2003). " id="5945" weight="80.03866469458191" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="5946" weight="89.02820817992601" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5947" weight="90.14408395877504" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="5948" weight="89.75495772810058" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5949" weight="83.04061774297618" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5950" weight="82.0805505436008" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="5951" weight="86.51814178553823" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5952" weight="90.53798761224803" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="5953" weight="88.50879932565459" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5954" weight="81.04395898158965" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5955" weight="89.70636472956828" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="5956" weight="92.69869578857717" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5957" weight="81.07097315999357" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5958" weight="93.56570715112258" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="5959" weight="86.5389928631779" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="5960" weight="90.00493545250625" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="5961" weight="91.27123455746944" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5962" weight="94.29084555870648" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="5963" weight="90.8077556029985" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5964" weight="84.43633404893542" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="5965" weight="86.54874983943924" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="5966" weight="91.53886972381457" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5967" weight="85.95716961653427" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="5968" weight="83.8301764911261" />
      <edge source="on the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (yamada and knight, 2001) , alignment templates are used in (och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (pbt) in (marcu and wong, 2002; zens et al, 2002; koehn et al, 2003; tom´as and casacuberta, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5969" weight="80.8763417332888" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " id="5970" weight="83.62949451539579" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5971" weight="84.80948832852582" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5972" weight="85.77671390101125" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5973" weight="87.62021015895552" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5974" weight="88.30025561841619" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="5975" weight="87.86780554258107" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="5976" weight="81.30546452588518" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="5977" weight="88.20271225005376" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="5978" weight="85.46001261080202" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5979" weight="86.72590970157745" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="5980" weight="82.13849479872839" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="5981" weight="83.63355298566549" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="5982" weight="81.6227084086687" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="5983" weight="83.04300596341949" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="5984" weight="80.9987274817211" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="5985" weight="80.35939913663033" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="5986" weight="85.20544294396394" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="5987" weight="86.67899322407875" />
      <edge source="koehn et al (2003a) showed that translation quality is very sensitive to how this table is extracted from the training data. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="5988" weight="82.83216249538545" />
      <edge source="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " target="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " id="5989" weight="82.67712375605542" />
      <edge source="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5990" weight="83.46395578620596" />
      <edge source="the system follows the structure proposed in the documentation for the pharaoh decoder and uses many publicly available components (koehn, 2003b). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5991" weight="81.06008918575631" />
      <edge source="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5992" weight="84.19064647188215" />
      <edge source="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="5993" weight="80.26491710334145" />
      <edge source="pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models (koehn, 2003b). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="5994" weight="81.2588015136874" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " id="5995" weight="84.41277460040206" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " id="5996" weight="80.03544731317731" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="5997" weight="84.20981181032599" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="5998" weight="84.43184768564814" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="5999" weight="85.15581108054403" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="6000" weight="80.56082974596723" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6001" weight="83.54058267142739" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6002" weight="81.61421052872055" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6003" weight="87.84155922579724" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6004" weight="83.75750796776553" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6005" weight="82.24538224951839" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6006" weight="82.05826228527985" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6007" weight="81.66533393247202" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6008" weight="84.30728316724468" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6009" weight="81.64207670033534" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6010" weight="82.16376991502759" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6011" weight="84.25303437418421" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6012" weight="83.02918316367374" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6013" weight="80.73880241583464" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6014" weight="86.49405217099732" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6015" weight="80.31335147344971" />
      <edge source="while the model and training regimen for φem differ from the model from marcu and wong (2002), we achieved results similar to koehn et al (2003a): φem slightly underperformed φh. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6016" weight="80.0064445772324" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="6017" weight="88.8530346523154" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="6018" weight="84.97272774164011" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="6019" weight="85.79318207583889" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="6020" weight="87.9028924578981" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="6021" weight="81.02638920323082" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="6022" weight="80.6666730218071" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="6023" weight="84.72305854103497" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6024" weight="86.4784322198474" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="6025" weight="84.868935793207" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6026" weight="88.69374300814093" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6027" weight="83.20660923850049" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6028" weight="87.27573463097511" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6029" weight="82.62710813956899" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6030" weight="84.77525290335448" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6031" weight="83.00015041550664" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6032" weight="82.38918658580505" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6033" weight="87.03327040902577" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6034" weight="86.68270613246136" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6035" weight="81.93435645564007" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6036" weight="84.72372167051083" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6037" weight="83.259624277217" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6038" weight="80.552873169676" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6039" weight="82.08474844636132" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6040" weight="87.46281653257742" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6041" weight="84.23639345547507" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6042" weight="84.2039967147284" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6043" weight="89.55382883448404" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6044" weight="82.11143261272989" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6045" weight="84.36402078821908" />
      <edge source="we view this as a particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al, 2003) perform better with higher recall alignments. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6046" weight="84.094666301003" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " id="6047" weight="81.24934180417807" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="6048" weight="86.54489745298481" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="6049" weight="82.67845411932164" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="6050" weight="84.13063076813947" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="6051" weight="80.65647235178459" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6052" weight="86.3780202503392" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="6053" weight="86.27757060521262" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6054" weight="83.66055233601043" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6055" weight="82.65166592733115" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6056" weight="82.16170728244808" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6057" weight="89.09951141131154" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6058" weight="88.23264106201995" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6059" weight="88.26864152199106" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6060" weight="90.97212330929287" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6061" weight="87.80550019153515" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6062" weight="83.40788231579475" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6063" weight="86.33606855509115" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6064" weight="82.05917662900313" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6065" weight="90.02426321949963" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6066" weight="88.91975609621012" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6067" weight="80.25651709969426" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6068" weight="88.91604919276823" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="6069" weight="85.26626365015319" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6070" weight="84.11485715278255" />
      <edge source="most current smt systems (och and ney, 2004; koehn et al, 2003) use a generative model for word alignment such as the freely available giza++ (och and ney, 2003), an implementation of the ibm alignment models (brown et al, 1993). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6071" weight="80.76931080971175" />
      <edge source="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="6072" weight="83.46264097693654" />
      <edge source="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6073" weight="82.2313422801889" />
      <edge source="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6074" weight="83.06034217517609" />
      <edge source="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6075" weight="81.67862897079378" />
      <edge source="for an initial alignment, we used giza++ in both directions (e-to-f and f-to-e, where f is either chinese (c) or spanish (s)), and also two different combined alignments: intersection of e-to-f and f-to-e; and ra using a heuristic combination approach called grow-diag-final (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6076" weight="80.2469145731112" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " id="6077" weight="87.70968867859823" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="6078" weight="85.23070931285375" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="6079" weight="85.91867622802734" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="6080" weight="80.39981754286691" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="6081" weight="82.88540885705329" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="6082" weight="85.58481750939816" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6083" weight="86.9010301666867" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6084" weight="84.95418712192033" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="6085" weight="83.45809039790784" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6086" weight="90.80869589764009" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6087" weight="82.7890425998686" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6088" weight="86.21921384797145" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6089" weight="87.95881495521994" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6090" weight="85.81567950280674" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6091" weight="82.40495274969169" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6092" weight="87.46317612165149" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6093" weight="80.73168669495061" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6094" weight="82.70185594782275" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6095" weight="84.46028455472607" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6096" weight="82.64782781615085" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6097" weight="81.08237769455926" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6098" weight="86.31232920956025" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6099" weight="84.03518690307052" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6100" weight="82.78713813544447" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6101" weight="83.78859324855799" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6102" weight="83.42448889861664" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6103" weight="85.14781056208712" />
      <edge source="the standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (och and ney, 2000; koehn et al, 2003)—henceforth referred to as “ra.” " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6104" weight="81.86915468470701" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " id="6105" weight="84.20117996813707" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="6106" weight="82.7841861022661" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="6107" weight="80.68862366764779" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="6108" weight="84.81367523114407" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="6109" weight="82.22787046848516" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6110" weight="80.08292752988275" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6111" weight="86.5205755178776" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="6112" weight="80.4213918316018" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="6113" weight="80.17400138665163" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="6114" weight="83.2130491757658" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6115" weight="90.59249082742969" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6116" weight="88.30581498351987" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6117" weight="81.4790113358421" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6118" weight="80.13797633574389" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6119" weight="83.42253670238713" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6120" weight="89.71678585183992" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6121" weight="82.48350032233253" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6122" weight="80.80129684689408" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6123" weight="89.66242526762917" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6124" weight="86.67840294640638" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6125" weight="88.82855135380355" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6126" weight="82.78727617809885" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6127" weight="84.79851257803246" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6128" weight="90.17994879718584" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6129" weight="88.76481208089686" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6130" weight="84.99023180946857" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6131" weight="80.97691341301167" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6132" weight="87.46394538106593" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6133" weight="83.81219698536559" />
      <edge source="for our experiments, we chose giza++ (och and ney, 2000) and the ra approach (koehn et al, 2003)— the best known alignment combination technique— as our initial aligners.1 4.2 tbl templates our templates consider consecutive words (of size 1, 2 or 3) in both languages. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6134" weight="82.8076643337869" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " id="6135" weight="87.2328155251837" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="6136" weight="83.92533534948632" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="6137" weight="81.42387712463896" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="6138" weight="82.53083649768023" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="6139" weight="82.84308001561325" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6140" weight="85.66296104399993" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " id="6141" weight="81.90774199597483" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6142" weight="83.32693989642912" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="6143" weight="81.22170318343369" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="6144" weight="82.02830919793843" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6145" weight="88.39843954210211" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6146" weight="81.60835932399783" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6147" weight="82.3704622179007" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6148" weight="84.84258265310334" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6149" weight="82.75362910663127" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6150" weight="84.14337872742455" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6151" weight="81.21609534545213" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6152" weight="83.06740535062151" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6153" weight="86.98350798780459" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6154" weight="83.14519802981228" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6155" weight="81.9368263706955" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6156" weight="87.00994121607401" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6157" weight="84.82393717788395" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6158" weight="80.39160303075539" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6159" weight="84.82964990659158" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6160" weight="86.50250101251078" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6161" weight="85.76690466511552" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6162" weight="82.85986429577873" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6163" weight="82.53234573027137" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6164" weight="84.92591824284916" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6165" weight="86.5069116954568" />
      <edge source="in englishto-german, this result produces results very comparable to a phrasal smt system (koehn et al, 2003) trained on the same data. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6166" weight="83.63995341336843" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " id="6167" weight="81.55861362040339" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="6168" weight="84.43463642591782" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="6169" weight="82.6179596900628" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="6170" weight="83.19925377270216" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="6171" weight="81.16644269770359" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="6172" weight="82.25596676025621" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6173" weight="86.26449995830289" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6174" weight="84.72237199151402" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="6175" weight="81.40690347086131" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " id="6176" weight="83.37429846140756" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6177" weight="89.00659292586765" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6178" weight="85.97229482547924" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6179" weight="87.0361071966722" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6180" weight="86.79310840928294" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6181" weight="83.91364400745904" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6182" weight="84.78252224939627" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6183" weight="81.22552616323011" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6184" weight="85.52155830795967" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6185" weight="84.39519848317197" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6186" weight="82.40171519913282" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6187" weight="81.50888889273303" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6188" weight="85.37132024279208" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6189" weight="86.09388820065882" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6190" weight="84.4497638925757" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6191" weight="89.289871735506" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6192" weight="85.56121236158334" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6193" weight="81.81984507737694" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6194" weight="85.4765331708109" />
      <edge source="it has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6195" weight="87.20753494852143" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " id="6196" weight="80.00983567575621" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6197" weight="82.24458837728402" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " id="6198" weight="82.14580157054753" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6199" weight="83.34815858244183" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6200" weight="81.05354637198144" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6201" weight="82.17286935779006" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6202" weight="85.39961597500022" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6203" weight="81.86897738866239" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6204" weight="81.45290358589747" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6205" weight="82.65880753186387" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6206" weight="80.01330156484003" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6207" weight="81.39108239750075" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6208" weight="81.32810054641841" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6209" weight="80.38111878635551" />
      <edge source="this dependency graph is partitioned into treelets; like (koehn et al, 2003), we assume a uniform probability distribution over all partitions. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6210" weight="81.97087350018535" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " id="6211" weight="81.6340230349471" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="6212" weight="82.49765443773921" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="6213" weight="86.16216716686125" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="6214" weight="83.26839139231541" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="6215" weight="82.57795436628221" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6216" weight="86.4979559816734" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="6217" weight="82.53039925043886" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6218" weight="85.23557832984487" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6219" weight="84.0590784088049" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6220" weight="87.14656898384668" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6221" weight="86.10224274874096" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6222" weight="84.10407065845918" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6223" weight="80.5943477896782" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6224" weight="89.1010644321507" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6225" weight="84.58074397700005" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6226" weight="84.62620176411745" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6227" weight="85.15711799236745" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6228" weight="89.27753715770346" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6229" weight="85.94728029171243" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6230" weight="81.84508336377536" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6231" weight="81.57105917119796" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6232" weight="82.18706248662488" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6233" weight="80.09751030048828" />
      <edge source="for each differently tokenized corpus, we computed word alignments by a hmm translation model (och and ney, 2003) and by a word alignment refinement heuristic of “grow-diagfinal” (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6234" weight="82.8863003555963" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " id="6235" weight="84.45770134411276" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6236" weight="83.51164082989723" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6237" weight="87.01376389220464" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6238" weight="81.1902827609396" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6239" weight="82.32790843082473" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6240" weight="81.72097164355388" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6241" weight="84.88113306803217" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6242" weight="83.42716133438498" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6243" weight="80.19380476079824" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6244" weight="84.71379848379065" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6245" weight="85.20453012348996" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6246" weight="85.38378965184997" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6247" weight="80.67204376633472" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6248" weight="82.05205307668774" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6249" weight="83.13317713650434" />
      <edge source="our phrase-based model uses a standard pharaoh feature functions listed as follows (koehn et al, 2003): • relative-count based phrase translation probabilities in both directions. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6250" weight="81.9528816111006" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " id="6251" weight="81.57702627084873" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="6252" weight="80.9660292805362" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="6253" weight="82.8796283524898" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6254" weight="83.3649694685809" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6255" weight="86.08415825030178" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6256" weight="81.74596363133315" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6257" weight="84.39262165838568" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6258" weight="89.63684322399341" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6259" weight="82.9650610265501" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6260" weight="82.42072080684564" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6261" weight="83.26994687028863" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6262" weight="83.61810340828377" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6263" weight="81.0630566591254" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6264" weight="86.12766571881949" />
      <edge source="one is a phrase-based translation in which a phrasal unit is employed for translation (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6265" weight="86.61150570557304" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " id="6266" weight="81.63138210855098" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " id="6267" weight="83.20703143664296" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6268" weight="87.45711706847041" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6269" weight="81.84856324889749" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6270" weight="82.37260336901157" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6271" weight="81.94919784198463" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6272" weight="87.53055208338876" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6273" weight="81.72517162877249" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6274" weight="81.58427278418554" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6275" weight="83.97721047236824" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6276" weight="80.36722256979634" />
      <edge source="second, phrase translation pairs are extracted from the word aligned corpus (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6277" weight="80.43652266443011" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " id="6278" weight="80.89012415345653" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6279" weight="83.45879983326208" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="details of this model are described by koehn et al (2003). " id="6280" weight="84.4601534184497" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="6281" weight="80.82622057175439" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6282" weight="81.39494092487854" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6283" weight="89.04206738299769" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6284" weight="80.39652326430631" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6285" weight="83.17443707198014" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6286" weight="86.22971438651878" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6287" weight="82.9901918314416" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6288" weight="82.90809941302939" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6289" weight="82.63769454402505" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6290" weight="82.21813408890581" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6291" weight="85.56162401517571" />
      <edge source=" the phrase extraction algorithm is based on those presented by koehn et al (2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6292" weight="81.2131516913241" />
      <edge source="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6293" weight="89.14206276295438" />
      <edge source="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6294" weight="83.74881800348182" />
      <edge source="in a phrase-based statistical translation (koehn et al, 2003), a bilingual text is decomposed as k phrase translation pairs (¯e1, ¯f¯a1), (¯e2, ¯f¯a2 ),...: " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6295" weight="80.02997007520423" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " id="6296" weight="82.27146541575381" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6297" weight="86.77049821479761" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6298" weight="81.83104491166799" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6299" weight="85.65248399083617" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6300" weight="85.81493641127878" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6301" weight="83.90175091036076" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6302" weight="83.18786351489248" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6303" weight="85.63727640485183" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6304" weight="83.87886051560693" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6305" weight="83.06406800077175" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6306" weight="84.35776905460027" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6307" weight="80.1776859257458" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6308" weight="80.77746688223495" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6309" weight="81.07086200242001" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6310" weight="81.45050707160743" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6311" weight="85.61318680267529" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6312" weight="80.78486694356913" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6313" weight="80.0660539940885" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6314" weight="90.14979681327023" />
      <edge source="the decoding process is very similar to those described in (koehn et al, 2003): it starts from an initial empty hypothesis. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6315" weight="83.00662824167804" />
      <edge source="for details, please refer to koehn et al (2003). " target="details of this model are described by koehn et al (2003). " id="6316" weight="82.84955095178444" />
      <edge source="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6317" weight="83.80703477776059" />
      <edge source="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6318" weight="81.64805812898037" />
      <edge source="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6319" weight="81.22722271275092" />
      <edge source="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6320" weight="81.76695096077302" />
      <edge source="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6321" weight="83.88416734756004" />
      <edge source="as an additional baseline, we compare against a phrasal smt decoder, pharaoh (koehn et al 2003). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6322" weight="81.29881959202395" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " id="6323" weight="83.52331925287469" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6324" weight="87.89462005792583" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6325" weight="83.26986170248527" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6326" weight="81.44713944203055" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6327" weight="90.25325735281908" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6328" weight="81.32273486502906" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6329" weight="86.29072165218008" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6330" weight="83.49079861063842" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6331" weight="87.97449231468369" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6332" weight="84.66711086220333" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6333" weight="82.60943476399028" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6334" weight="84.80526937355125" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6335" weight="86.10102483167428" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6336" weight="84.47087947240321" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6337" weight="80.09431591692955" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6338" weight="84.02296046444609" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6339" weight="84.0965241599614" />
      <edge source="we used the heuristic combination described in (och and ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6340" weight="82.06742105360124" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6341" weight="82.90431663389839" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6342" weight="81.06928938907474" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6343" weight="80.3104519771118" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6344" weight="80.50049351196805" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6345" weight="82.36254928239927" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6346" weight="84.40692519722165" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6347" weight="82.17112099973454" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6348" weight="85.35203216401119" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6349" weight="82.17816148754167" />
      <edge source="systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) or some linguistically motivated constraint, such as itg (zens and ney, 2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6350" weight="81.35626782406653" />
      <edge source="the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by a wide margin (koehn 2003). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6351" weight="82.26931268483074" />
      <edge source="details of this model are described by koehn et al (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6352" weight="82.6515813750087" />
      <edge source="details of this model are described by koehn et al (2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6353" weight="80.96446708750136" />
      <edge source="details of this model are described by koehn et al (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6354" weight="82.08226459685899" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " id="6355" weight="81.76087876350763" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6356" weight="83.12984872517409" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6357" weight="82.206762818784" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6358" weight="88.69088239121008" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6359" weight="83.17394851034645" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6360" weight="87.32904922676374" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6361" weight="87.87213797296889" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6362" weight="86.56618324530514" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6363" weight="82.72942055571184" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6364" weight="92.27369453592522" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6365" weight="83.0232442043611" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6366" weight="89.36490031737425" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6367" weight="83.9287142683158" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6368" weight="82.64556641686195" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6369" weight="87.802230851763" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6370" weight="83.50349811452809" />
      <edge source="defining scms the work presented here was done in the context of phrase-based mt (koehn et al, 2003; och and ney, 2004). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="6371" weight="81.99378957884764" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " id="6372" weight="84.7574606975314" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6373" weight="85.47784020331063" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6374" weight="86.5209704773284" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6375" weight="80.28928434780147" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6376" weight="88.5165410606253" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6377" weight="84.45110537921671" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6378" weight="85.69495938240652" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6379" weight="90.33779109577485" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6380" weight="84.86808987063006" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6381" weight="82.42405285767467" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6382" weight="87.87324119029417" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6383" weight="84.61517834708516" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6384" weight="82.01192285916402" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6385" weight="89.30258795798709" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6386" weight="89.0636802348154" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6387" weight="87.0620946915979" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6388" weight="85.84431152469605" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6389" weight="83.88416727248394" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6390" weight="86.71221911523065" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6391" weight="86.9592909253302" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6392" weight="80.54244711053435" />
      <edge source="phrase tables were learned from the training corpus using the diag-and� method (koehn et al, 2003), and using ibm model 2 to produce initial word alignments (these authors found this worked as well as ibm4). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6393" weight="80.82777029644012" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " id="6394" weight="81.48758847507507" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " id="6395" weight="80.76114655072242" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6396" weight="87.19357837967081" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6397" weight="83.23492039914674" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6398" weight="85.8599501038675" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6399" weight="84.87934960271501" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6400" weight="85.15816518528085" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6401" weight="83.77315999995447" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6402" weight="86.02634264479421" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6403" weight="84.85100042497503" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6404" weight="82.92136605824001" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6405" weight="81.52939617102366" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6406" weight="86.38384732552768" />
      <edge source="a comparison of the two approaches can be found in koehn, och, and marcu (2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6407" weight="84.45666342606053" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " id="6408" weight="86.10048956889528" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6409" weight="87.08863828067534" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6410" weight="82.81314753565839" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6411" weight="89.30432474935908" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6412" weight="83.98703804967893" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6413" weight="85.66459571341407" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6414" weight="81.33984572233035" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6415" weight="88.58326905079339" />
      <edge source="however, (koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between “there is” in english and “es gibt” (“it gives”) in german. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6416" weight="84.40974406880801" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6417" weight="81.2744510345995" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " id="6418" weight="81.66707937243436" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6419" weight="82.6495970559249" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6420" weight="86.1003334328353" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6421" weight="85.58381799545649" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6422" weight="82.10409694540186" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6423" weight="83.69635881764464" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6424" weight="83.97656052148706" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6425" weight="82.4876448785123" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6426" weight="84.92636019861241" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6427" weight="82.47331994170291" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6428" weight="86.91362463589769" />
      <edge source="the normalization is visualized as a translation problem where messages in the sms language are to be translated to normal english using a similar phrase-based statistical mt method (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6429" weight="84.30057735827363" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " id="6430" weight="83.10205781105257" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6431" weight="86.05047294945987" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6432" weight="82.52676968318286" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6433" weight="82.76815147627114" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6434" weight="85.00044505330966" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6435" weight="81.72432873796683" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6436" weight="89.3081433199382" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6437" weight="82.84320223612723" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6438" weight="86.41262413818545" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6439" weight="87.95174768190938" />
      <edge source="we compared a baseline system, the state-of-the-art phrase-based system pharaoh (koehn et al, 2003; koehn, 2004a), against our system. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6440" weight="84.11250628278164" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " id="6441" weight="85.75647878907984" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6442" weight="89.26181801658966" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6443" weight="87.73562043606957" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6444" weight="89.85217254054251" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6445" weight="86.39816807920995" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6446" weight="90.6294453917138" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6447" weight="84.46952114684542" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6448" weight="88.24064683258909" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6449" weight="86.89920650789253" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6450" weight="82.18209620844692" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6451" weight="85.61523112365181" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6452" weight="87.79899583495747" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6453" weight="84.30139866379989" />
      <edge source="we obtain the word alignments using the method of koehn et al (2003), which is based on that of och and ney (2004). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6454" weight="83.5681134203225" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6455" weight="86.95183609700096" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6456" weight="87.9388318153863" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6457" weight="85.97425556685745" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6458" weight="82.9274630726294" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6459" weight="82.07760688470968" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6460" weight="86.57790502374382" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6461" weight="93.2722028703768" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6462" weight="83.34682687714208" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6463" weight="88.60480981324834" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6464" weight="80.19103786508046" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="6465" weight="80.27500860984335" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004a), as publicly distributed. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6466" weight="85.39881606088102" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " id="6467" weight="83.42793317590191" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6468" weight="87.0905426970579" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6469" weight="80.96318253315278" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6470" weight="86.6470093297497" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6471" weight="82.30179708222325" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6472" weight="88.9657664294673" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6473" weight="81.31701578185783" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6474" weight="81.2585168757153" />
      <edge source="but koehn et al (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6475" weight="80.77800126461725" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " id="6476" weight="90.83875996906943" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " id="6477" weight="82.93766150173165" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6478" weight="89.1613150324895" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6479" weight="88.29009788831965" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6480" weight="86.46099690220277" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6481" weight="87.41988253857842" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6482" weight="90.41373540989932" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6483" weight="87.9338564515394" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6484" weight="83.11281923545259" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6485" weight="84.72604988852454" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6486" weight="89.91213511611424" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6487" weight="86.63009232993821" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6488" weight="82.2129052439818" />
      <edge source="to do this, we first identify initial phrase pairs using the same criterion as previous systems (och and ney, 2004; koehn et al, 2003): definition 1. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6489" weight="80.45884279494304" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6490" weight="88.40093440936758" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6491" weight="85.69458314579124" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6492" weight="86.61043899026424" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6493" weight="88.27676950139613" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6494" weight="91.80781750406813" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6495" weight="87.73928758098563" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6496" weight="83.88532310623087" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6497" weight="90.60038563035877" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="6498" weight="83.71078920547883" />
      <edge source="above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (och and ney, 2004; koehn et al, 2003), or not at all (zens and ney, 2004; kumar et al, 2005). " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6499" weight="84.3639579191576" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" id="6500" weight="84.02826878891483" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6501" weight="81.50850087560985" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6502" weight="84.48168636338684" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6503" weight="80.94721652241014" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6504" weight="87.0673885402338" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6505" weight="81.78655337363368" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6506" weight="83.70605465271422" />
      <edge source="koehn et al (2003) mention german 〈es gibt, there is〉 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6507" weight="81.3646261772758" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " id="6508" weight="89.14709065082384" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6509" weight="88.49625253430065" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6510" weight="88.55376340073123" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6511" weight="91.57441783179627" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6512" weight="89.42352348513008" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6513" weight="82.21396888272989" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6514" weight="85.71203160356309" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6515" weight="85.8376440146523" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6516" weight="88.16252968027842" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6517" weight="81.72324189022233" />
      <edge source="it is important because a word-aligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based machine translation (och et al, 1999), (tillmann and xia, 2003), (koehn et al, 2003)" target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6518" weight="84.74640917963208" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " id="6519" weight="84.50740226406788" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6520" weight="82.51317757482246" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6521" weight="86.77256132918218" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6522" weight="87.46769158693131" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6523" weight="84.39096486608364" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6524" weight="82.2548239881216" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6525" weight="87.9950625986683" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6526" weight="81.23933095768028" />
      <edge source="the block set is generated using a phrase-pair selection algorithm similar to (koehn et al, 2003; al-onaizan et al, 2004), which includes some heuristic filtering to mal statement here. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6527" weight="83.4187737963697" />
      <edge source="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " target="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " id="6528" weight="85.37324834850195" />
      <edge source="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6529" weight="91.39832891812596" />
      <edge source="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6530" weight="84.88211143272994" />
      <edge source="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6531" weight="80.52233266748105" />
      <edge source="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6532" weight="83.64117842952147" />
      <edge source="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6533" weight="85.94994141907313" />
      <edge source="the current state of the art is represented by the so-called phrase-based translation approach (och and ney, 2004; koehn et al, 2003). " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6534" weight="84.1256746794262" />
      <edge source="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " target="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " id="6535" weight="91.26469115327014" />
      <edge source="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6536" weight="84.60705859828279" />
      <edge source="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6537" weight="85.1780905853732" />
      <edge source="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6538" weight="83.53377616550814" />
      <edge source="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6539" weight="87.06548520566986" />
      <edge source="phrase-based models (koehn et al, 2003; och and ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6540" weight="80.83271108527424" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." id="6541" weight="91.41853070748954" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6542" weight="84.9295691006598" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6543" weight="90.29289268728418" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6544" weight="92.55894508780105" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6545" weight="84.05732551942992" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="6546" weight="81.56635410247421" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6547" weight="83.10396982690574" />
      <edge source="phrase-based translation models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004), which go beyond the original ibm translation models (brown et al, 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6548" weight="82.35665242662154" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." target="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " id="6549" weight="80.63810036326188" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6550" weight="86.36932936493311" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6551" weight="89.01923263536445" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6552" weight="84.75240960026835" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6553" weight="84.25885215899649" />
      <edge source="the baseline system we used for comparison was pharaoh (koehn et al, 2003; koehn, 2004), a freely available decoder for phrase-based translation models." target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6554" weight="83.25603093241587" />
      <edge source="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " target="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " id="6555" weight="88.49384336444103" />
      <edge source="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6556" weight="83.48630903615995" />
      <edge source="the inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [koehn et al, 2003]. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6557" weight="85.10942713501626" />
      <edge source="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " target="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " id="6558" weight="86.62731599651107" />
      <edge source="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6559" weight="80.54852118356244" />
      <edge source="whereas language generation has benefited from syntax [wu, 1997; alshawi et al, 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [koehn et al, 2003]. " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6560" weight="81.48785532190665" />
      <edge source="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " target="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " id="6561" weight="80.28942512816232" />
      <edge source="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " target="recently, various works have improved the quality of statistical machine translation systems by using phrase translation (koehn et al, 2003; marcu et al, 2002; och et al, 1999; och and ney, 2000; zens et al, 2004). " id="6562" weight="81.83267255470237" />
      <edge source="during the last four years, various implementations and extentions to phrase-based statistical models (marcu and wong, 2002; koehn et al, 2003; och and ney, 2004) have led to significant increases in machine translation accuracy. " target="using giza++ model 4 alignments and pharaoh (koehn et al, 2003), we achieved a bleu score of 0.3035. " id="6563" weight="82.0903639124916" />
      <edge source="a word link extension algorithm similar to the one presented in this paper is given in (koehn et al, 2003). " target="word alignment is an important component of a complete statistical machine translation pipeline (koehn et al, 2003). " id="6564" weight="85.11441092195169" />
    </edges>
  </graph>
</gexf>
