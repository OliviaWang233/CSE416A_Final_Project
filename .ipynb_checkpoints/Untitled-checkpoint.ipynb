{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "44118c5c-2bba-414e-be07-cd19b791c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import spacy\n",
    "from networkx.algorithms.community import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5cd45da0-6547-4b5a-bb5d-9fcf23426508",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\") \n",
    "G = nx.Graph()\n",
    "sentences = []\n",
    "with open('data.csv','r') as csvfile:\n",
    "    file = csv.reader(csvfile, delimiter=\"|\")\n",
    "    for row in file:\n",
    "        sentences.append(row[1])\n",
    "        G.add_node(row[1], article_index = row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "888eaf91-9054-47dc-b7d4-f9d8675a350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 91 nodes and 367 edges\n"
     ]
    }
   ],
   "source": [
    "'running time of this cell is about one minute'\n",
    "\n",
    "# add edges with weight \n",
    "# rule: if the similarity > N, these two nodes have edge\n",
    "\n",
    "for i in range(len(sentences)-1):\n",
    "    for j in range(i+1, len(sentences)):\n",
    "        doc1 = nlp(sentences[i])\n",
    "        doc2 = nlp(sentences[j])\n",
    "        similarity = ((doc1.similarity(doc2))-0.5)*200\n",
    "        if similarity>85:\n",
    "            G.add_edge(sentences[i], sentences[j], weight=similarity)\n",
    "print(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d65c7a5e-ba56-4600-88ce-e52104a0a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_number = 13\n",
      "nodes in connected components are [78, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[{' We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets.', \" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999).\", \" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model.\", ' Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment.', ' Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999).', ' The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules.', ' It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999].', ' Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy.', ' The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6).', \" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3).\", \" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;\", ' As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))', ' For a detailed descriptions see Haji6 (1998), Hladkfi (2000) and Collins, Haji6, Ram~haw, Tillmann (1999).', \" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals.\", ' This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000).', ' The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999).', ' The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999).', \" Comparable results in the literature are Schiehlen's (2004) 81.03% dependency f- score reached on the German NEGRA treebank and Collins et al.'s (1999) 80.0% labelled accuracy on the Czech PDT treebank.\", ' The increasing availability of multi-format treebanks (e.g.(Bick, 2006)) and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem.', ' a subset of the morphological tag as described in (Collins et al., 1999)', ' From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999).', ' In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research.', ' However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997).', \" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags.\", \" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic.\", ' Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007).', ' A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004).', ' We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1].', ' Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999).', ' Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008).', ' Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001).', ' Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree.', \" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank.\", ' Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999).', ' However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages.', ' It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003).', ' In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features.', ' Two rule-based methods to convert dependency structure into phrase structure are presented by Covington [14] and Collins et al.', ' For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000).', ' By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005).', \" For example, Collins et al. (1999) adapted Collins' parser to Czech, a highly- inflected language.\", ' Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied.', ' So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank.', ' Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999).', ' The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)', ' Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible.', ' The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese.', ' The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1', ' Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms.', ' We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5].', ' We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999)).', ' Collins et al. (1999) describe how the models in the current article were applied to parsing Czech.', ' This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%.', ' This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)', ' Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;', ' One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank.', ' Algorithm 2 presents the extended version of the decoding algorithm used in the Collins parser, what the algorithm needs to do is to generate edges for each span.', ' Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999).', ' To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999).', ' Covington [14] and Collins et al. [13] use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure.', ' In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999).', ' Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005).', ' The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values).', ' The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999).', ' We used the two-letter tag method proposed by Collins et al. [11] to integrate a family of POS tags to a CPOS.', ' The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6].', ' There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures.', ' The dependents in the method of Collins et al. [13] project only one level; hence, the dependents of a head are in the same level.', \" We use the statistical Collins's parser to create the stnlcture of the tree and then a statistical procedure to assign words their syntactic functions.\", ' For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian.', ' Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000).', ' The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999)).', ' Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003).', \" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level.\", ' More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures.', ' The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English.', ' Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008).', ' Much work has been done on the use of morphological features for parsing of morphologically rich languages. Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable).'}, {' This two-dimensional parametrization2 was shown to improve parsing accuracy for English [4, 1] as well as other languages, e.g., German [7] Czech [5] and Chinese [2].', ' Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4].'}, {' For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) [Zhou 1996] and Peking Chinese Treebank.'}, {' For Czech, the adaptation by Collins et al. (1999) culminated in an 80 F1-score.'}, {' With its 1.5 million syntactically annotated tokens, the PDT in version 2.0 forms the biggest source of Czech syntactic data. Dependency parsers, e.g. [8,9], usually use the PDT data for training their internal syntax models.'}, {' State-of-the-art morphological taggers can achieve accuracy rates of over 96% for English [34, 36] and 92% for highly inflected languages like Czech [20], and dependency parsers can achieve labeled accuracy rates for the same languages of 86% [31] and 80% [11], respectively.'}, {' Currently it is dominant that using data-driven approaches to learn parsers automatically from experience, such as probabilistic generative models [3], generative probabilistic parsing models [2] and deterministic discriminative model [7] and so on.'}, {' Other parsers with high accuracy reported on PDT 2.0 use feature extraction as well [4,5].'}, {' DECT. Individual positions of the 15-letter tags as individual features. Original MST parser uses only 2-letter tags proposed by [5].'}, {\" COL. Collins's parser adapted for PDT [4].\"}, {' COLL1999: The projective lexicalized phrase-structure parser of Collins et al. (1999).'}, {' First, Czech is a “highly inflected” language: the role of function words in the Germanic and Romance languages is typically filled by suffixes in Czech. Second, Czech exhibits a “relatively free word order” [7].'}, {' Here 80% accuracy for unlabelled dependencies have been achieved(Collins et al., 1999)'}]\n"
     ]
    }
   ],
   "source": [
    "CC_number = nx.number_connected_components(G)\n",
    "print('CC_number = ' + str(CC_number))\n",
    "number_of_nodes_in_CC = [len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "print('# nodes in connected components are ' + str(CC))\n",
    "\n",
    "#remove the isolated nodes\n",
    "CC = [c for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "for i in range(CC_number):\n",
    "    if CC[i]==1:\n",
    "        \n",
    "print(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ade370ea-2b2f-4955-b01c-6aa5e6618c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetweennessBasedClustering(G, k):\n",
    "    \n",
    "    '''girvan_newman function will return the iterator include all the partitions with all possible thresholds \n",
    "    (partly utilized the NetworkX's code)'''\n",
    "    def girvan_newman(G):\n",
    "        most_valuable_edge = None\n",
    "            # If the graph is already empty, simply return its connected components.\n",
    "        if G.number_of_edges() == 0:\n",
    "            yield tuple(nx.connected_components(G))\n",
    "            return\n",
    "        # If no function is provided for computing the most valuable edge, use the edge betweenness centrality.\n",
    "        if most_valuable_edge is None:\n",
    "\n",
    "            def most_valuable_edge(G):\n",
    "                \"\"\"Returns the edge with the highest betweenness centrality\n",
    "                in the graph `G`.\n",
    "                \"\"\"\n",
    "                # We have guaranteed that the graph is non-empty, so this dictionary will never be empty.\n",
    "                betweenness = nx.edge_betweenness_centrality(G)\n",
    "                return max(betweenness, key=betweenness.get)\n",
    "\n",
    "        # The copy of G here must include the edge weight data.\n",
    "        g = G.copy().to_undirected()\n",
    "        # Self-loops must be removed because their removal has no effect on\n",
    "        # the connected components of the graph.\n",
    "        g.remove_edges_from(nx.selfloop_edges(g))\n",
    "        while g.number_of_edges() > 0:\n",
    "            yield  _without_most_central_edges(g, most_valuable_edge)\n",
    "            \n",
    "    def _without_most_central_edges(G, most_valuable_edge):\n",
    "        original_num_components = nx.number_connected_components(G)\n",
    "        num_new_components = original_num_components\n",
    "        while num_new_components <= original_num_components:\n",
    "            edge = most_valuable_edge(G)\n",
    "            G.remove_edge(*edge)\n",
    "            new_components = tuple(nx.connected_components(G))\n",
    "            num_new_components = len(new_components)\n",
    "        \n",
    "        return new_components\n",
    "\n",
    "    \"\"\" We have all the clustering with different threshold, the next part is to find the partition with threshold k \"\"\"\n",
    "    result = girvan_newman(G)\n",
    "    \n",
    "    lastContent = []\n",
    "    for i in result:\n",
    "        kk = 0\n",
    "        content = []\n",
    "        for j in i:\n",
    "            kk = kk+1\n",
    "            content.append(j)\n",
    "        size = len(content)\n",
    "        if k < size:\n",
    "            return lastContent\n",
    "        lastContent = content\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1aced9ff-06d0-458d-b34a-d2c295b10122",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'number_of_edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hj/cznj72454zx5dsbnb7_rbmth0000gn/T/ipykernel_88805/1676310374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#c = greedy_modularity_communities(G, weight = 'weight',n_communities = 5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBetweennessBasedClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hj/cznj72454zx5dsbnb7_rbmth0000gn/T/ipykernel_88805/543056536.py\u001b[0m in \u001b[0;36mBetweennessBasedClustering\u001b[0;34m(G, k)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlastContent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hj/cznj72454zx5dsbnb7_rbmth0000gn/T/ipykernel_88805/543056536.py\u001b[0m in \u001b[0;36mgirvan_newman\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmost_valuable_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# If the graph is already empty, simply return its connected components.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'number_of_edges'"
     ]
    }
   ],
   "source": [
    "#c = greedy_modularity_communities(G, weight = 'weight',n_communities = 5)\n",
    "comp = BetweennessBasedClustering(LCC, 10)\n",
    "print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a714ce5-c2b1-491e-9be3-2405dd66397b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
