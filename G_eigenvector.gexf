<?xml version='1.0' encoding='utf-8'?>
<gexf xmlns="http://www.gexf.net/1.2draft" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.gexf.net/1.2draft http://www.gexf.net/1.2draft/gexf.xsd" version="1.2">
  <meta lastmodifieddate="2022-04-25">
    <creator>NetworkX 2.6.3</creator>
  </meta>
  <graph defaultedgetype="undirected" mode="static" name="">
    <attributes mode="static" class="node">
      <attribute id="0" title="article_index" type="string" />
      <attribute id="1" title="partition" type="long" />
      <attribute id="2" title="centrality" type="double" />
    </attributes>
    <nodes>
      <node id=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." label=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al.">
        <attvalues>
          <attvalue for="0" value="1" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.06681447084225374" />
        </attvalues>
      </node>
      <node id=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." label=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure.">
        <attvalues>
          <attvalue for="0" value="1" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.11877402141193075" />
        </attvalues>
      </node>
      <node id=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." label=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level.">
        <attvalues>
          <attvalue for="0" value="1" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.1381911377935973" />
        </attvalues>
      </node>
      <node id=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." label=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS.">
        <attvalues>
          <attvalue for="0" value="2" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.11587772645475704" />
        </attvalues>
      </node>
      <node id=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." label=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008).">
        <attvalues>
          <attvalue for="0" value="3" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.19820806309905176" />
        </attvalues>
      </node>
      <node id=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." label=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values).">
        <attvalues>
          <attvalue for="0" value="4" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.15252034228473316" />
        </attvalues>
      </node>
      <node id=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4]." label=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4].">
        <attvalues>
          <attvalue for="0" value="5" />
          <attvalue for="1" value="2" />
          <attvalue for="2" value="0.5648417595396397" />
        </attvalues>
      </node>
      <node id=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." label=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank.">
        <attvalues>
          <attvalue for="0" value="6" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.08997420393858206" />
        </attvalues>
      </node>
      <node id=" Algorithm 2 presents the extended version of the decoding algorithm used in the Collins parser, what the algorithm needs to do is to generate edges for each span." label=" Algorithm 2 presents the extended version of the decoding algorithm used in the Collins parser, what the algorithm needs to do is to generate edges for each span.">
        <attvalues>
          <attvalue for="0" value="6" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.02687021847339561" />
        </attvalues>
      </node>
      <node id=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." label=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank.">
        <attvalues>
          <attvalue for="0" value="6" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.04646816024966755" />
        </attvalues>
      </node>
      <node id=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." label=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable).">
        <attvalues>
          <attvalue for="0" value="11" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.15112776806834124" />
        </attvalues>
      </node>
      <node id=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." label=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007).">
        <attvalues>
          <attvalue for="0" value="8" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.11649981631850428" />
        </attvalues>
      </node>
      <node id=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." label=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005).">
        <attvalues>
          <attvalue for="0" value="9" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.1857677802612502" />
        </attvalues>
      </node>
      <node id=" For Czech, the adaptation by Collins et al. (1999) culminated in an 80 F1-score." label=" For Czech, the adaptation by Collins et al. (1999) culminated in an 80 F1-score.">
        <attvalues>
          <attvalue for="0" value="10" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.035603987208162005" />
        </attvalues>
      </node>
      <node id=" For example, Collins et al. (1999) adapted Collins' parser to Czech, a highly- inflected language." label=" For example, Collins et al. (1999) adapted Collins' parser to Czech, a highly- inflected language.">
        <attvalues>
          <attvalue for="0" value="12" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.040535430450942864" />
        </attvalues>
      </node>
      <node id=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." label=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999).">
        <attvalues>
          <attvalue for="0" value="13" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.2106547285942538" />
        </attvalues>
      </node>
      <node id=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." label=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures.">
        <attvalues>
          <attvalue for="0" value="14" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.22267724339665498" />
        </attvalues>
      </node>
      <node id=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." label=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model.">
        <attvalues>
          <attvalue for="0" value="14" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.1589297762075518" />
        </attvalues>
      </node>
      <node id=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." label=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank.">
        <attvalues>
          <attvalue for="0" value="14" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.16637466364772838" />
        </attvalues>
      </node>
      <node id=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." label=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied.">
        <attvalues>
          <attvalue for="0" value="15" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.13124603715184513" />
        </attvalues>
      </node>
      <node id=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." label=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001).">
        <attvalues>
          <attvalue for="0" value="16" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.26488246122180026" />
        </attvalues>
      </node>
      <node id=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." label=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree.">
        <attvalues>
          <attvalue for="0" value="16" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.215037521821504" />
        </attvalues>
      </node>
      <node id=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." label=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008).">
        <attvalues>
          <attvalue for="0" value="16" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.21783635832812126" />
        </attvalues>
      </node>
      <node id=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." label=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment.">
        <attvalues>
          <attvalue for="0" value="16" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.20052225249029987" />
        </attvalues>
      </node>
      <node id=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." label=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research.">
        <attvalues>
          <attvalue for="0" value="17" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.2013098513508796" />
        </attvalues>
      </node>
      <node id=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." label=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags.">
        <attvalues>
          <attvalue for="0" value="18" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.18266537488958703" />
        </attvalues>
      </node>
      <node id=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" label=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))">
        <attvalues>
          <attvalue for="0" value="19" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.15020213051428957" />
        </attvalues>
      </node>
      <node id=" With its 1.5 million syntactically annotated tokens, the PDT in version 2.0 forms the biggest source of Czech syntactic data. Dependency parsers, e.g. [8,9], usually use the PDT data for training their internal syntax models." label=" With its 1.5 million syntactically annotated tokens, the PDT in version 2.0 forms the biggest source of Czech syntactic data. Dependency parsers, e.g. [8,9], usually use the PDT data for training their internal syntax models.">
        <attvalues>
          <attvalue for="0" value="20" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.020357242081229767" />
        </attvalues>
      </node>
      <node id=" State-of-the-art morphological taggers can achieve accuracy rates of over 96% for English [34, 36] and 92% for highly inflected languages like Czech [20], and dependency parsers can achieve labeled accuracy rates for the same languages of 86% [31] and 80% [11], respectively." label=" State-of-the-art morphological taggers can achieve accuracy rates of over 96% for English [34, 36] and 92% for highly inflected languages like Czech [20], and dependency parsers can achieve labeled accuracy rates for the same languages of 86% [31] and 80% [11], respectively.">
        <attvalues>
          <attvalue for="0" value="21" />
          <attvalue for="1" value="2" />
          <attvalue for="2" value="0.3437846993195429" />
        </attvalues>
      </node>
      <node id=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." label=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999].">
        <attvalues>
          <attvalue for="0" value="22" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.049105898988805165" />
        </attvalues>
      </node>
      <node id=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." label=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6).">
        <attvalues>
          <attvalue for="0" value="24" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.1593151918103463" />
        </attvalues>
      </node>
      <node id=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." label=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000).">
        <attvalues>
          <attvalue for="0" value="25" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.24139917639375258" />
        </attvalues>
      </node>
      <node id=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." label=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem.">
        <attvalues>
          <attvalue for="0" value="26" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.18401820300926455" />
        </attvalues>
      </node>
      <node id=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." label=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian.">
        <attvalues>
          <attvalue for="0" value="26" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.22988902544333384" />
        </attvalues>
      </node>
      <node id=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." label=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999).">
        <attvalues>
          <attvalue for="0" value="26" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.18098449243772444" />
        </attvalues>
      </node>
      <node id=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." label=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5].">
        <attvalues>
          <attvalue for="0" value="27" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.11080940815309011" />
        </attvalues>
      </node>
      <node id=" This two-dimensional parametrization2 was shown to improve parsing accuracy for English [4, 1] as well as other languages, e.g., German [7] Czech [5] and Chinese [2]." label=" This two-dimensional parametrization2 was shown to improve parsing accuracy for English [4, 1] as well as other languages, e.g., German [7] Czech [5] and Chinese [2].">
        <attvalues>
          <attvalue for="0" value="29" />
          <attvalue for="1" value="2" />
          <attvalue for="2" value="0.47678363380526756" />
        </attvalues>
      </node>
      <node id=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." label=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures.">
        <attvalues>
          <attvalue for="0" value="30" />
          <attvalue for="1" value="4" />
          <attvalue for="2" value="1.0" />
        </attvalues>
      </node>
      <node id=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" label=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)">
        <attvalues>
          <attvalue for="0" value="30" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.1912477773751656" />
        </attvalues>
      </node>
      <node id=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." label=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999).">
        <attvalues>
          <attvalue for="0" value="31" />
          <attvalue for="1" value="2" />
          <attvalue for="2" value="0.3453995201000121" />
        </attvalues>
      </node>
      <node id=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." label=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic.">
        <attvalues>
          <attvalue for="0" value="32" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.0901418443528902" />
        </attvalues>
      </node>
      <node id=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." label=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules.">
        <attvalues>
          <attvalue for="0" value="33" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.21612129852617198" />
        </attvalues>
      </node>
      <node id=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." label=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999).">
        <attvalues>
          <attvalue for="0" value="33" />
          <attvalue for="1" value="5" />
          <attvalue for="2" value="1.0" />
        </attvalues>
      </node>
      <node id=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." label=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank.">
        <attvalues>
          <attvalue for="0" value="33" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.15622201850841397" />
        </attvalues>
      </node>
      <node id=" Comparable results in the literature are Schiehlen's (2004) 81.03% dependency f- score reached on the German NEGRA treebank and Collins et al.'s (1999) 80.0% labelled accuracy on the Czech PDT treebank." label=" Comparable results in the literature are Schiehlen's (2004) 81.03% dependency f- score reached on the German NEGRA treebank and Collins et al.'s (1999) 80.0% labelled accuracy on the Czech PDT treebank.">
        <attvalues>
          <attvalue for="0" value="33" />
          <attvalue for="1" value="3" />
          <attvalue for="2" value="0.5735829623578843" />
        </attvalues>
      </node>
      <node id=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." label=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3).">
        <attvalues>
          <attvalue for="0" value="34" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.12013651161985801" />
        </attvalues>
      </node>
      <node id=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." label=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1].">
        <attvalues>
          <attvalue for="0" value="35" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.18887224630189564" />
        </attvalues>
      </node>
      <node id=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." label=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6].">
        <attvalues>
          <attvalue for="0" value="36" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.1859082615580684" />
        </attvalues>
      </node>
      <node id=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." label=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999).">
        <attvalues>
          <attvalue for="0" value="37" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.21331165134465677" />
        </attvalues>
      </node>
      <node id=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." label=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features.">
        <attvalues>
          <attvalue for="0" value="38" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.20651360903096427" />
        </attvalues>
      </node>
      <node id=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." label=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English.">
        <attvalues>
          <attvalue for="0" value="38" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.19837504941986675" />
        </attvalues>
      </node>
      <node id=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." label=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003).">
        <attvalues>
          <attvalue for="0" value="39" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.20142983649364793" />
        </attvalues>
      </node>
      <node id=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." label=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003).">
        <attvalues>
          <attvalue for="0" value="40" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.25662373759748697" />
        </attvalues>
      </node>
      <node id=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." label=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals.">
        <attvalues>
          <attvalue for="0" value="40" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.17688101048152438" />
        </attvalues>
      </node>
      <node id=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." label=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%.">
        <attvalues>
          <attvalue for="0" value="40" />
          <attvalue for="1" value="3" />
          <attvalue for="2" value="0.5851818021077321" />
        </attvalues>
      </node>
      <node id=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." label=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005).">
        <attvalues>
          <attvalue for="0" value="41" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.12486839030298084" />
        </attvalues>
      </node>
      <node id=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." label=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999).">
        <attvalues>
          <attvalue for="0" value="41" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.16143326024168986" />
        </attvalues>
      </node>
      <node id=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." label=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms.">
        <attvalues>
          <attvalue for="0" value="41" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.1311929099573895" />
        </attvalues>
      </node>
      <node id=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." label=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets.">
        <attvalues>
          <attvalue for="0" value="41" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.17111180409935844" />
        </attvalues>
      </node>
      <node id=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." label=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000).">
        <attvalues>
          <attvalue for="0" value="42" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.12792215563052864" />
        </attvalues>
      </node>
      <node id=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" label=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1">
        <attvalues>
          <attvalue for="0" value="42" />
          <attvalue for="1" value="3" />
          <attvalue for="2" value="0.5732057604165373" />
        </attvalues>
      </node>
      <node id=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." label=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999).">
        <attvalues>
          <attvalue for="0" value="43" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.16409079975627824" />
        </attvalues>
      </node>
      <node id=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" label=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;">
        <attvalues>
          <attvalue for="0" value="44" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.2094140347419744" />
        </attvalues>
      </node>
      <node id=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." label=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004).">
        <attvalues>
          <attvalue for="0" value="44" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.1817917545269963" />
        </attvalues>
      </node>
      <node id=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." label=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999).">
        <attvalues>
          <attvalue for="0" value="44" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.048223312137455884" />
        </attvalues>
      </node>
      <node id=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." label=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999).">
        <attvalues>
          <attvalue for="0" value="44" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.1333637730007733" />
        </attvalues>
      </node>
      <node id=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." label=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy.">
        <attvalues>
          <attvalue for="0" value="44" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.20899154549565951" />
        </attvalues>
      </node>
      <node id=" a subset of the morphological tag as described in (Collins et al., 1999)" label=" a subset of the morphological tag as described in (Collins et al., 1999)">
        <attvalues>
          <attvalue for="0" value="44" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.09066617636698944" />
        </attvalues>
      </node>
      <node id=" Second, Czech exhibits a “relatively free word order” [7]." label=" Second, Czech exhibits a “relatively free word order” [7].">
        <attvalues>
          <attvalue for="0" value="45" />
          <attvalue for="1" value="6" />
          <attvalue for="2" value="1.0" />
        </attvalues>
      </node>
      <node id=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." label=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999).">
        <attvalues>
          <attvalue for="0" value="46" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.07864710289358837" />
        </attvalues>
      </node>
      <node id=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." label=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999).">
        <attvalues>
          <attvalue for="0" value="47" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.1423850891412368" />
        </attvalues>
      </node>
      <node id=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" label=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)">
        <attvalues>
          <attvalue for="0" value="48" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.17089995321721282" />
        </attvalues>
      </node>
      <node id=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." label=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999)).">
        <attvalues>
          <attvalue for="0" value="49" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.21020103042358532" />
        </attvalues>
      </node>
      <node id=" Here 80% accuracy for unlabelled dependencies have been achieved(Collins et al., 1999)" label=" Here 80% accuracy for unlabelled dependencies have been achieved(Collins et al., 1999)">
        <attvalues>
          <attvalue for="0" value="50" />
          <attvalue for="1" value="7" />
          <attvalue for="2" value="1.0" />
        </attvalues>
      </node>
      <node id=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." label=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000).">
        <attvalues>
          <attvalue for="0" value="51" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.16898531543328754" />
        </attvalues>
      </node>
      <node id=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." label=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese.">
        <attvalues>
          <attvalue for="0" value="51" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.15950499201995325" />
        </attvalues>
      </node>
      <node id=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." label=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages.">
        <attvalues>
          <attvalue for="0" value="51" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.21082255150969367" />
        </attvalues>
      </node>
      <node id=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." label=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999)).">
        <attvalues>
          <attvalue for="0" value="52" />
          <attvalue for="1" value="8" />
          <attvalue for="2" value="1.0" />
        </attvalues>
      </node>
      <node id=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." label=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997).">
        <attvalues>
          <attvalue for="0" value="53" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.2575701276721899" />
        </attvalues>
      </node>
      <node id=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." label=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech.">
        <attvalues>
          <attvalue for="0" value="54" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.18625178267377235" />
        </attvalues>
      </node>
      <node id=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." label=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999).">
        <attvalues>
          <attvalue for="0" value="55" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.1489120480406032" />
        </attvalues>
      </node>
      <node id=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." label=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level.">
        <attvalues>
          <attvalue for="0" value="56" />
          <attvalue for="1" value="9" />
          <attvalue for="2" value="1.0" />
        </attvalues>
      </node>
      <node id=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." label=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible.">
        <attvalues>
          <attvalue for="0" value="57" />
          <attvalue for="1" value="2" />
          <attvalue for="2" value="0.46491117995167774" />
        </attvalues>
      </node>
      <node id=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" label=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;">
        <attvalues>
          <attvalue for="0" value="58" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.22397849060334002" />
        </attvalues>
      </node>
      <node id=" For a detailed descriptions see Haji6 (1998), Hladkfi (2000) and Collins, Haji6, Ram~haw, Tillmann (1999)." label=" For a detailed descriptions see Haji6 (1998), Hladkfi (2000) and Collins, Haji6, Ram~haw, Tillmann (1999).">
        <attvalues>
          <attvalue for="0" value="59" />
          <attvalue for="1" value="1" />
          <attvalue for="2" value="0.021112586425823282" />
        </attvalues>
      </node>
      <node id=" We use the statistical Collins's parser to create the structure of the tree and then a statistical procedure to assign words their syntactic functions." label=" We use the statistical Collins's parser to create the structure of the tree and then a statistical procedure to assign words their syntactic functions.">
        <attvalues>
          <attvalue for="0" value="59" />
          <attvalue for="1" value="0" />
          <attvalue for="2" value="0.022718188651481747" />
        </attvalues>
      </node>
    </nodes>
    <edges>
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." id="0" weight="91.15420973162472" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." id="1" weight="82.79106325935078" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." id="2" weight="80.12658067482927" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." id="3" weight="82.14059715619845" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." id="4" weight="85.05325974824973" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="5" weight="82.23910202011315" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="6" weight="82.56831124976007" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." id="7" weight="81.06438668718742" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." id="8" weight="81.76773534061587" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="9" weight="80.69116435445054" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="10" weight="80.56937127101887" />
      <edge source=" Two rule-based methods to convert dependency structure into phrase structure are presented by Covington and Collins et al." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="11" weight="80.11486584606153" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." id="12" weight="81.69005908060728" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." id="13" weight="85.36337508098224" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." id="14" weight="83.67772997196342" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." id="15" weight="80.74626813708747" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="16" weight="85.07503831918946" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="17" weight="82.3667724548367" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="18" weight="86.06563237695181" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="19" weight="81.21969757657777" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="20" weight="80.4655426884411" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="21" weight="84.71712278534478" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="22" weight="83.03955650974957" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="23" weight="84.15274595265278" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="24" weight="81.05434161404897" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="25" weight="81.00833014520205" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="26" weight="80.55052700917196" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="27" weight="80.46319516242953" />
      <edge source=" Covington and Collins et al. use three simple rules with the help of X-bar theory and convert the dependency structure into phrase structure." target=" We use the statistical Collins's parser to create the structure of the tree and then a statistical procedure to assign words their syntactic functions." id="28" weight="80.38996415124204" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="29" weight="82.07507628405652" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="30" weight="82.77747768703836" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="31" weight="88.15877586024445" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="32" weight="86.30562152372643" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="33" weight="80.83935338683482" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="34" weight="81.25109244854463" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="35" weight="80.85540627904793" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="36" weight="83.60633551317243" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="37" weight="87.03412795631009" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="38" weight="82.07971235251952" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="39" weight="85.75135424552407" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="40" weight="84.38970084724231" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="41" weight="80.4155744094872" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="42" weight="82.18268459790652" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="43" weight="84.21551161715577" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="44" weight="80.29961812945321" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="45" weight="83.67599457456313" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="46" weight="83.0213654124108" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="47" weight="81.37494034507348" />
      <edge source=" The dependents in the method of Collins et al.  project only one level; hence, the dependents of a head are in the same level." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="48" weight="80.61199366665761" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." id="49" weight="80.72705022415138" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." id="50" weight="80.04216830775218" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="51" weight="81.3265760670562" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="52" weight="83.8626657537898" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="53" weight="87.91579497660355" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="54" weight="80.82876669125032" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." id="55" weight="81.60211378592876" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="56" weight="80.16195312748482" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="57" weight="84.5274608081566" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="58" weight="84.60246431137746" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="59" weight="89.38102065953937" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="60" weight="81.64055093801308" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="61" weight="80.96198987961867" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="62" weight="80.07312363028409" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="63" weight="80.23880858866927" />
      <edge source=" We used the two-letter tag method proposed by Collins et al. to integrate a family of POS tags to a CPOS." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="64" weight="81.60408277183689" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." id="65" weight="81.33648626196445" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." id="66" weight="80.80058184950248" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." id="67" weight="86.07114928500803" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." id="68" weight="82.82385584421183" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." id="69" weight="94.53795956018772" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="70" weight="85.90309033255804" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="71" weight="87.61787225294341" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="72" weight="82.5397121028914" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="73" weight="82.30525054964248" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="74" weight="80.61070111838859" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="75" weight="80.13745703431626" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="76" weight="84.7137552481477" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="77" weight="85.55845123860648" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="78" weight="82.38126642373491" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="79" weight="82.1505444636291" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="80" weight="82.57534394744552" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="81" weight="87.41110229305704" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="82" weight="80.87216663572931" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="83" weight="80.31092377828666" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="84" weight="82.18339044663685" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="85" weight="81.35788165032037" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="86" weight="80.8258784913279" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="87" weight="82.75401845413141" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="88" weight="82.13721022324268" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="89" weight="82.65706770055476" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="90" weight="81.77013750921117" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="91" weight="81.48499898026154" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="92" weight="83.48483298110567" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="93" weight="81.62590679899029" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="94" weight="80.63878884071067" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="95" weight="85.34305148486965" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="96" weight="84.40546878229168" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="97" weight="82.8787090214852" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="98" weight="80.48511794213181" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="99" weight="85.58929792572765" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="100" weight="81.43825057295469" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="101" weight="83.89293556405353" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="102" weight="81.99558550728567" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="103" weight="83.34794632868672" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="104" weight="84.1565408034752" />
      <edge source=" Previous work on treebank conversion primarily focuses on converting one grammar formalism of a treebank into another and then conducting a study on the converted treebank (Collins et al., 1999; Xia et al., 2008)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="105" weight="83.02900987081915" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." id="106" weight="85.04158311413423" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." id="107" weight="83.98821475388391" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." id="108" weight="80.11960661921125" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="109" weight="84.38053646284938" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="110" weight="81.52513698045898" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="111" weight="84.0244649423028" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="112" weight="87.85748580582063" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="113" weight="81.18901009817345" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." id="114" weight="86.08239653145687" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="115" weight="82.33728696840936" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="116" weight="84.09488891120607" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="117" weight="85.80469009743159" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." id="118" weight="81.73730316819446" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="119" weight="83.5442840832665" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="120" weight="83.387052452521" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="121" weight="87.20731229703004" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="122" weight="82.16200978817987" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="123" weight="85.01762807745837" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="124" weight="82.0292022312081" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="125" weight="83.35988442728271" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="126" weight="85.06620654636072" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="127" weight="81.23810836629835" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="128" weight="80.93451154087225" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="129" weight="80.46180437800183" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="130" weight="81.385692462485" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="131" weight="80.66215800473265" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="132" weight="81.17887404810016" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="133" weight="88.28182792281922" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="134" weight="87.5846564101129" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="135" weight="86.84697096401774" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="136" weight="86.22456165748453" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="137" weight="85.84963726100574" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="138" weight="81.59295782534024" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="139" weight="83.63227342668063" />
      <edge source=" The coarse morphological tag provided by Czech two-letter coarse morphological tag, as described in (Collins et al., 1999), The first letter is the main POS (12 possible values), the second letter is either the morphological case field if the main POS displays case (i.e. for nouns, adjectives, pronouns, numerals and prepositions; 7 possible values), or the detailed POS if it does not (22 possible values)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="140" weight="84.4507199016168" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4]." target=" State-of-the-art morphological taggers can achieve accuracy rates of over 96% for English [34, 36] and 92% for highly inflected languages like Czech [20], and dependency parsers can achieve labeled accuracy rates for the same languages of 86% [31] and 80% [11], respectively." id="141" weight="80.54595985534179" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4]." target=" This two-dimensional parametrization2 was shown to improve parsing accuracy for English [4, 1] as well as other languages, e.g., German [7] Czech [5] and Chinese [2]." id="142" weight="91.25387415133991" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4]." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="143" weight="82.5109796249879" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4]." target=" Second, Czech exhibits a “relatively free word order” [7]." id="144" weight="81.73146881439885" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech [7], Bulgarian [15], Turkish [14] and Russian [4]." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="145" weight="83.83167178873599" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." id="146" weight="81.14224180565861" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="147" weight="84.2445936473488" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." id="148" weight="81.57378510086501" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="149" weight="81.07458398567049" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="150" weight="83.13083948540572" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." id="151" weight="80.24582651370554" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="152" weight="81.896651998697" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="153" weight="80.14848020139944" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="154" weight="81.5585293233118" />
      <edge source=" For example, for constituent (phrase-structure) syntactic parsing [Charniak 2000; Collins 1999; Petrov et al. 2006] of Chinese, besides the most popular treebank, Penn Chinese Treebank (CTB) [Xue et al. 2002], there are other treebanks such as Tsinghua Chinese Treebank (TCT) and Peking Chinese Treebank." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="155" weight="81.15744349523335" />
      <edge source=" Algorithm 2 presents the extended version of the decoding algorithm used in the Collins parser, what the algorithm needs to do is to generate edges for each span." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="156" weight="81.84604532258363" />
      <edge source=" Algorithm 2 presents the extended version of the decoding algorithm used in the Collins parser, what the algorithm needs to do is to generate edges for each span." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="157" weight="85.45527868749502" />
      <edge source=" Algorithm 2 presents the extended version of the decoding algorithm used in the Collins parser, what the algorithm needs to do is to generate edges for each span." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="158" weight="82.17411340889649" />
      <edge source=" Algorithm 2 presents the extended version of the decoding algorithm used in the Collins parser, what the algorithm needs to do is to generate edges for each span." target=" We use the statistical Collins's parser to create the structure of the tree and then a statistical procedure to assign words their syntactic functions." id="159" weight="87.49763099277554" />
      <edge source=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." target=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." id="160" weight="81.32184685974157" />
      <edge source=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." target=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." id="161" weight="89.65284957472892" />
      <edge source=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="162" weight="81.2843967409034" />
      <edge source=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="163" weight="80.32977312373555" />
      <edge source=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="164" weight="84.23005933606014" />
      <edge source=" One type focuses on converting treebanks of different grammar formalisms. Collins et al. [1999] addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="165" weight="81.49038888691945" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." id="166" weight="85.21295138401443" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." id="167" weight="100.0" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." id="168" weight="85.05166581692684" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." id="169" weight="80.79023632966657" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="170" weight="81.30461949128424" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="171" weight="80.27684759529896" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="172" weight="82.0685323880723" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="173" weight="83.50966496364674" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="174" weight="82.92000570602372" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="175" weight="83.5991711042591" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="176" weight="83.15181899492268" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="177" weight="82.0233310619227" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="178" weight="84.13603904003135" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="179" weight="86.76330921305966" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="180" weight="80.89479281514305" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="181" weight="82.24368083127528" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="182" weight="84.09341907889947" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="183" weight="85.52502603356157" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="184" weight="81.18459364547626" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="185" weight="83.08354853634717" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="186" weight="85.07174797148265" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="187" weight="80.04630996776092" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="188" weight="81.29117626709959" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="189" weight="82.57458136109015" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="190" weight="83.10353549974572" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="191" weight="82.88444535590278" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="192" weight="85.53446771574006" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="193" weight="86.3588073112963" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="194" weight="84.43247964502316" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="195" weight="81.5626755027101" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="196" weight="84.29107506958526" />
      <edge source=" Collins et al. (1999) report that an optimal tagset for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="197" weight="85.07592770224794" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." id="198" weight="84.20818178294309" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." id="199" weight="83.24052824106649" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." id="200" weight="89.38914225160539" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="201" weight="83.46218399196556" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." id="202" weight="86.17204995434594" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="203" weight="80.44752081404292" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="204" weight="87.25712831592205" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="205" weight="81.67818700303653" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="206" weight="84.15993907185295" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="207" weight="80.17232303956683" />
      <edge source=" Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="208" weight="85.48502856731986" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." id="209" weight="82.42728881039541" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." id="210" weight="80.79847065562613" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="211" weight="85.95682518490122" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="212" weight="84.02092699043496" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="213" weight="83.71093413397676" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="214" weight="80.35036159785858" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="215" weight="83.1594903107364" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="216" weight="80.78471309898634" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." id="217" weight="80.48687376585828" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="218" weight="86.54422012176694" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="219" weight="85.47840135820014" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="220" weight="87.16794030390105" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="221" weight="86.58143827490032" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="222" weight="85.90030289467303" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="223" weight="82.53620575256232" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="224" weight="83.83488698642647" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="225" weight="83.82953645073368" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="226" weight="80.41655831551815" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="227" weight="83.68104367629812" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="228" weight="84.05340457934243" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="229" weight="86.50955274833423" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="230" weight="85.4717908962777" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="231" weight="81.83347683058282" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="232" weight="82.81398627808949" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="233" weight="82.141292753827" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="234" weight="80.63744498320824" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="235" weight="81.40111912658577" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="236" weight="83.0976615011576" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="237" weight="84.89857623431885" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="238" weight="81.26930243438603" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="239" weight="80.90447443722921" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="240" weight="87.77239324456383" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="241" weight="83.6604405200617" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="242" weight="84.14801886133372" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="243" weight="81.95879783231328" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="244" weight="83.39852305222695" />
      <edge source=" By comparison, the case feature improved parsing for Czech (Collins et al., 1999) and the combination of the number feature for adjectives and mode feature for verbs improved results for Spanish (Cowan and Collins, 2005)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="245" weight="82.98598094966607" />
      <edge source=" For Czech, the adaptation by Collins et al. (1999) culminated in an 80 F1-score." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="246" weight="80.67089379718064" />
      <edge source=" For Czech, the adaptation by Collins et al. (1999) culminated in an 80 F1-score." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="247" weight="80.5372004344753" />
      <edge source=" For Czech, the adaptation by Collins et al. (1999) culminated in an 80 F1-score." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="248" weight="80.95444580053537" />
      <edge source=" For Czech, the adaptation by Collins et al. (1999) culminated in an 80 F1-score." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="249" weight="83.65541696960514" />
      <edge source=" For example, Collins et al. (1999) adapted Collins' parser to Czech, a highly- inflected language." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="250" weight="81.23069239662159" />
      <edge source=" For example, Collins et al. (1999) adapted Collins' parser to Czech, a highly- inflected language." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="251" weight="85.21527356088608" />
      <edge source=" For example, Collins et al. (1999) adapted Collins' parser to Czech, a highly- inflected language." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="252" weight="82.07086037186832" />
      <edge source=" For example, Collins et al. (1999) adapted Collins' parser to Czech, a highly- inflected language." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="253" weight="83.36916524519242" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." id="254" weight="82.98737842445438" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." id="255" weight="87.28735365702194" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="256" weight="85.34984386043799" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." id="257" weight="83.6322010625592" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="258" weight="84.7156587015625" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="259" weight="84.17248981921152" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="260" weight="87.90300037728672" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." id="261" weight="86.39177534795172" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="262" weight="82.69306844548971" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="263" weight="80.40429094789432" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="264" weight="86.42649826959703" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." id="265" weight="85.95034892414371" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="266" weight="86.98272402768312" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="267" weight="80.96543119137718" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="268" weight="86.52188892109666" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="269" weight="81.30298089280032" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="270" weight="88.17486293812745" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="271" weight="82.52960414605252" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="272" weight="86.44348777081154" />
      <edge source=" Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima'an, 2008), and the effect of variable word order (Collins et al., 1999)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="273" weight="81.99998991856745" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." id="274" weight="80.11953918098402" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." id="275" weight="85.70950720286919" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." id="276" weight="88.21577393619174" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="277" weight="88.62500141604119" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="278" weight="87.1695560079353" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="279" weight="80.41033531334323" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="280" weight="82.27128815120591" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." id="281" weight="82.45664524860086" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." id="282" weight="82.79939690146271" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="283" weight="84.98473896993453" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="284" weight="85.54445798226978" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="285" weight="84.43239966195901" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="286" weight="81.10577426984378" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." id="287" weight="86.88221433047923" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="288" weight="84.21666657834217" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="289" weight="87.87238019166112" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="290" weight="80.09831002221254" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="291" weight="80.28553789721326" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="292" weight="82.77453342986053" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="293" weight="80.48538321009553" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="294" weight="81.13090345702018" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="295" weight="86.2757905207377" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="296" weight="82.74362976662948" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="297" weight="83.68343438366608" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="298" weight="82.19435727038251" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="299" weight="83.81563804022838" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="300" weight="87.65715876567326" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="301" weight="80.99652325844941" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="302" weight="84.42334491318778" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="303" weight="81.97122147393326" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="304" weight="81.44017303844528" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="305" weight="83.38966996177102" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="306" weight="84.32000076682533" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="307" weight="85.96019554417842" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="308" weight="88.0442367723819" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="309" weight="83.13601229665117" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="310" weight="82.1484258792695" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="311" weight="84.29212074926673" />
      <edge source=" There have been some work (Collins et al., 1999b; Xia and Palmer, 2001) about converting dependency structures to phrase structures." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="312" weight="80.63754651716381" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." id="313" weight="80.4983552740584" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." id="314" weight="86.5599079465224" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="315" weight="82.86611118107463" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="316" weight="80.78537089362455" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="317" weight="88.27938912857385" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="318" weight="80.68092537609006" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." id="319" weight="81.64118104763831" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." id="320" weight="81.57383151003378" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="321" weight="80.16251337524506" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="322" weight="82.52043216083574" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="323" weight="81.00897828823088" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="324" weight="84.25669145686486" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="325" weight="84.8388462831272" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="326" weight="86.609049198179" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="327" weight="84.06703426809685" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="328" weight="80.80373843578815" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="329" weight="86.7082777012002" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." id="330" weight="83.14687063407334" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="331" weight="80.07478661824999" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="332" weight="82.38893521860614" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="333" weight="84.26956772446985" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="334" weight="82.93282468269653" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="335" weight="82.5234227233677" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="336" weight="83.76455354482898" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="337" weight="80.32591088572876" />
      <edge source=" Collins et al. (1999b) proposed an algorithm to convert the Czech dependency Treebank into a phrase structure Treebank and do dependency parsing through Collins (1999a)'s model." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="338" weight="83.39946770787705" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." id="339" weight="80.43044675792275" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." id="340" weight="80.23702860789395" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="341" weight="82.88598911200735" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="342" weight="84.0370466528884" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="343" weight="81.93586629117074" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="344" weight="80.3340379541811" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="345" weight="86.07131355853494" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." id="346" weight="80.76083002657273" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="347" weight="82.5750023768111" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="348" weight="83.65221042256947" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="349" weight="83.07889960667785" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="350" weight="80.7534274754002" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="351" weight="84.53794594578925" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="352" weight="89.66627623758754" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="353" weight="80.88276620668815" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="354" weight="82.45508981842747" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="355" weight="83.27353330738309" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="356" weight="85.07557881819501" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="357" weight="82.13962113453832" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="358" weight="80.4583166289427" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="359" weight="80.45461508180716" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="360" weight="85.30249503886813" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="361" weight="85.5728318636943" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="362" weight="81.06512641487336" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="363" weight="83.61125355111758" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="364" weight="82.40036942789666" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="365" weight="86.48596133558566" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="366" weight="83.84755523779761" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="367" weight="80.29566016423149" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="368" weight="87.56869505758813" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="369" weight="86.60830655534468" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="370" weight="86.69719190306313" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="371" weight="81.58268213734416" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="372" weight="81.14852307632148" />
      <edge source=" Different from tree- transformed PCFG based approach and lexicalized PCFG based approach, both of Collins et al. (1999b) and Xia and Palmer (2001) attempted to build some heuristic rules through linguistic theory, but didn't try to learn anything from Treebank." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="373" weight="80.19370720111823" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="374" weight="81.6749648229208" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="375" weight="84.12739165220722" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="376" weight="87.34024135346523" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="377" weight="83.83100792239746" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." id="378" weight="80.24171636260672" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." id="379" weight="80.33299086948402" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="380" weight="84.45406637144761" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="381" weight="83.93685678594593" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="382" weight="80.3097725167997" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="383" weight="87.1494622875649" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="384" weight="81.24833834449443" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="385" weight="80.95010940201377" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="386" weight="86.61978795134968" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="387" weight="80.4036710845112" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="388" weight="82.77685298391779" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="389" weight="80.36983458900416" />
      <edge source=" Collins et al. (1999) addressed constituent syntactic parsing on Czech using a treebank converted from a Prague dependency treebank, where conversion rules derived from head-dependent pairs and heuristic rules are applied." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="390" weight="82.47736339667841" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." id="391" weight="87.5180370707653" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="392" weight="85.94360328344013" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." id="393" weight="82.38978780048296" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="394" weight="83.69908255303697" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="395" weight="86.81750401178073" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="396" weight="88.21267920368301" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="397" weight="80.35734683634766" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="398" weight="82.93822148277155" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="399" weight="83.50861578593967" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="400" weight="81.94836929938754" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="401" weight="80.21672628626182" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="402" weight="88.36643123639476" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." id="403" weight="83.32722164055639" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="404" weight="81.95318219961585" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="405" weight="83.89203332009676" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="406" weight="88.45638542181796" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="407" weight="86.85112125238732" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="408" weight="83.19073266873285" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="409" weight="80.25901840868804" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="410" weight="82.22840119399734" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="411" weight="81.89839136419454" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="412" weight="86.88650723930805" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="413" weight="85.51547048062153" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="414" weight="82.4053380991183" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="415" weight="82.30081416810306" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="416" weight="82.26249581875655" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="417" weight="86.97777072457336" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="418" weight="81.60056388965116" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="419" weight="87.22500863483418" />
      <edge source=" Other related works focus on converting one grammar formalism of a treebank to another and then conducting studies on the converted treebank (Collins et al., 1999; Forst, 2003; Wang et al., 1994; Watkinson and Manandhar, 2001)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="420" weight="82.63547269135447" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." id="421" weight="92.84420830053814" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="422" weight="89.82943333814902" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="423" weight="80.9499649271235" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="424" weight="83.89820562022064" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="425" weight="82.6222785962764" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." id="426" weight="84.62223741520664" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="427" weight="82.85724387653872" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="428" weight="90.98240124003658" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="429" weight="87.5342527842823" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="430" weight="83.1364272163332" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." id="431" weight="82.19653951277243" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="432" weight="81.12214521681838" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="433" weight="84.35096493907498" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="434" weight="90.61468196481881" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="435" weight="81.59924779398567" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="436" weight="80.65305163732586" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="437" weight="83.01557613726405" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="438" weight="80.90371472695325" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="439" weight="82.42104335331038" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="440" weight="84.46108356456455" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="441" weight="81.60490887603473" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="442" weight="80.79810990339445" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="443" weight="87.32880469551749" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="444" weight="82.62301895832265" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="445" weight="82.38289992140635" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="446" weight="80.2307544342838" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="447" weight="87.56630937829519" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="448" weight="83.64586313938156" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="449" weight="81.59855530424156" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="450" weight="84.80787713762506" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="451" weight="83.6135401916984" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="452" weight="85.5334603972019" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="453" weight="84.89652924564592" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="454" weight="86.59522515321696" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="455" weight="83.59913141438756" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="456" weight="89.15747421483067" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="457" weight="80.69367551162401" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="458" weight="80.36309632253564" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="459" weight="85.09483983567752" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="460" weight="80.54624516521483" />
      <edge source=" Previous methods for DS to PS conversion (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008) often rely on pre- defined heuristic rules to eliminate converison ambiguity, e.g., minimal projection for dependents, lowest attachment position for dependents, and the selection of conversion rules that add fewer number of nodes to the converted tree." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="461" weight="81.37530203475988" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." id="462" weight="87.1522003512707" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="463" weight="86.03587216476822" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="464" weight="85.0810374188695" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="465" weight="80.71107612813793" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="466" weight="86.57382369223694" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="467" weight="84.76771518165687" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="468" weight="85.23220593603698" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="469" weight="82.34761965965016" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="470" weight="85.79244279831275" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="471" weight="83.5848250960705" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="472" weight="80.45311124141045" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="473" weight="81.69873793667767" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="474" weight="80.30308941706879" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="475" weight="85.93338759265568" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="476" weight="84.9911365008274" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="477" weight="85.11544615872444" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="478" weight="84.5257743187209" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="479" weight="81.3899458191909" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="480" weight="85.36397338204952" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="481" weight="84.87711368052157" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="482" weight="81.14920059656265" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="483" weight="81.29600510682886" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="484" weight="83.61077659590353" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="485" weight="86.15361872116878" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." id="486" weight="86.3197123277291" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="487" weight="86.30967940551149" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="488" weight="85.65936245501095" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="489" weight="81.04179624139323" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="490" weight="85.51920533169867" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="491" weight="85.45890903425048" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="492" weight="85.33016102424978" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="493" weight="80.37202472052181" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="494" weight="83.88885276166667" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="495" weight="82.165449473164" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="496" weight="84.7843779750275" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="497" weight="83.46761807137817" />
      <edge source=" Previous DS to PS conversion methods built a converted tree by iteratively attaching nodes and edges to the tree with the help of conversion rules and heuristic rules, based on current head- dependent pair from a source dependency tree and the structure of the built tree (Collins et al., 1999; Covington, 1994; Xia and Palmer, 2001; Xia et al., 2008)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="498" weight="84.53114630104966" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." id="499" weight="87.26827324630071" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="500" weight="82.5103069277436" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="501" weight="81.81825717818147" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="502" weight="85.11834052370082" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="503" weight="84.60048662366779" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="504" weight="82.39460107851127" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="505" weight="83.8900835354518" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="506" weight="83.37712733891141" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="507" weight="88.48639278721532" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="508" weight="84.10437740125913" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="509" weight="85.58360359062162" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="510" weight="84.46499476252932" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="511" weight="85.09353527263825" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="512" weight="84.51870798359009" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="513" weight="83.3330729284733" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="514" weight="82.56344146616445" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="515" weight="84.94011302663738" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="516" weight="82.77735026584207" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="517" weight="80.17386784261969" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="518" weight="81.22677255680979" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="519" weight="80.15259602713923" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="520" weight="84.96846073864504" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="521" weight="86.29316549783101" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="522" weight="80.67943677417131" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="523" weight="83.4337695446345" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="524" weight="87.66824547301522" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="525" weight="85.88565440635685" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="526" weight="81.3360784588548" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="527" weight="82.82173307811335" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="528" weight="84.14358833481923" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="529" weight="82.69739932657309" />
      <edge source=" Collins et al. (1999) performed statistical constituency parsing of Czech on a treebank that was converted from the Prague Dependency Treebank under the guidance of conversion rules and heuristic rules, e.g., one level of projection for any category, minimal projection for any dependents, and fixed position of attachment." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="530" weight="88.01628343097683" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." id="531" weight="81.82683845541021" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" id="532" weight="80.85239809589824" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="533" weight="80.56527950326003" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="534" weight="83.3765787594438" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="535" weight="81.30085921220333" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="536" weight="87.27438884491573" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="537" weight="86.56131385440935" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="538" weight="82.96448864227382" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="539" weight="88.90501982505641" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="540" weight="85.91472343244084" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="541" weight="85.48469172003578" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="542" weight="86.7295661715598" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="543" weight="86.69529140159062" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="544" weight="81.29935974174363" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="545" weight="80.0045239783195" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="546" weight="81.60214500368332" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="547" weight="86.26428072532812" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." id="548" weight="83.9485883654336" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="549" weight="80.70455481907597" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="550" weight="85.29511136409829" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="551" weight="80.75345297248168" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="552" weight="82.07588881508427" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="553" weight="85.99397788731054" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="554" weight="81.83612831102887" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="555" weight="85.02095326051491" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="556" weight="80.27766966341714" />
      <edge source=" In the application of the Collins parser to the Prague Dependency Treebank (Collins et al. 1999) the automatic mapping from dependency to phrase-structure was a major area of research." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="557" weight="86.63347016723489" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="558" weight="84.43991744669965" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="559" weight="83.31963248937649" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="560" weight="89.01224329255434" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." id="561" weight="87.27834123219482" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="562" weight="87.54066755525982" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="563" weight="81.80737816977613" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="564" weight="84.08389529660741" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="565" weight="81.98688149776177" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="566" weight="81.98980953596353" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="567" weight="83.11629588053397" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="568" weight="83.17864647594797" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="569" weight="92.35892772154104" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="570" weight="83.36232384758011" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="571" weight="80.82105958913534" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="572" weight="83.95085747236305" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="573" weight="84.75946210798739" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="574" weight="82.36838629645598" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="575" weight="84.33795166723597" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="576" weight="80.32742226444157" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="577" weight="80.62485098473427" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="578" weight="82.8147360269845" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="579" weight="83.31516487600308" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="580" weight="83.48308065553229" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="581" weight="80.40994577604579" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="582" weight="82.96871006305253" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="583" weight="84.97476114975393" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="584" weight="84.26679047843481" />
      <edge source=" Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT3, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="585" weight="85.16304165369601" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." id="586" weight="81.15943275810267" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." id="587" weight="81.27928227482428" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="588" weight="85.10645887166189" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="589" weight="84.24312180869092" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="590" weight="85.02823405373799" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="591" weight="81.66143312304503" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="592" weight="89.04147492499736" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="593" weight="87.20178656017615" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="594" weight="81.84928696778336" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="595" weight="83.6169816567007" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="596" weight="80.67476590236737" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="597" weight="82.16657462008692" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="598" weight="82.02927279833563" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="599" weight="83.4732792426475" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="600" weight="83.00487509404269" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="601" weight="83.98196533882303" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="602" weight="84.48958192363605" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="603" weight="82.66409887902924" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="604" weight="87.98341830997241" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="605" weight="80.83011829286303" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="606" weight="85.20672957441613" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="607" weight="88.01344972866386" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="608" weight="84.37324938562634" />
      <edge source=" As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., (Collins et al., 1999))" target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="609" weight="81.57683241724712" />
      <edge source=" With its 1.5 million syntactically annotated tokens, the PDT in version 2.0 forms the biggest source of Czech syntactic data. Dependency parsers, e.g. [8,9], usually use the PDT data for training their internal syntax models." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="610" weight="81.42730427479911" />
      <edge source=" With its 1.5 million syntactically annotated tokens, the PDT in version 2.0 forms the biggest source of Czech syntactic data. Dependency parsers, e.g. [8,9], usually use the PDT data for training their internal syntax models." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="611" weight="80.26729830462749" />
      <edge source=" With its 1.5 million syntactically annotated tokens, the PDT in version 2.0 forms the biggest source of Czech syntactic data. Dependency parsers, e.g. [8,9], usually use the PDT data for training their internal syntax models." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="612" weight="81.0754105202363" />
      <edge source=" State-of-the-art morphological taggers can achieve accuracy rates of over 96% for English [34, 36] and 92% for highly inflected languages like Czech [20], and dependency parsers can achieve labeled accuracy rates for the same languages of 86% [31] and 80% [11], respectively." target=" This two-dimensional parametrization2 was shown to improve parsing accuracy for English [4, 1] as well as other languages, e.g., German [7] Czech [5] and Chinese [2]." id="613" weight="81.59999558727331" />
      <edge source=" State-of-the-art morphological taggers can achieve accuracy rates of over 96% for English [34, 36] and 92% for highly inflected languages like Czech [20], and dependency parsers can achieve labeled accuracy rates for the same languages of 86% [31] and 80% [11], respectively." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="614" weight="80.04383584711105" />
      <edge source=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." target=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." id="615" weight="80.74544726824335" />
      <edge source=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="616" weight="85.03401888745428" />
      <edge source=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="617" weight="81.42670959471468" />
      <edge source=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="618" weight="84.42427836937192" />
      <edge source=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="619" weight="83.41902033303397" />
      <edge source=" It is possible to derive transformations that will convert many dependency grammars to context-free grammars, and vice versa [Collins et al. 1999]." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="620" weight="80.0044856615983" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="621" weight="83.76103084291957" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="622" weight="85.98152577350429" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="623" weight="87.37754767706095" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="624" weight="81.9447577825035" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="625" weight="82.99363161471219" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="626" weight="84.26201007624043" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="627" weight="87.21246589381136" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="628" weight="80.11409852023657" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="629" weight="84.00314450463684" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="630" weight="82.42882284079944" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="631" weight="80.10663694402925" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="632" weight="80.9283389243969" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="633" weight="82.90550144024182" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="634" weight="85.8092728435683" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="635" weight="82.8246833423678" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="636" weight="80.5614359608926" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="637" weight="85.73670808942431" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="638" weight="87.96123618797122" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="639" weight="90.42893057960319" />
      <edge source=" The two of them which are most conspicuous, and identified as most problematic, e.g., in (Collins et al., 1999), are rich nominal inflection (§2.1) and free word order (§2.6)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="640" weight="81.02088073613214" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." id="641" weight="83.56517047162149" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="642" weight="89.19261197038637" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="643" weight="81.33027573623473" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="644" weight="87.11643464928291" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." id="645" weight="85.30910549757648" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="646" weight="86.55651595127667" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." id="647" weight="82.34213783302397" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="648" weight="80.70154608679614" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="649" weight="82.1544485435882" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="650" weight="85.34502301002038" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="651" weight="93.65637381786985" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." id="652" weight="81.47037550378545" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="653" weight="80.42746102128471" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="654" weight="87.64009350388433" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="655" weight="81.21270230649922" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="656" weight="84.54594099541049" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="657" weight="80.07531652901329" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="658" weight="84.93946317820654" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="659" weight="86.86782844667025" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="660" weight="85.7178884179971" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="661" weight="87.32852027184164" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="662" weight="88.90462490236615" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="663" weight="87.50314241300534" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="664" weight="82.28376898703264" />
      <edge source=" This two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for English as well as other languages, such as German (Dubey and Keller, 2003) Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="665" weight="82.13414495436734" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." id="666" weight="89.67401958333248" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="667" weight="85.36982313706247" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="668" weight="86.16491948347442" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="669" weight="84.87271558253669" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="670" weight="88.55692436556532" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="671" weight="81.11115558221194" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="672" weight="80.02121794015866" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="673" weight="85.53008482132478" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="674" weight="81.0508245562326" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="675" weight="85.27972918006934" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="676" weight="81.38153268553157" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="677" weight="86.15024180777549" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="678" weight="81.57424550227452" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="679" weight="83.91980391242373" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="680" weight="86.8395323526437" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="681" weight="84.77640567756765" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="682" weight="80.19382865410753" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="683" weight="88.22372901838264" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="684" weight="82.30833157588806" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="685" weight="86.74524633415768" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="686" weight="85.12094775570596" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="687" weight="90.49482266740753" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="688" weight="85.60822902509535" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="689" weight="80.810939888952" />
      <edge source=" The increasing availability of multi-format treebanks  and the automatic conversion from some formats to others, e.g. (Collins et al, 1999; Bahgat Shehata and Zanzotto, 2006), are attempts to overcome this problem." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="690" weight="83.8450597392789" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." id="691" weight="84.98457680086867" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="692" weight="87.10193728062336" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="693" weight="86.57564195905256" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." id="694" weight="81.46563067081823" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="695" weight="89.06483775945442" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="696" weight="83.04036199970892" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="697" weight="86.61537241787683" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="698" weight="81.49128386815529" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="699" weight="85.1443773895803" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="700" weight="91.26136911323273" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="701" weight="81.23899398182309" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="702" weight="83.30911948283146" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="703" weight="82.65294776416543" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="704" weight="83.07661780617606" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="705" weight="88.1580412008458" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="706" weight="80.7845224113729" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="707" weight="86.7701365415044" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="708" weight="82.93206018646448" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="709" weight="84.47074936658994" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="710" weight="82.64614590936408" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="711" weight="86.88028596720585" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="712" weight="81.18272009168722" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="713" weight="82.48390288064226" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="714" weight="81.43251475225057" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="715" weight="86.22730497607363" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="716" weight="87.61765984460392" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="717" weight="88.9746607749126" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="718" weight="81.6680346026918" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="719" weight="84.96086314421736" />
      <edge source=" For instance, the availability of parallel annotations, and among them one in Penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on tree- banks or languages other than Penn and English, as empirically demonstrated by, e.g., (Collins et al, 1999) on Czech, (Dubey and Keller, 2003) on German, (Corazza et al, 2004) on Italian." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="720" weight="80.10970170671929" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." id="721" weight="83.62267312225438" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="722" weight="86.41889504400572" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="723" weight="81.10590806712243" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="724" weight="83.32231448672542" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="725" weight="84.19144568277537" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="726" weight="81.39509932254292" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="727" weight="81.62434820672202" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="728" weight="82.33111982130647" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="729" weight="82.09260417319027" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="730" weight="89.97261001877834" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="731" weight="82.12195241138289" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="732" weight="82.5224468250073" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="733" weight="82.52366334392943" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="734" weight="81.33761239590226" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="735" weight="83.95573782392051" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="736" weight="80.89407422836763" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="737" weight="83.65823003534175" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="738" weight="80.0331245853806" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="739" weight="84.02843465255117" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="740" weight="83.67912351905477" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="741" weight="80.89826371595159" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="742" weight="80.78912396391316" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="743" weight="82.57284818042802" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="744" weight="84.63559694572969" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="745" weight="86.63613561050565" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="746" weight="83.41970965202255" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="747" weight="83.3010129238796" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="748" weight="82.6597793877467" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="749" weight="86.05208117779416" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="750" weight="83.24169036958817" />
      <edge source=" The output of this first step includes compact tags where features are expressed by short strings, like in (Collins et al, 1999)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="751" weight="85.02837732175313" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" id="752" weight="81.90935649719482" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="753" weight="80.45650284030539" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="754" weight="84.51649875740226" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="755" weight="86.73912267652224" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="756" weight="84.09564645445344" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="757" weight="91.38778959406515" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="758" weight="83.24973084783412" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="759" weight="80.67713542462613" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="760" weight="82.36563764735305" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="761" weight="80.7358645830992" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="762" weight="87.18766554902184" />
      <edge source=" We have described the feature templates and we have shown that when we are able to train over a large feature space, the addition of full 15-letters morphological tags for Czech outperforms the 2-letters tags commonly used since [5]." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="763" weight="83.02827407135582" />
      <edge source=" This two-dimensional parametrization2 was shown to improve parsing accuracy for English [4, 1] as well as other languages, e.g., German [7] Czech [5] and Chinese [2]." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="764" weight="80.56667964545434" />
      <edge source=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." target=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." id="765" weight="81.34587350369817" />
      <edge source=" More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="766" weight="80.72952603988735" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="767" weight="84.08320818580566" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="768" weight="84.66318371595405" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="769" weight="81.30536425935368" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="770" weight="80.6257492685339" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="771" weight="82.76935772453125" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="772" weight="81.29060277716549" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="773" weight="89.17164661994033" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="774" weight="81.81189144435277" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="775" weight="82.61572848020205" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="776" weight="81.62764492586754" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="777" weight="80.85284715010357" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="778" weight="87.13657571132991" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="779" weight="82.68400993175473" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="780" weight="84.2184223817072" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="781" weight="83.42734537552974" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="782" weight="80.42417201538036" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="783" weight="86.50310231387957" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="784" weight="80.15122493504757" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="785" weight="82.59469226165541" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="786" weight="83.41048976858667" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="787" weight="83.72358598340868" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="788" weight="87.62472030606496" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="789" weight="83.58980591747876" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="790" weight="83.23480652525951" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="791" weight="81.2915034130246" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="792" weight="83.17525681547579" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="793" weight="80.21607649162826" />
      <edge source=" The part-of-speech tagging used (both in training and testing) is the HMM tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in Collins et al. (1999)" target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="794" weight="87.96067834078364" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." id="795" weight="88.62771739076696" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="796" weight="82.67731231754274" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="797" weight="84.89440887534963" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="798" weight="83.74248854959075" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="799" weight="82.14583481707332" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="800" weight="83.3630044885642" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="801" weight="86.32742231724409" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="802" weight="82.09459746903323" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="803" weight="87.00867153636634" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="804" weight="82.8387862313836" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="805" weight="85.95179595107578" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="806" weight="80.26352566756808" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="807" weight="84.90722963287789" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="808" weight="87.96241828809319" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="809" weight="86.82724632281862" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="810" weight="81.75995147009661" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="811" weight="82.14883363517494" />
      <edge source=" Dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as Czech (Collins et al., 1999)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="812" weight="81.18800258185404" />
      <edge source=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="813" weight="86.7892216698293" />
      <edge source=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." target=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." id="814" weight="87.4636262784327" />
      <edge source=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="815" weight="90.71797650483514" />
      <edge source=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="816" weight="92.12317634444662" />
      <edge source=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="817" weight="83.55159771234821" />
      <edge source=" Collins (1997)'s parser and its reimplementation and extension by Bikel (2002) have by now been applied to a variety of languages: English (Collins, 1999), Czech (Collins et al., 1999), German (Dubey and Keller, 2003), Spanish (Cowan and Collins, 2005), French (Arun and Keller, 2005), Chinese (Bikel, 2002) and, according to Dan Bikel's web page, Arabic." target=" For a detailed descriptions see Haji6 (1998), Hladkfi (2000) and Collins, Haji6, Ram~haw, Tillmann (1999)." id="818" weight="87.19593284686293" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." id="819" weight="82.54429596317325" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." id="820" weight="82.07274713340765" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="821" weight="81.50083808251203" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="822" weight="81.90319431821416" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="823" weight="81.78938175217796" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="824" weight="86.58649091844404" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="825" weight="84.73113967917489" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="826" weight="83.57052918528196" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="827" weight="85.70254755648945" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="828" weight="81.15136238983605" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="829" weight="81.58677708359959" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="830" weight="83.92076754048756" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="831" weight="85.90994164425602" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="832" weight="89.13161917109002" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="833" weight="81.64671386119231" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="834" weight="86.06938046031836" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="835" weight="84.19388533824979" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="836" weight="81.75177455410494" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="837" weight="85.97241425588705" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="838" weight="84.02382209316298" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="839" weight="86.65425706220115" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="840" weight="86.10215802415848" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="841" weight="90.34317123354134" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="842" weight="90.63607653238583" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="843" weight="90.69669883289538" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="844" weight="84.46583665189044" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="845" weight="85.47797028858012" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="846" weight="82.74277916811737" />
      <edge source=" The usage of special knowledge bases to determine projections of categories (Xia and Palmer, 2001) would have presupposed language-dependent knowledge, so we investigated two other options: Flat rules (Collins et al., 1999) and binary rules." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="847" weight="83.39749753368014" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." id="848" weight="82.78195064694759" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="849" weight="81.54314179086661" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="850" weight="84.46865735697524" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="851" weight="84.82427817226868" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="852" weight="81.87890192834706" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="853" weight="84.61466315475093" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="854" weight="82.83182592171438" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="855" weight="82.31950186504793" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="856" weight="82.45041340322376" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="857" weight="81.88403372173477" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="858" weight="81.4153848029854" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="859" weight="81.16918126914531" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="860" weight="80.90926356866265" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="861" weight="85.34364437089432" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="862" weight="82.35168043379855" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="863" weight="84.94159804084234" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="864" weight="82.8038861122415" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="865" weight="85.23468209990754" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="866" weight="86.92077605471309" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="867" weight="81.21522615838029" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="868" weight="83.57623228309048" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="869" weight="82.31309699119728" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="870" weight="82.16225514911861" />
      <edge source=" Finally the placement of punctuation signs has a major impact on the performance of a parser (Collins et al., 1999)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="871" weight="82.52885034812607" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="872" weight="85.90128677223731" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="873" weight="81.32672620802548" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="874" weight="85.76342525858922" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="875" weight="81.6565240277337" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="876" weight="87.10075581786829" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="877" weight="82.02640195893356" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="878" weight="81.63645525508203" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="879" weight="80.04770763010893" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="880" weight="85.44045140377115" />
      <edge source=" So, Collins et al. (1999) proposed a tag classification for parsing the Czech treebank." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="881" weight="81.65862843743774" />
      <edge source=" Comparable results in the literature are Schiehlen's (2004) 81.03% dependency f- score reached on the German NEGRA treebank and Collins et al.'s (1999) 80.0% labelled accuracy on the Czech PDT treebank." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="882" weight="87.38090490421322" />
      <edge source=" Comparable results in the literature are Schiehlen's (2004) 81.03% dependency f- score reached on the German NEGRA treebank and Collins et al.'s (1999) 80.0% labelled accuracy on the Czech PDT treebank." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="883" weight="81.98800642330686" />
      <edge source=" Comparable results in the literature are Schiehlen's (2004) 81.03% dependency f- score reached on the German NEGRA treebank and Collins et al.'s (1999) 80.0% labelled accuracy on the Czech PDT treebank." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="884" weight="81.83707503560633" />
      <edge source=" Comparable results in the literature are Schiehlen's (2004) 81.03% dependency f- score reached on the German NEGRA treebank and Collins et al.'s (1999) 80.0% labelled accuracy on the Czech PDT treebank." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="885" weight="80.14041872163091" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="886" weight="84.94310582661771" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="887" weight="82.03462275201166" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="888" weight="82.10315598288136" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="889" weight="83.2669405009564" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="890" weight="84.57268975049763" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="891" weight="83.70922290861635" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="892" weight="83.96165371390703" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="893" weight="80.55510984984251" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="894" weight="83.98963230726825" />
      <edge source=" They are referred to using the following abbreviations: McD (McDonnald's maximum spanning tree parser, [6]),6 COL (Collins's parser adapted for PDT, [7]), ZZ (rule-based dependency parser described in Section 2), AN (Holan's parser ANALOG which has no training phase and in the parsing phase it searches for the local tree configuration most similar to the training data, [5]), L2R, R2L, L23 and R32 (pushdown parsers introduced in Section 3)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="895" weight="84.90764400240545" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." id="896" weight="86.98895987356441" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="897" weight="88.71934210987529" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="898" weight="88.13194969751324" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="899" weight="82.11691680083517" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="900" weight="84.00275569996563" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="901" weight="81.20722231047253" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="902" weight="80.0719028625406" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="903" weight="84.86299744442518" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="904" weight="84.75793341432403" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="905" weight="82.92744309550328" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="906" weight="81.3691679749921" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="907" weight="81.19664101298638" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="908" weight="85.7475639872473" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="909" weight="85.27879566887597" />
      <edge source=" We thus augment the syntactic type of conjuncts to include the type of the conjoined constituents by using the syntactic type of the head child. This is similar to what was done for Czech by Collins et al. [1]." target=" We use the statistical Collins's parser to create the structure of the tree and then a statistical procedure to assign words their syntactic functions." id="910" weight="82.97093959700467" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." id="911" weight="88.87149213500638" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="912" weight="87.10139592517167" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="913" weight="82.10257655999919" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="914" weight="82.99496502734058" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="915" weight="81.21871601753963" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="916" weight="83.30361689806884" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="917" weight="83.62151254201413" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="918" weight="86.7755174222144" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="919" weight="81.1423692585808" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="920" weight="86.25080237977714" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="921" weight="86.79235481049665" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="922" weight="80.41535922593792" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="923" weight="83.88497089622187" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="924" weight="90.22080006642501" />
      <edge source=" The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser [1], is applied to a new language, which often leads to a significant decrease in the measured accuracy [2,3,4,5,6]." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="925" weight="86.71726417862511" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." id="926" weight="88.0478802907611" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="927" weight="86.95466867156343" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="928" weight="82.75819649076533" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="929" weight="84.73215083241712" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="930" weight="80.77553236767774" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="931" weight="82.63639738578317" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="932" weight="84.37571412108798" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="933" weight="86.97637813352577" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." id="934" weight="83.47487888741713" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="935" weight="81.13118339636233" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="936" weight="88.22741448488189" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="937" weight="80.26033361539689" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="938" weight="80.60879739200684" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="939" weight="88.87911945576509" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="940" weight="85.62110955798998" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="941" weight="80.4657155075081" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="942" weight="80.85873565808697" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="943" weight="84.00606391291035" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="944" weight="84.4125347837805" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="945" weight="88.44827600503773" />
      <edge source=" The remaining set of projected trees becomes the treebank that will be used to train a new dependency parser — we conduct our experiments using a version of the Collins parser that has been adapted for dependency treebanks (Collins et al. 1999)." target=" We use the statistical Collins's parser to create the structure of the tree and then a statistical procedure to assign words their syntactic functions." id="946" weight="84.14035760120294" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." id="947" weight="84.12360677323274" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="948" weight="82.58063683745362" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="949" weight="80.05506368021913" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="950" weight="84.88306154561907" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="951" weight="82.1974002196574" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="952" weight="85.7500607168515" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="953" weight="82.42206019289746" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="954" weight="86.45736236146729" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="955" weight="80.21259333170275" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="956" weight="80.58200922005582" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="957" weight="81.98612531612423" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="958" weight="84.26494664405016" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="959" weight="88.45092741495289" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="960" weight="81.11043010947981" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="961" weight="83.52300145912332" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="962" weight="84.19007874929967" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="963" weight="88.01663693180095" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="964" weight="87.84186299570045" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="965" weight="83.98501182880875" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="966" weight="85.69552695879898" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="967" weight="85.17126589697945" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="968" weight="85.96185065852629" />
      <edge source=" In particular, we used the method of Collins et al. (1999) to simplify part-of-speech tags since the rich tags used by Czech would have led to a large but rarely seen set of POS features." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="969" weight="86.98037592693211" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." id="970" weight="86.45940185026181" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="971" weight="80.45991522616013" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="972" weight="81.8636719184742" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="973" weight="80.326025041326" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="974" weight="81.72088403449867" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="975" weight="84.84223266054565" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="976" weight="86.12812962396671" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="977" weight="80.70798013781805" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="978" weight="88.11905776520736" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="979" weight="81.44006855802135" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="980" weight="84.09340174777017" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="981" weight="80.84288387526368" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="982" weight="83.43750103239893" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="983" weight="85.44240239154051" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="984" weight="85.49736427121206" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="985" weight="85.06178020257752" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="986" weight="81.10382219739951" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="987" weight="86.86464017980164" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="988" weight="82.56752367750839" />
      <edge source=" The Czech parser of Collins et al. (1999) was run on a different data set and most other dependency parsers are evaluated using English." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="989" weight="84.5643623488549" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." id="990" weight="83.39926759863054" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." id="991" weight="86.21220512642151" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="992" weight="82.86988613307061" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="993" weight="81.51036790020343" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." id="994" weight="80.30947586119552" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="995" weight="80.77158758510987" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="996" weight="87.66410036034726" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="997" weight="81.00350779393722" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="998" weight="81.94978180049381" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="999" weight="84.30768643674071" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="1000" weight="83.91125253508021" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="1001" weight="81.94621204349728" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1002" weight="86.72289575025074" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="1003" weight="80.25953928923346" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="1004" weight="86.3230836367529" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1005" weight="86.76024020370107" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1006" weight="86.65912605053443" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1007" weight="84.95248355643542" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1008" weight="84.81407346126831" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1009" weight="80.3033829975963" />
      <edge source=" It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1010" weight="83.33975461933416" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="1011" weight="81.38974190004184" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." id="1012" weight="83.76020290503388" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="1013" weight="80.4674583404984" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="1014" weight="91.49168209789049" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="1015" weight="81.82338842689971" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="1016" weight="87.77951239758399" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="1017" weight="86.86132219023108" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="1018" weight="90.51128674720002" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="1019" weight="87.48038932556264" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1020" weight="86.37945063535422" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1021" weight="86.46290908331149" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1022" weight="87.29159861582288" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1023" weight="81.65390416555924" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="1024" weight="83.79212650149688" />
      <edge source=" Interest in parsing models for languages other than English has been growing, starting with work on Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000; Levy and Manning, 2003)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1025" weight="80.24412483959689" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." id="1026" weight="80.30167192050675" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="1027" weight="80.37308544849233" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="1028" weight="84.33256208277355" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." id="1029" weight="80.7212590493433" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1030" weight="82.6257169956584" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1031" weight="83.08136310390535" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1032" weight="85.9676650818068" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1033" weight="80.2575912237306" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1034" weight="84.05215476863506" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="1035" weight="80.55609440072293" />
      <edge source=" Bigram Model This model, inspired by the approach of Collins et al. (1999) for parsing the Prague Dependency Treebank, builds on Collins' Model 2 by implementing a 1st order Markov assumption for the generation of sister non-terminals." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1036" weight="84.78950919129404" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." id="1037" weight="82.38397066923619" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="1038" weight="82.05636019974236" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="1039" weight="87.21777823926516" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1040" weight="83.31909671242532" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="1041" weight="81.19320669805552" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1042" weight="86.21578153043995" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1043" weight="88.7533056162843" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1044" weight="81.43574384927274" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1045" weight="81.39129080945312" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1046" weight="80.52712216465912" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1047" weight="81.99085368459302" />
      <edge source=" This is consistent with the findings of Collins et al. (1999) for Czech, where the bigram model upped dependency accuracy by about 0.9%, as well as for English where Charniak (2000) reports an increase in F-score of approximately 0.3%." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1048" weight="83.65458291355219" />
      <edge source=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." target=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." id="1049" weight="82.94416203320345" />
      <edge source=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="1050" weight="83.33401949525823" />
      <edge source=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="1051" weight="89.95989860539683" />
      <edge source=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="1052" weight="85.47809011372267" />
      <edge source=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1053" weight="81.10078498992192" />
      <edge source=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="1054" weight="82.05198533322773" />
      <edge source=" Most previous dependency parsing models have focused on projective trees, including the work of Eisner (1996), Collins et al. (1999), Yamada and Matsumoto (2003), Nivre and Scholz (2004), and McDonald et al. (2005)." target=" For a detailed descriptions see Haji6 (1998), Hladkfi (2000) and Collins, Haji6, Ram~haw, Tillmann (1999)." id="1055" weight="83.75898594195237" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="1056" weight="84.28673902499222" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="1057" weight="80.07027972395251" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="1058" weight="81.41643353442865" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1059" weight="82.51702534752437" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="1060" weight="80.89127848257674" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1061" weight="82.48323925231153" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1062" weight="86.241799610803" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1063" weight="84.15372030534745" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1064" weight="84.50060689808451" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1065" weight="82.05067940294965" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1066" weight="80.42023132712104" />
      <edge source=" To reduce sparseness, our features rely only on the reduced POS tag set from Collins et al. (1999)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1067" weight="80.48735168820455" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." id="1068" weight="82.20294665186157" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="1069" weight="86.02264441478236" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1070" weight="84.61659488950524" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1071" weight="84.64300747257063" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1072" weight="86.23013811952522" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1073" weight="85.91128290371026" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1074" weight="86.29191368913625" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1075" weight="81.20631065750872" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1076" weight="81.97988193864632" />
      <edge source=" Furthermore, we can also see that the MST parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by Collins et al. (1999) and Zeman (2004) that use expensive O n5 parsing algorithms." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1077" weight="81.44711101272183" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" id="1078" weight="82.63281609708577" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="1079" weight="83.25901283949109" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="1080" weight="82.51859090210611" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1081" weight="87.71603233419249" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="1082" weight="82.35103818680605" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1083" weight="84.10529373872518" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1084" weight="89.29099042345428" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1085" weight="85.0199314737223" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1086" weight="84.0341356089264" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1087" weight="85.92267960130862" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1088" weight="84.79777084733293" />
      <edge source=" We should note that the results in Collins et al. (1999) are different then reported here due to different training and testing data sets." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1089" weight="80.5161587248361" />
      <edge source=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." target=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." id="1090" weight="80.76041226551295" />
      <edge source=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="1091" weight="80.80025094087486" />
      <edge source=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="1092" weight="88.48199240401047" />
      <edge source=" For instance, work has been done in Chinese using the Penn Chinese Tree- bank (Levy and Manning, 2003; Chiang and Bikel, 2002), in Czech using the Prague Dependency Tree- bank (Collins et al., 1999), in French using the French Treebank (Arun and Keller, 2005), in German using the Negra Treebank (Dubey, 2005; Dubey and Keller, 2003), and in Spanish using the UAM Spanish Treebank (Moreno et al., 2000)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="1093" weight="83.94130536965996" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" id="1094" weight="81.84438156579108" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="1095" weight="81.04300133640268" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="1096" weight="80.90077223617311" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1097" weight="86.21020805599073" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="1098" weight="82.61703853216642" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1099" weight="85.0715497795858" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" Here 80% accuracy for unlabelled dependencies have been achieved(Collins et al., 1999)" id="1100" weight="81.76827973310634" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1101" weight="85.08582094094706" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1102" weight="80.92118358692434" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1103" weight="82.46428099062253" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1104" weight="85.12735278103332" />
      <edge source=" The authors in (Collins et al., 1999) describe an approach that gives 80% accuracy in recovering unlabeled dependencies in Czech.1" target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1105" weight="81.12207086941747" />
      <edge source=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="1106" weight="80.99995130498361" />
      <edge source=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="1107" weight="85.55448367442295" />
      <edge source=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="1108" weight="81.95711119336335" />
      <edge source=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1109" weight="80.67197372036723" />
      <edge source=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1110" weight="80.03817882169318" />
      <edge source=" Uses a probabilistic context-free grammar, home in constituency- based structures. Described in (Haji et al., 1998; Collins et al., 1999)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="1111" weight="89.98528302565083" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." id="1112" weight="81.37891957027313" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="1113" weight="80.97994696633681" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1114" weight="82.43021714820087" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="1115" weight="84.83366519864019" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1116" weight="80.8564156683317" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." id="1117" weight="85.31278849368798" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1118" weight="84.94555131009665" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1119" weight="80.39753176004751" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1120" weight="90.0387011364093" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1121" weight="80.21540861072145" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="1122" weight="84.49507614460663" />
      <edge source=" Statistical parsing models have been shown to be successful in recovering labeled constituencies (Collins, 2003; Charniak and Johnson, 2005; Roark and Collins, 2004) and have also been shown to be adequate in recovering dependency relationships (Collins et al., 1999;" target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1123" weight="86.40152666745861" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." id="1124" weight="85.91291301761879" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1125" weight="84.65712567006629" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." id="1126" weight="82.67253184377223" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="1127" weight="82.6294714046872" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1128" weight="86.43517043496098" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1129" weight="84.98041957795675" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1130" weight="81.76396789769946" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1131" weight="83.55121506165708" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1132" weight="81.96774835264075" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1133" weight="80.15653080154794" />
      <edge source=" A pragmatic justification for using constituency- based parsers in order to predict dependency structures is that currently the best Czech dependency- tree parser is a constituency-based parser (Collins et al., 1999; Zeman, 2004)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1134" weight="84.1225442950146" />
      <edge source=" In an attempt to extend a constituency-based parsing model to train on dependency trees, Collins transforms the PDT dependency trees into constituency trees (Collins et al., 1999)." target=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." id="1135" weight="83.06914058089005" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." id="1136" weight="85.67869772221479" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" a subset of the morphological tag as described in (Collins et al., 1999)" id="1137" weight="82.414875904727" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="1138" weight="80.56358124353633" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="1139" weight="81.95352848611262" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1140" weight="82.66204082837947" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1141" weight="83.1912194946033" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1142" weight="81.54246736163495" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1143" weight="85.92961290014296" />
      <edge source=" The trees are then transformed into Penn Treebank style constituencies using the technique described in (Collins et al., 1999)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1144" weight="80.70377437759038" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" id="1145" weight="84.71295122659082" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1146" weight="86.46227123632475" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1147" weight="88.31087865261655" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1148" weight="82.72333629495618" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1149" weight="83.73087140276793" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1150" weight="84.75406950934101" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1151" weight="87.49122061266002" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="1152" weight="82.23959394570568" />
      <edge source=" Although the results presented in (Collins et al., 1999) used the reordering technique, we have experimented with his parser using the governor-raising technique and observe an increase in dependency accuracy." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1153" weight="85.49637439518918" />
      <edge source=" a subset of the morphological tag as described in (Collins et al., 1999)" target=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." id="1154" weight="81.22798976821932" />
      <edge source=" a subset of the morphological tag as described in (Collins et al., 1999)" target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1155" weight="80.13691123240115" />
      <edge source=" a subset of the morphological tag as described in (Collins et al., 1999)" target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1156" weight="80.63080427927238" />
      <edge source=" a subset of the morphological tag as described in (Collins et al., 1999)" target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1157" weight="83.35652213254781" />
      <edge source=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1158" weight="86.35337393923403" />
      <edge source=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1159" weight="82.986792228282" />
      <edge source=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1160" weight="83.53852869715242" />
      <edge source=" From the resulting (noisy) dependency treebank, a dependency parser is trained using the techniques of (Collins, 1999)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1161" weight="84.40304548104965" />
      <edge source=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." target=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." id="1162" weight="86.74866773537016" />
      <edge source=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="1163" weight="80.39074194338906" />
      <edge source=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1164" weight="87.46168729512564" />
      <edge source=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1165" weight="85.92044824016625" />
      <edge source=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1166" weight="87.5680408620138" />
      <edge source=" Unlabeled attachment score (UAS): The proportion of words that are assigned the correct head (or no head if the word is a root) (Eisner, 1996; Collins et al., 1999)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1167" weight="80.34193435850719" />
      <edge source=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1168" weight="84.78653989968102" />
      <edge source=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1169" weight="82.70383132203689" />
      <edge source=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1170" weight="83.4118789369648" />
      <edge source=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1171" weight="82.79545980700497" />
      <edge source=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="1172" weight="82.95018751225732" />
      <edge source=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1173" weight="85.32239727083186" />
      <edge source=" This development has fueled interest in proting the parsing technologies developed for English and the Penn treebank format to other languages and representation formats(Collins et al., 1999; Debey and Leller, 2003)" target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1174" weight="80.13672157900061" />
      <edge source=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1175" weight="88.39746301875628" />
      <edge source=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1176" weight="83.77787571904949" />
      <edge source=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1177" weight="86.51008795086487" />
      <edge source=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1178" weight="81.56265153716203" />
      <edge source=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1179" weight="86.76034953859839" />
      <edge source=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="1180" weight="83.73038885433384" />
      <edge source=" The number of recovered dependencies gives an estimate of the probability that a dependency will be correctly identified by the LG parser (this criterion is also employed by, e.g., Collins et al. (1999))." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1181" weight="90.12671927596352" />
      <edge source=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." id="1182" weight="89.1057239922483" />
      <edge source=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1183" weight="84.56759267738443" />
      <edge source=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="1184" weight="85.1304473826689" />
      <edge source=" Lexicalization can increase parsing performance dramatically for English (Carroll and Rooth, 1998; Charniak, 1997, 2000; Collins, 1997), and the lexicalized model proposed by Collins (1997) has been successfully applied to Czech (Collins et al., 1999) and Chinese (Bikel and Chiang, 2000)." target=" For a detailed descriptions see Haji6 (1998), Hladkfi (2000) and Collins, Haji6, Ram~haw, Tillmann (1999)." id="1185" weight="86.18103666808463" />
      <edge source=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." target=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." id="1186" weight="83.30334755276043" />
      <edge source=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1187" weight="82.95799384443734" />
      <edge source=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1188" weight="80.53831614997485" />
      <edge source=" The work by Collins et al. (1999) and Bikel and Chiang (2000) has demonstrated the applicability of the Collins (1997) model for Czech and Chinese." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1189" weight="84.0100626829491" />
      <edge source=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." target=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." id="1190" weight="90.5243008886725" />
      <edge source=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1191" weight="91.07577501457105" />
      <edge source=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1192" weight="85.84856235010187" />
      <edge source=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1193" weight="84.41189714883761" />
      <edge source=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="1194" weight="84.74555036937348" />
      <edge source=" However, the learning curve for Negra (see Figure 1) indicates that the performance of the Collins (1997) model is stable, even for small training sets. Collins et al. (1999) and Bikel and Chiang (2000) do not compare their models with an unlexicalized baseline; hence it is unclear if lexicalization really improves parsing performance for these languages." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1195" weight="86.61240474748564" />
      <edge source=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." target=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." id="1196" weight="89.8843039822145" />
      <edge source=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1197" weight="87.89520919666107" />
      <edge source=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1198" weight="80.09337474857756" />
      <edge source=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="1199" weight="81.87284290940713" />
      <edge source=" We use the example of Dutch ditransitives, but our argument equally applies to other languages such as Czech (see Collins et al. (1999))." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1200" weight="80.86718850663183" />
      <edge source=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." target=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." id="1201" weight="81.26126132991185" />
      <edge source=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." target=" Dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al. 1997; Collins 1996; Collins et al. 1999)." id="1202" weight="80.21879830176515" />
      <edge source=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1203" weight="84.24428113093782" />
      <edge source=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="1204" weight="80.61610120188791" />
      <edge source=" However, such constructions prove to be difficult for stochastic parsers (Collins et al., 1999) and they either avoid tackling the problem (Charniak, 2000; Bod, 2003) or only deal with a subset of the problematic cases (Collins, 1997)." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1205" weight="80.47779598657334" />
      <edge source=" Collins et al. (1999) describe how the models in the current article were applied to parsing Czech." target=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." id="1206" weight="80.94850702022278" />
      <edge source=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." target=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." id="1207" weight="82.84712168871104" />
      <edge source=" The ATSs produced by Collins' dependency parser(Collins et al., 1999), which yields the ATSs, are manually edited; instructuions for the editing have been formulated and apporximately 100000 sentences have been annotated at the analytical level." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1208" weight="84.32749680008989" />
      <edge source=" Algorithm 2, as adopted by Collins and his colleagues [2] when they converted the Czech dependency Treebank [6] into a phrase- structure Treebank, produces phrase structures that are as flat as possible." target=" the sentences from CNC are preprocessed by a dependency-based modification of Collins et al.'s (1999) automatic parser (with a success rate of about 80%), followed by a manual tagging procedure that is supported by a special user-friendly software tool that enables the annotators to work with (i.e. modify) the automatically derived graphic representations of the trees;" id="1209" weight="83.94443776801475" />
    </edges>
  </graph>
</gexf>
