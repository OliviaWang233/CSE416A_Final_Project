1|Qazvinian and Radev [169] propose to summarize the reference areas in other articles related to the target paper that has to be summarized.
2|Machine learning methods have been shown to be very effective and successful in single and multi-document summarization, specifically in class specific summarization where classifiers are trained to locate particular type of information such as scientific paper summarization [51, 52, 71] and biographical summaries [62, 66, 81].
3|In previous work, (Qazvinian and Radev 2008), we used citation sentences and employed a network- based clustering algorithm to summaries of individual papers and more general scientific topics, such as Dependency Parsing, and Machine Translation (Radev et al. 2009a, b).
3|Previously, we showed in Qazvinian and Radev (2008) that different citations to the same paper they discuss various contributions of the cited paper.
3|Qazvinian and Radev (2008) proposed a method for summarizing scientific articles by building a similarity network of the sentences that cite it, and then applying network analysis techniques to find a set of sentences that covers as much of the paper factoids as possible.
3|This corpus has already been used in a variety of experiments (Qazvinian and Radev 2008; Hall et al. 2008; Councill et al. 2008; Qazvinian et al. 2010). 
4|In addition to citation function classification, automated research on citation content includes automatic abstraction, information retrieval, citation context recognition, etc.
5|Following the idea of generating summaries from this input information, in Qazvinian and Radev (2008) citations are analysed to produce a single-document summary from scientific articles.
6|Numerous summarization studies (Abu-Jbara & Radev, 2011; Elkiss et al., 2008; Kupiec, Pedersen, & Chen, 1995; Mei & Zhai, 2008; Mohammad et al., 2009; Nanba & Okumura, 2004; Qazvinian, Hassanabadi, & Halavati, 2008; Qazvinian & Radev, 2008, 2010; Teufel & Moens, 2002) have been applied to the scientific literature.
6|Although earlier studies (Nanba et al., 2000; Nanba & Okumura, 1999) analyzed citation sentences using predefined phrase-based rules to build survey generation tools, Qazvinian and Radev (2008) treated citation sentences as resources for fact summarization.
6|Other researchers (Abu-Jbara & Radev, 2011; Qazvinian et al., 2008) have proposed using LexRank (a network- based ranking algorithm equivalent to PageRank) to identify the most salient sentences within clusters.
7|Citations have generally proven useful for summarization (Abu-Jbara & Radev, 2011; Kaplan, Iida, & Tokunaga, 2009; Nanba & Okumura, 1999; Qazvinian & Radev, 2008, 2010; Taheriyan, 2011)
8|There has been previous work done on citation- based summarization (Nanba et al., 2000; Elkiss et al., 2008; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Mohammad et al., 2009).
8|Following Qazvinian and Radev (2008), we build a cosine similarity graph out of the sentences of each category.
8|Produced using Qazvinian and Radev (2008) system
8|One summary was produced using our system and the other was produced using Qazvinian and Radev (2008) system.
8|The sum mary that our system produced, the human summary, and a summary produced by Qazvinian and Radev (2008) summarizer (the best baseline - after our system and its variations - in terms of extraction quality as shown in the previous subsection.)
8|The forth baseline is Qazvinian and Radev (2008) citation-based summarizer (QR08) in which the citation sentences are first clustered then the sentences within each cluster are ranked using LexRank.
8|Qazvinian and Radev (2008) proposed a method for summarizing scientific articles by building a similarity network of the citation sentences that cite the target paper, and then applying network analysis techniques to find a set of sentences that covers as much of the summarized paper facts as possible.
9|More recently, Qazvinian and Radev (2008) argue that citation texts are useful in creating a summary of the important contributions of a research paper.
9|Citation texts have also been used to create summaries of single scientific articles in Qazvinian and Radev (2008) and Mei and Zhai (2008).
9|Two clustering methods proposed by Qazvinian and Radev (2008)—C-RR and C-LexRank—were used to create summaries.
9|This evaluation approach is similar to the one adopted by Qazvinian and Radev (2008), but adapted here for use in the multi-document case.
10|For example, citation-based summarization systems (Qazvinian and Radev, 2008; Qazvinian et al., 2010; Abu- Jbara and Radev, 2011) and survey generation systems (Mohammad et al., 2009; Qazvinian et al., 2013) can benefit from citation purpose and polarity analysis to improve paper and content selection.
11|Previous work has shown the importance of citations in scientific domains and indicated that citations include survey-worthy information (Sid- dharthan and Teufel, 2007; Elkiss et al., 2008; Qazvinian and Radev, 2008; Mohammad et al., 2009; Mei and Zhai, 2008).
11|Previous work that generate surveys of scientific topics use the text of citation sentences alone (Mohammad et al., 2009; Qazvinian and Radev, 2008).
11|Similarly, the text of citation sentences has been directly used to produce summaries of scientific papers in (Qazvinian and Radev, 2008; Mei and Zhai, 2008; Mohammad et al., 2009).
12|While we show only multi-document summaries in ASE, single- document citation text summaries using Trimmer or Cluster- Lexrank (Qazvinian & Radev, 2008) for highly cited papers could be easily added to provide another perspective.
13|TextRank [19] and Cluster LexRank [20] are two methods that use a graph-based approach for document summarization.
14|Other tasks that leverage citation contexts in clude classifying citation intent (Teufel et al., 2006; Jurgens et al., 2018; Cohan et al., 2019), identifying citation sentiment (Athar and Teufel, 2012), identifying meaningful citations (Valen- zuela et al., 2015), extracting key phrases (Caragea et al., 2014), and citation context-based paper summarization (Teufel et al., 2006; Qazvinian and Radev, 2008; Cohan and Goharian, 2015; Mitrovic ́ and Mu ̈ller, 2015).
15|Citation sentences have been used to build summaries of target papers [11, 15] as well as for supporting scientific literature search [1].
16|Moreover, citation contexts were used for scientific paper summarization (Abu-Jbara and Radev, 2011; Qazvinian et al., 2010; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Lehnert et al., 1990; Nakov et al., 2004).
17|Teufel and Moens (2002) and Qazvinian and Radev (2008) summarize scientific articles, the latter by automatically finding and filtering sentences in other papers that cite the target article.
17|This has been shown in other work too (Elkiss et al., 2008; Nanba et al., 2004; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Mohammad et al., 2009).
18|We use 25 manually annotated papers from (Qazvinian and Radev, 2008), which are highly cited articles in AAN.
18|The C-RR method as described in (Qazvinian and Radev, 2008) uses a round-robin fashion to pick sentences from each cluster, assuming that the clustering will put the sentences with similar facts into the same clusters.
19|More recently, Qazvinian and Radev (2008) argued that citation sentences (i.e., set of sentences that appear in other papers and cite a given article) are useful in creating a summary of important contributions of a research paper.
19|Previously, Qazvinian and Radev (2008) examined 7 different similarity measures including TF-IDF with various IDF databases, longest common sub-sequence, generation probability (Erkan, 2006), and the Levenstein distance on a training set of citations.
20|Citation based summary is a summary which is formed by utilizing a set of citations to a referenced article (Qazvinian and Radev, 2008; Qazvinian et al., 2013).
20|Our work is closest to Qazvinian and Radev (2008) with the difference that they only make use of citations.
20|Similar to (Qazvinian and Radev, 2008), we want to find subgraphs or communities whose intra-connectivity is high but inter-connectivity is low.
21|Cluster Lexrank (Qazvinian and Radev, 2008) is another graph-based summarization algorithm, and it tries to find important sentences in a graph in which nodes are sentences and edges are similarities.
22|Early work in citation- based summarization (Nakov, Schwartz, and Hearst 2004; Elkiss et al. 2008; Qazvinian and Radev 2008; Abu-Jbara and Radev 2011) aimed to summarize the contribution of a target paper (often called reference paper, or RP, in this context) by extracting a set of sentences from the citation sentences.
23|More recently, citation-based summarization received a great deal of attention [Teufel et al., 2006; Qazvinian and Radev, 2008].
24|While past work has often focused on citation structure (Borner et al., 2003; Qazvinian and Radev, 2008), our emphasis is on the text content, following Ramage et al. (2010) and Gerrish and Blei (2010).
24|Previous work on modeling scientific literature mostly focused on citation graphs (Borner et al., 2003; Qazvinian and Radev, 2008).
25|Previous work has shown that such summaries can be more informative than the abstract of the target paper, because they take into account the response of the community to the target paper after the publication of the paper (Qazvinian and Radev 2008; Qazvinian, Radev and O ̈zgu ̈r 2010).
26|Citation sentences have been used to build summaries of target papers [16,23] as well as for supporting scientific literature search [2].
27|The CL-SciSumm task provides resources to encourage research in a promising direction of scientific paper summarization, which considers the set of citation sentences (i.e., “citances”) that reference a specific paper as a (community created) summary of a topic or paper [21].
28|Citation analysis has proven to be very useful in automatic summarization (Mei and Zhai, 2008; Qazvinian and Radev, 2008).
29|The most common measures are macro and micro F-scores (Qazvinian and Radev 2008; Athar and Teufel 2012; Kang and Kim 2012) and average precision (Abu-Jbara and Radev 2012; Athar and Teufel 2012; Angrosh et al. 2013).
30|Previous work has studied and used citation sentences in various applications such as: scientific paper summarization (Elkiss et al., 2008; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Qazvinian et al., 2010; Qazvinian and Radev, 2010; Abu- Jbara and Radev, 2011), automatic survey genera- tion (Nanba et al., 2000; Mohammad et al., 2009), citation function classification (Nanba et al., 2000; Teufel et al., 2006; Siddharthan and Teufel, 2007; Teufel, 2007), and paraphrase recognition (Nakov et al., 2004; Schwartz et al., 2007).
31|It can also help expert researchers who are in the process of preparing opinion based summaries for survey papers by providing them with motivations behind as well as positive and negative comments about different approaches (Qazvinian and Radev, 2008).
32|Qazvinian and Radev [55] have used these parameters in summarizing scientific papers using citation summary networks.
33|Another similar study (Qazvinian and Radev, 2008) aims at using the content of citations within citing papers to generate summaries of fields of research.
34|Citation analysis has been used for many interesting applications, including paper summarization (Abu-Jbara & Radev, 2011; Qazvinian & Radev, 2008), survey generation (Mohammad et al., 2009), paper classification (Nanba, Kando, & Okumura, 2011), citation recommendation (He, Pei, Kifer, Mitra, & Giles, 2010), document clustering (Aljaber, Stokes, Bailey, & Pei, 2010; Tong, Dinakarpandian, & Lee, 2009), paper ranking (Jiang, Sun, & Zhuge, 2012), and information retrieval (Ritchie, Robertson, & Teufel, 2008).
35|These problems have inspired another type of scientific summaries which are obtained by utilizing a set of citations referencing the original paper [66,68].
36|It can be used to generate a summary of an article Qazvinian and Radev (2008).
37|They have been exploited for a number of natural language processing (NLP) and information retrieval (IR) applications, including summarization (Qazvinian and Radev, 2008; Qazvinian et al., 2010)[CJPF]1, improved indexing and retrieval (Ritchie et al., 2006)[CJPF], and building integrated research databases (Nanba et al., 2004)[CJPF].
38|Following the idea of generating summaries from this input information, in Qazvinian and Radev [30] citations are analyzed to produce a single-document summary from scientific articles. 
39|For instance, Qazvinian and Radev (2010, 2008) study the problem of summarizing a scientific paper.
40|Though traditional feature-based ranking approaches [15], [22], [29], [31], [38] employ quite different techniques to rank sentences, they have at least one point in common, i.e., all of them focus on sentences only, but ignoring the information beyond the sentence level (referring to Fig. 1(a)).
41|Further, Mei and Zhai (2008) and Qazvinian and Radev (2008) utilized citation information in creating summaries for a single scientific article in computational linguistics domain.
42|Apart from this, graph clustering is investigated to identify meaningful topics, such as [5, 8, 18, 19].
43|The Shared Task dataset comprises the set of citation sentences (i.e., “citances”) that reference a specific paper as a (community-created) summary of a topic or paper [19].
44|Although much work has been done in analyzing citation contexts (Qazvinian & Radev, 2008; Nakov, Schwartz, & Hearst, 2004), we are particularly interested in utilizing topic mod- eling techniques (Pritchard, Stephens, & Donnelly, 2000; Blei, Ng, & Jordan, 2003; Teh, Jordan, Beal, & Blei, 2006) to analyze the differences between topics identified based on the abstracts of citing papers and topics identified at the sentence level.
44|Citation contexts can be used to generate the summary of a paper (Qazvinian & Radev, 2008).
45|Citation analysis has been proposed for enhancing bibliometrics as well as for extractive summarization[129]. 
46|The CL-SciSumm task provides resources and benchmark tasks to encourage research on scientific paper summarization, which considers the set of citation sentences (i.e., “citances”) that reference a specific paper as a (community created) summary of a topic or paper [21]. 
47|For example, Qazvinian and Radev [21] applied hierarchical agglomerative clustering algorithm to obtain sentence clusters, and then developed two strategies to extract sentences from the clusters to build a summary.
48|Applications of citation analysis include evaluating the impact of a published literature through a measurable bibliometric (Garfield, 1972; Luukkonen, 1992; Borgman and Furner, 2002), analyzing bibliometric networks (Radev et al., 2009), summarizing scientific papers (Qazvinian and Radev, 2008; Abu-Jbara and Radev, 2011), generating surveys of scientific paradigms (Mohammad et al., 2009), among others.
49|Qazvinian et al. proposed a model of summarizing a single article, which is based on analyzing others' viewpoint of the tar- get article's contributions and the study of its citation summary network using a clustering approach [17].
50|Various works including [14], [15], [16], [17], [18], [19], [20], [21] employed citation information for the scientific article summarization.
51|Citations have been used by many researchers for summarization in this domain (Elkiss et al., 2008; Mohammad et al., 2009; Qazvinian and Radev, 2008; Abu-Jbara and Radev, 2011).
52|Qazvinian and Radev (2008) employ cosine measure on the task of scientific paper summarization using citations.
53|An application of the idea can be found in the work of Qazvinian and Radev [12,13], where they propose different methods to create a summary by extracting a subset of the sentences that constitute the citation context.
54|The Shared Task dataset comprises the set of citation sentences (i.e., “citances”) that reference a specific paper as a (community-created) summary of a topic or paper [19]
55|More recently, Qazvinian and Radev (2008) argue that citation texts are useful in creating a summary of the important contributions of a research paper. 
55|Hence, Qazvinian used citation sentences to create scientific paper summaries through citation summary networks and apply keyphrase extraction techniques to extract the key information contained in each citation which are then used to get high-quality citation-based summaries.
56|Qazvinian & Radev (2008) use sentences from papers citing the article to be summarised.
57|In addition, researchers have also focused on the potential usefulness of the text associated with citations in specific applications, such as text summarization [13, 14], thesaurus construction [15], and information retrieval [16, 17].
58|Recently, the community has acknowledged that sentences that cite a paper describe the community's view of the importance of a paper [31,32].
59|C-Lexrank is another network based content selec- tion algorithm that focuses on diversity (Qazvinian and Radev, 2008).
60|In order to enhance the performance of summarization, recently cluster-based ranking approaches were explored in the literature (Wan and Yang, 2006; Sun et al, 2007; Wang et al, 2008a,b; Qazvinian and Radev, 2008).
60|To summarize a scientific paper, Qazvinian and Radev (2008) presented two sentence selection strategies based on the clusters which were generated by a hierarchical agglomeration algorithm applied in the citation summary network.
60|A summary is generated in the same way as presented in (Qazvinian and Radev, 2008).
61|Qazvinian and colleagues (2008) present a summarization approach that can be seen as the converse of what we are working to achieve.
62|anguage model based method (Jagarlamudi, Pingali, & Varma, 2005; Lawrie, 2003; Qazvinian & Radev, 2008): Language model is used for characterizing the documents and especially for measuring the similarity by compar- ing with two probabilistic distribution contained in two sentences.
63|This key observation was then put to work by extracting the set of citation sentences to produce a summary of an article's contributions (Qazvinian & Radev, 2008).
64|Our work builds on previous work on summarization of scientific literature (Mohammad et al. 2009; Qazvinian and Radev 2008).
65|Other similar examples of related work sections are shown by Qazvinian and Radev4 and Wan et al.5
65|Based on this finding, Qazvinian and Radev employ the citations to create the summary for a scientific paper.
66|Qazvinian and Radev [53] published a novel approach to summarize scientific articles.
67|Some of these works focus on summarizing content (Paice, 1981; Paice and Jones, 1993), while others focused on citation sentences (citation-aware summarization) (Elkiss et al., 2008; Qazvinian and Radev, 2008; Abu- Jbara and Radev, 2011).
68|Works including (Mei and Zhai 2008; Qazvinian and Radev 2008; Schwartz and Hearst 2006; Mohammad et al., 2009) employed citation information for the single scientific article summarization.
69|Following the idea of generating summaries from this type of input information, in(Qazvinian % Radev, 2008) citations are analyzed to produce a single-document summary from scientific articles.
71|An example application is the automatic summarization of a set of research articles: Qazvinian and Radev (2008) and Qazvinian et al. (2013) proposed using the text of citing sentences to produce summaries of individual articles.
72|A first application of the idea can be found in the work of Qazvinian and Radev [18], where they create a summary by extracting a subset of the sentences that constitute the citation context.
73|Qazvinian & Radev (2008) and Mohammad et al. (2009b) use clustering techniques to locate core areas of a corpus, and then use the contexts around each citation to generate extracts that stand in as survey summaries.
74|It can be used to generate a summary of an article (Qazvinian, 2008).
75|An application of the idea can be found in Qazvinian and Radev (2008) and Qazvinian, Radev, and Ozgur (2010), where a summary is created extracting a subset of the sentences that constitute the citation context.
76|Following the approach of Qazvinian et al. (Qazvinian and Radev, 2008), we use the citing papers to help inform the summary, but also build a language model to cover the major sections of the paper such as the abstract and the results sections.
76|In (Qazvinian and Radev, 2008) the authors use the citation network to produce a summary of a scientific article and thereby put the focus on what other authors wrote about a paper as the prominent information to include in a summary of a paper in the scientific literature.
77|A seminal approach in [5], [6] leverages citation context for summarization.
78|Qazvinian and Radev [2] and Mei and Zhai [7] argued that citation contexts are useful for creating a summary of the important aspects of a paper.
79|This paper focuses on using citation sentiment analysis for scientific authoring support (Nanba et al., 2004; Qazvinian & Radev, 2008;Zhang et al., 2008; Ritchie et al., 2008; Shafer & Kasterka, 2010).
80|Graph-based methods. These methods construct graph where short texts as nodes and text-pairwise relations as edges [5–8].
81|For instance, [6] and [8] used the citation links to create a network and then classify the papers based on that.
82|Similarly, approaches for summarising an academic document based on the citations of that document found in the literature at large have been studied [10].
83|There is no doubt that, more and more attention has been paid in automatic summarization on scientific text due to the increasing demand (Chen and Zhuge 2014; Cohan and Goharian 2017; Qazvinian and Radev 2008; Qazvinian et al. 2013; Ronzano and Saggion 2016).
83|Previous work has focused on utilization of citation-based information to generate summaries on a research topic or paper (Abu- Jbara and Radev 2011; Mei and Zhai 2008; Nanba et al. 2011; Qazvinian and Radev 2008).
84|Such techniques include metadata extraction [11], [13], paper summarization [1], [23], survey generation [2], [23], [31], literature search [9], [17], paper recommendation [28], and trend visualization [6], [25], [29].
85|Similarly, [11] presented an approach for summarising an academic document based on the citations of that document found the literature at large.
86|Importantly, the notion of cross-document coherence (as represented by citation links, for example) is widely-applicable for generating summaries in different scenarios (see also, for example, Teufel and Moens 2002; Qazvinian and Radev 2008; Mohammad et al. 2009).
87|Unsupervised methods often use the ranking models to select sentences from a candidate set, and include centroid-based method [30], language model based methods [15,18,29] and graph-based methods [12,26,43].
88|Other previous studies have used citing sentences in various applications such as: scientific paper summarization (Elkiss et al., 2008; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Qazvinian et al., 2010; Qazvinian and Radev, 2010; Abu-Jbara and Radev, 2011a), automatic survey generation (Nanba et al., 2000; Mohammad et al., 2009), and citation function classification (Nanba et al., 2000; Teufel et al., 2006; Siddharthan and Teufel, 2007; Teufel, 2007).
89|Citances often cover important and novel insights about findings or aspects of a paper that others have found interesting; thus, they capture contributions that had an impact on the research community (Elkiss et al., 2008; Qazvinian and Radev, 2008).
90|Moreover, citation contexts were used for scientific paper summarization (Abu-Jbara and Radev, 2011; Qazvinian et al., 2010; Qazvinian and Radev, 2008; Mei and Zhai, 2008; Lehnert et al., 1990)
91|These techniques take advantage of the citations that a research paper has in order to extract and summarize its main contributions (Qazvinian & Radev, 2008, 2010). 
92|And (Qazvinian and Radev,2008)[2] take the citation summary of a reference paper into account to produce a summary of a single scientific article.
93|More recently citation text has been used also for summarization of scientific articles: the set of citations to a target article – sentences about the cited paper, called citances (Nakov, Schwartz, & Hearst, 2004) – are used to ascertain its important contributions, and to form a summary (Divoli, Nakov, & Hearst, 2012; Elkiss et al., 2008; Mei & Zhai, 2008; Mohammad et al., 2009; Qazvinian & Radev, 2008; Qazvinian et al., 2013).
94|Qazvinian and Radev (2008) presented an application of citation analysis to summarization, where they sought to extract, from among the set of sentences that constitute the citation summary, a subset that gives the main contributions of that paper.
95|It also contains a small set of 25 highly cited articles which are manually annotated with respect to important facts9 (Qazvinian & Radev, 2008). 
95|For the only paper provided as an example (P99- 1065) in (Qazvinian & Radev, 2008), there are some differences in the computation of matches between our results and those given in the paper, which are probably due to a different way of performing string matching and a slightly different version of the corpus.
95|In order to compare our approach with that of (Qazvinian & Radev, 2008), we also downloaded C-LexRank, the method described in that paper, which was released by the authors as a Perl script.
95|The pyramid scores that we compute differ from those reported in (Qazvinian & Radev, 2008), which reports a pyramid score of 0.41 for random, 0.71 for LexRank and 0.75 for C-LexRank; whereas our results for random are similar to the other methods.
96|Such a search index can be constructed by generating a graph where nodes represent documents (such as tweets) and edges represent their pairwise similarity according to some distance measure (e.g., the number of words in common) [8], [16].
97|Qazvinian and Radev (2008) built a similarity network of the citation sentences that cite a target paper, and applied network analysis techniques to determine the sentences that covered as much summarized facts about the paper as possible.
97|This evaluation approach is similar to the one adopted by Qazvinian and Radev (2008), but adapted here for use in the multi-document case.
98|Later papers on citation analysis, summarization, classification, etc. are Qazvinian et al. (2010), Abu- Jbara & Radev (2011), Qazvinian & Radev (2010), Qazvinian & Radev (2008), Mohammad et al. (2009), Athar (2011), Schäfer & Kasterka (2010), and Dong & Schäfer (2011).
99|The problem of graph clustering arises in many practical applications, such as in the distributed allocation of radio resources in wireless communications [4], [5], the analysis of scientific collaboration in citation networks [6], [7] and the prediction of protein functions [8].
100|The paper recommendation issue is known as paper recommendation [8], [17], [3], paper summarization [20], [9], [11], [5], and paper suggestion [14], [15].
101|A citation-based summary employs a set of citations that reference an article to create a summary of that cited article (Qazvinian and Radev, 2008; Qazvinian et al., 2013).
101|Qazvinian and Radev (2008) proposed a summarization system based on citation sentences. 
102|Qazvinian and Radev [39] used citation summaries and network analysis techniques to produce a summary of the important contributions of a research paper.
103|There are a few other diversity-focused summarization systems like C-LexRank (Qazvinian and Radev, 2008), which employs document clustering.
104|Then the the network is split into communities, and the most salient documents in each community are selected (Qazvinian and Radev, 2008).
105|Qazvinian et al. (2008) present a summarization approach that can be seen as the converse of what we are working to achieve.
106|Summarizing long inputs has been investigated in many domains, including books (Mihalcea and Ceylan, 2007), patents (Trappey et al., 2009), movie scripts (Gorinski and Lapata, 2015), and scientific publications (Qazvinian and Radev, 2008).
107|Qazvinian et al. [67] produce a document's summary using a cluster-based approach.
108|In recent years there has been a growing interest in the problem of citation-based summarization [25, 2, 1] where given a cluster of scientific documents in which one document in the cluster is a reference paper and the rest of the documents are papers citing the reference paper, the objective is to summarize the reference paper taking in consideration the information citing it.
109|Earlier work in the area of survey article generation has investigated content models based on lexical networks (Mohammad et al., 2009; Qazvinian and Radev, 2008).
110|Some of the recent work has treated survey generation as a direct extension of single paper summarization (Qazvinian and Radev, 2008) and used citing sentences to a set of relevant papers as the input for the summarizer (Mohammad et al., 2009; Qazvinian et al., 2013).
111|C-Lexrank is a clustering-based summarization system that was proposed by Qazvinian and Radev (2008) to summarize different perspectives in citing sentences that reference a paper or a topic.
112|C-Lexrank (Qazvinian and Radev, 2008) modifies Lexrank by first running a clustering algorithm on the network to partition the network into different communities and then selecting sentences from each community by running Lexrank on the sub-network within each community.
113|Clustering is used to increase the diversity of content in extractive multi-document summaries (Otter- bacher, Erkan, and Radev 2005; Qazvinian and Radev 2008).
114|After that, [11] employed citation sentences for scientific summarization.
115|Recently, the value of this information has been shown in practical applications such as information retrieval (IR)(Ritchie et al., 2008), summarization (Qazvinian and Radev, 2008), and even identifying scientific breakthroughs (Small and Klavans, 2011).
116|Therefore such statements in publications on previous literature, which we here call Cited Statements, offer succinct comments on prior art, whose information content is powerful enough to be used for article summarization14.
117|Later, [21] cleverly used a citation network to form summaries and demonstrated that the information others state about an article give further insights to the significance of the work’s contributions to the scientific community.
118|Two variants of the LexRank system have been proposed by Qazvinian and Radev (2008) for the summarisation of publications: Cluster Lexrank (C-lexrank) calculates LexRank within each cluster while Cluster Round-Robin (C-RR) picks sentences from each cluster in a Round-Robin way.
119|Qazvinian and Radev (2008) present an approach to summarising academic documents based on finding citation con- texts in the entire set of published literature for the document in question.
120|Qazvinian and Radev [11] proposed a method for the summarisation of scientific papers by clustering the nodes of a graph.
120|However, our approach exploits surface-level features of the text like previous works [28,31,35], clusters the input sentences into some clusters and chooses summary sentences from them in a similar manner to Qazvinian and Radev [11], Park et al. [22] and Cai and Li [23].
121|Two popular techniques for avoiding redundancy in summarization are maximal marginal relevance (MMR; Carbonell & Goldstein, 1998) and clustering (Mckeown, Kalvans, Hatzivassiloglou, Barzilay, & Eskin, 1999; Qazvinian & Radev, 2008).
121|Finally, we choose the most salient sentence from the most salient sentence clusters to the least salient sentence clusters, then the second-most salient sentences of each cluster, and so on, which is similar to C-LexRank (Qazvinian & Radev, 2008).
122|Recent work concentrates in taking advantage of the extracted citation information, for example, for scientific paper summarization [6] and text retrieval [7].
123|Recent works using citations concentrate in taking advantage of extracted citation information, for example on scientific paper summarization [78], text retrieval [86] and document clustering [1].
124|One of the initial works in the area is due to Quazvinian and Radev [18] who use a clustering based approach to generate citation based summaries.
125|Qazvinian and Radev (2008) first experimented with citation summary based paper summarisations.
126|The manual annotation has been performed independently by annotators, and a phrase needed to be marked by at least 2 annotators to be qualified as capturing a paper's key fact (Qazvinian and Radev, 2008).
126|The manual annotation has been performed independently by annotators, and a phrase needed to be marked by at least 2 annotators to be qualified as capturing a paper’s key fact (Qazvinian and Radev, 2008).
126|For paper P05-1013, Table 2 lists the top 10 keywords identified from its citation summary using our method, while Table 1 lists the humanly selected gold standard key facts (Qazvinian and Radev, 2008).
126|Intuitively, a good summarisation should be short, and consist of citing sentences that maximise keywords coverage w.r.t. an arbitrarily imposed summary length limit (Qazvinian and Radev, 2008). 
126|To facilitate comparison and cross-referencing, the table has been formatted as close as possible to Table 7 in (Qazvinian and Radev, 2008) with figures in the Gold and C- LexRank columns directly copied over.
127|Qazvinian and Radev [3] use citation and lexicons of citing sentences to construct a citation lexical network and summarize the impact of a scientific publication. 
128|Other work in this area uses the text of documents along with citations to summarize documents (Qazvinian and Radev, 2008) or to propose new bibliometrics: Mann et al. (2006) use topic models and citations to map topics over time and define several new bibliometric measurements such as topic Impact Factor, topical diffusion, and topic longevity.
129|The typical examples of such use are C-RR and C-LexRank proposed by Qazvinian and Radev [28], which selected the important citation sentences from the sentence clusters generated by a hierarchical agglomeration algorithm.
130|Qazvinian and Radev [30] proposed a model of summarizing a single article which is based on analyzing other’s viewpoint of the target article’s contributions and the study of its citation summary network using a clustering approach.
131|It has been claimed that since citations reveal the most important and mention-worthy information of a reference paper, their combination would capture all the paper’s main points and contributions (Qazvinian and Radev 2008).
132|The task is like the task of scholarly paper summarization (Luh- n, 1958; Edmundson, 1969; Qazvinian and Radev, 2008; Mei and Zhai, 2008).
133|It is useful in summarizing a scientific topic [V.Qazvinian and D.R.Radev, 2008] [Chen and Zhuge, 2013].
134|In Qazvinian and Radev (2008), on the other hand, the authors have proposed a citation summary network that uses a clustering approach where communities in the citation summary's lexical network are formed and sentences are extracted from separate clusters.
135|This context (known as citation context or citation summary) refers to a set of sentences pointing to the paper [17] when cited.
136| The SDS has variety of high- quality datasets (Hermann et al. 2015; Grusky, Naaman, and Artzi 2018) on different domains such as news (Napoles, Gormley, and Durme 2012; Nallapati et al. 2016), scientific articles (Qazvinian and Radev 2008), etc., however, not many high-quality datasets exist for QMDS training and evaluation.
137|(Qazvinian and Radev, 2008) analyzed the network of citations to an article to generate its summary.
138|Traditional models focused on aggregating all citances (citation sentences) that cite one unique paper for summarization [3, 4].
139|Although scientific summarization has always been an important research topic in the area of natural language processing (NLP) [11, 17, 23, 24] in recent years new summarization approaches have emerged which take advantage of the citations that a scientific article has received in order to extract and summarize its main contributions [18, 19, 1]. 
140|Summarization of scientific papers has been studied widely. Some earlier studies have used citation networks [20, 2], which are based on the idea that sentences describing a cited paper have crucial information related to the cited paper.
141|Citation networks have been studied for several decades in the information sciences (Egghe & Rousseau, 1990; Price, 1965) and more recently in physics (Lehmann, Lautrup, & Jackson, 2003; Redner, 1998) and in computational linguistics (Qazvinian & Radev, 2008) for various properties that are similar to other real world networks (e.g. clustering into communities). 
142|Another direction is citation summary (Qazvinian and Radev 2008; Cohan and Goharian 2018; Yasunaga et al. 2019), which can make use of the reference relationship between papers.
143|Other research topics include paper summarization (Qazvinian and Radev, 2008; Abu-Jbara and Radev, 2011), survey generation (Mohammad et al., 2009; Yeloglu et al., 2011), literature search (Li et al., 2010; Shahaf et al., 2012), and paper recommendation (Sugiyama et al., 2010).
144|The typical examples of such use are C-RR and C-LexRank proposed by Qazvinian and Radev [2008], which selected the important citation sentences from the sentence clusters generated by a hierarchical agglomerative algorithm.
145|In addition to assessment, metrics for quality of academic writing would be quite useful for generation systems. Particularly there is interest in recent years on summarization of scientific articles [105, 130, 131].
146|More recently, Qazvinian and Radev (2008) argue that citation text is useful in creating a summary of the important contributions of a research paper.
147|Citation texts have also been used to create summaries of single scientific articles in (Qazvinian and Radev, 2008; Mei and Zhai, 2008).
148|To create summaries, we also use two clustering methods that are proposed in Qazvinian and Radev (2008), which are called C-RR and C-LexRank.
149|This evaluation approach is similar to the one adopted by Qazvinian and Radev (2008), but adapted here for use in the multi-document case.
150|Further, Mei and Zhai (2008) and Qazvinian and Radev (2008) utilized citation information in creating summaries for a single scientific article in computational linguistics domain.
